{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values:  2363\n",
      "Missing timestamps: 4        2023-08-24 23:00:00\n",
      "6        2023-08-25 00:00:00\n",
      "7        2023-07-30 07:00:00\n",
      "12       2023-08-25 01:00:00\n",
      "14       2023-07-30 06:00:00\n",
      "                ...         \n",
      "37316    2023-07-26 00:00:00\n",
      "37319    2023-08-07 00:00:00\n",
      "37322    2023-08-17 00:00:00\n",
      "37325    2023-08-27 00:00:00\n",
      "37328    2023-09-05 00:00:00\n",
      "Name: TIMESTAMP, Length: 1171, dtype: object\n",
      "      VWC_06    VWC_18    VWC_30    VWC_42   day_sin   day_cos  hour_sin  \\\n",
      "4   0.520205  0.493258  0.335655  0.229572 -0.796183 -0.605056 -0.258819   \n",
      "6   0.520205  0.493258  0.335655  0.221790 -0.806480 -0.591261  0.000000   \n",
      "7   0.323284  0.265436  0.316656  0.800000 -0.471160 -0.882048  0.965926   \n",
      "12  0.510584  0.493258  0.335655  0.233463 -0.806480 -0.591261  0.258819   \n",
      "14  0.331623  0.265436  0.314756  0.807004 -0.471160 -0.882048  1.000000   \n",
      "\n",
      "        hour_cos   dow_sin   dow_cos  \n",
      "4   9.659258e-01  0.433884 -0.900969  \n",
      "6   1.000000e+00 -0.433884 -0.900969  \n",
      "7  -2.588190e-01 -0.781831  0.623490  \n",
      "12  9.659258e-01 -0.433884 -0.900969  \n",
      "14  6.123234e-17 -0.781831  0.623490  \n"
     ]
    }
   ],
   "source": [
    "# Imports for data handling and processing\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Connect to the database and load data\n",
    "conn = sqlite3.connect('processed_data.db')\n",
    "query = 'SELECT * from data_table'\n",
    "df = pd.read_sql_query(query, conn)\n",
    "conn.close()\n",
    "\n",
    "# select plot_number 2014\n",
    "df = df[df['plot_number'] == 2014]\n",
    "\n",
    "# select data between July 19 and September 06\n",
    "df = df[(df['TIMESTAMP'] >= '2023-07-19') & (df['TIMESTAMP'] <= '2023-09-06')]\n",
    "\n",
    "# print number of missing values\n",
    "print(\"Number of missing values: \", df.isnull().sum().sum())\n",
    "\n",
    "#print timestamps of missing values beside the missing values\n",
    "print(f\"Missing timestamps: {df[df.isnull().any(axis=1)]['TIMESTAMP']}\")\n",
    "\n",
    "# Timestamp cyclical encoding for day of year\n",
    "df['TIMESTAMP'] = pd.to_datetime(df['TIMESTAMP'])\n",
    "df['day_sin'] = np.sin(df['TIMESTAMP'].dt.dayofyear / 365 * 2 * np.pi)\n",
    "df['day_cos'] = np.cos(df['TIMESTAMP'].dt.dayofyear / 365 * 2 * np.pi)\n",
    "\n",
    "# Timestamp cyclical encoding for hour of day\n",
    "df['hour_sin'] = np.sin(df['TIMESTAMP'].dt.hour / 24 * 2 * np.pi)\n",
    "df['hour_cos'] = np.cos(df['TIMESTAMP'].dt.hour / 24 * 2 * np.pi)\n",
    "\n",
    "# Timestamp cyclical encoding for day of week\n",
    "df['dow_sin'] = np.sin(df['TIMESTAMP'].dt.dayofweek / 7 * 2 * np.pi)\n",
    "df['dow_cos'] = np.cos(df['TIMESTAMP'].dt.dayofweek / 7 * 2 * np.pi)\n",
    "\n",
    "\n",
    "# Normalization (if beneficial after exploration)\n",
    "scaler = MinMaxScaler()\n",
    "columns_of_interest = ['VWC_06', 'VWC_18', 'VWC_30', 'VWC_42']\n",
    "df[columns_of_interest] = scaler.fit_transform(df[columns_of_interest])\n",
    "\n",
    "# Drop unnecessary columns (anything that is not an encoded feature or a column of interest)\n",
    "columns_to_drop = [col for col in df.columns if col not in ['day_sin', 'day_cos', 'hour_sin', 'hour_cos', 'dow_sin', 'dow_cos'] + columns_of_interest]\n",
    "df = df.drop(columns=columns_to_drop)\n",
    "\n",
    "# drop rows with missing values\n",
    "df = df.dropna()\n",
    "\n",
    "# print statistics for the vwc columns\n",
    "#print(df[columns_of_interest].describe())\n",
    "print(df.head())\n",
    "\n",
    "# implement the The Augmented Dickey-Fuller (ADF) test to check for stationarity\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "for column in columns_of_interest:\n",
    "    result = adfuller(df[column])\n",
    "    print(f'ADF Statistic for {column}: {result[0]}')\n",
    "    print(f'p-value: {result[1]}')\n",
    "    print('Critical Values:')\n",
    "    for key, value in result[4].items():\n",
    "        print(f'\\t{key}: {value}')\n",
    "        \n",
    "# conclude based on the p-value\n",
    "if result[1] > 0.05:\n",
    "    print(f\"The p-value of {result[1]} is greater than 0.05, so the time series is not stationary.\")\n",
    "else:    \n",
    "    print(f\"The p-value of {result[1]} is less than 0.05, so the time series is stationary.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "from hmmlearn import hmm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data Preparation\n",
    "def create_data_sequences_vectorized(df, window_size, prediction_horizon, step_size, targets, features):\n",
    "    # Check for missing columns upfront\n",
    "    missing_cols = [col for col in features + targets if col not in df.columns]\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"Missing columns in DataFrame: {', '.join(missing_cols)}\")\n",
    "\n",
    "    # Ensure dataset is large enough\n",
    "    if len(df) < window_size + prediction_horizon:\n",
    "        raise ValueError(\"Dataset size too small for the given window_size and prediction_horizon.\")\n",
    "\n",
    "    X, y = [], []\n",
    "    for i in range(0, len(df) - window_size - prediction_horizon + 1, step_size):\n",
    "        # Extract features for the window size\n",
    "        feature_values = df[features].iloc[i:i+window_size].values\n",
    "        X.append(feature_values)\n",
    "\n",
    "        # Extract target values for the prediction horizon\n",
    "        target_values = df[targets].iloc[i+window_size:i+window_size+prediction_horizon].values\n",
    "        y.append(target_values)\n",
    "\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "\n",
    "\n",
    "# Model Fitting\n",
    "def fit_hmm(X, n_states=5, model_type='GaussianHMM'):\n",
    "    model = getattr(hmm, model_type)(n_components=n_states, covariance_type='full')\n",
    "    # Flatten X for HMM training\n",
    "    X_flattened = X.reshape(X.shape[0]*X.shape[1], -1)\n",
    "    model.fit(X_flattened)\n",
    "    return model\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def predict_hmm(model, initial_observations, prediction_horizon_days):\n",
    "    \"\"\"\n",
    "    Predicts VWC values for a future horizon using a trained HMM, given initial observations.\n",
    "\n",
    "    Args:\n",
    "        model: The trained Hidden Markov Model.\n",
    "        initial_observations: A 2D array of shape [192, num_features] for 8 days of hourly observations.\n",
    "        prediction_horizon_days: The number of days to predict, expected to be 4 days here.\n",
    "\n",
    "    Returns:\n",
    "        A NumPy array with shape [prediction_horizon_days * 24, num_targets], containing predicted VWC values.\n",
    "    \"\"\"\n",
    "    num_hours_per_day = 24\n",
    "    prediction_horizon_hours = prediction_horizon_days * num_hours_per_day\n",
    "    num_targets = 4  # Number of VWC sensors to predict\n",
    "\n",
    "    # Initialize the output array with zeros\n",
    "    predicted_vwc = np.zeros((prediction_horizon_hours, num_targets))\n",
    "\n",
    "    # Simulate prediction logic assuming the HMM model can generate hourly predictions for each target\n",
    "    # This is a placeholder for the actual model prediction logic\n",
    "    for i in range(prediction_horizon_hours):\n",
    "        # Generate a sample from the model (assuming it gives hourly predictions for each VWC sensor)\n",
    "        next_sample, _ = model.sample()\n",
    "        print(f\"next_sample_shape: {next_sample.shape}\")\n",
    "        print(f\"next_sample: {next_sample}\")\n",
    "        predicted_vwc[i, :] = next_sample[:num_targets]\n",
    "        \n",
    "\n",
    "    return predicted_vwc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (28, 192, 6), X_test shape: (8, 192, 6)\n",
      "y_train shape: (28, 96, 4), y_test shape: (8, 96, 4)\n",
      "next_sample_shape: (1, 6)\n",
      "next_sample: [[-0.61270205 -0.75829709 -0.11046749 -0.0333957  -0.0082407   0.2935999 ]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (6,) into shape (4,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 34\u001b[0m\n\u001b[0;32m     32\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty_like(y_test)  \u001b[38;5;66;03m# Ensure y_pred matches the shape of y_test\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, obs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(X_test):\n\u001b[1;32m---> 34\u001b[0m     y_pred[i] \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_hmm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction_horizon\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Assuming predict_hmm is adapted for 3D\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Adjust metric calculations for 3D output\u001b[39;00m\n\u001b[0;32m     37\u001b[0m rmse \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(mean_squared_error(y_test, y_pred, multioutput\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraw_values\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "Cell \u001b[1;32mIn[18], line 67\u001b[0m, in \u001b[0;36mpredict_hmm\u001b[1;34m(model, initial_observations, prediction_horizon_days)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnext_sample_shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnext_sample\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnext_sample: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnext_sample\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 67\u001b[0m     \u001b[43mpredicted_vwc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m next_sample[:num_targets]\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m predicted_vwc\n",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (6,) into shape (4,)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "# Configuration variables\n",
    "window_size = 192\n",
    "prediction_horizon = 96\n",
    "step_size = 24\n",
    "n_states = 5\n",
    "features = ['day_sin', 'day_cos', 'hour_sin', 'hour_cos', 'dow_sin', 'dow_cos']\n",
    "targets = ['VWC_06', 'VWC_18', 'VWC_30', 'VWC_42']\n",
    "\n",
    "# Data preparation\n",
    "X, y = create_data_sequences_vectorized(df, window_size, prediction_horizon, step_size, targets=targets, features=features)\n",
    "\n",
    "kf = KFold(n_splits=5)\n",
    "metrics = {'RMSE': [], 'MAE': [], 'R2': []}\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    #print X and y train and test shapes\n",
    "    print(f\"X_train shape: {X_train.shape}, X_test shape: {X_test.shape}\")\n",
    "    print(f\"y_train shape: {y_train.shape}, y_test shape: {y_test.shape}\") \n",
    "    \n",
    "    model = fit_hmm(X_train, n_states)\n",
    "    \n",
    "    # Adjust the prediction loop to correctly handle the 3D structure of y_test\n",
    "    y_pred = np.empty_like(y_test)  # Ensure y_pred matches the shape of y_test\n",
    "    for i, obs in enumerate(X_test):\n",
    "        y_pred[i] = predict_hmm(model, obs, prediction_horizon)  # Assuming predict_hmm is adapted for 3D\n",
    "    \n",
    "    # Adjust metric calculations for 3D output\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred, multioutput='raw_values'))\n",
    "    mae = mean_absolute_error(y_test, y_pred, multioutput='raw_values')\n",
    "    r2 = r2_score(y_test, y_pred, multioutput='variance_weighted')\n",
    "    \n",
    "    metrics['RMSE'].append(rmse.mean(axis=0))  # Average over timesteps for each target\n",
    "    metrics['MAE'].append(mae.mean(axis=0))\n",
    "    metrics['R2'].append(r2)  # R2 is calculated globally but can be interpreted in context\n",
    "\n",
    "# Average metrics across folds and then across targets for a single overall metric\n",
    "print(f\"Average RMSE: {np.mean(metrics['RMSE']):.4f}\")\n",
    "print(f\"Average MAE: {np.mean(metrics['MAE']):.4f}\")\n",
    "print(f\"Average R2: {np.mean(metrics['R2']):.4f}\")\n",
    "\n",
    "# Visualization for a single prediction instance, already correctly implemented\n",
    "\n",
    "# Model saving, unchanged\n",
    "with open('trained_vwc_hmm.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
