{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.signal import savgol_filter\n",
    "\n",
    "\n",
    "def trim_start_end_nans(df):\n",
    "    \"\"\"\n",
    "    Removes rows at the start and end of a DataFrame that have NaN values in any column.\n",
    "    \"\"\"\n",
    "    # Initialize start_idx and end_idx based on the DataFrame's index type\n",
    "    if isinstance(df.index, pd.DatetimeIndex):\n",
    "        start_idx = df.index[0]  # Assume first index is earliest; adjust if necessary\n",
    "        end_idx = df.index[-1]  # Assume last index is latest; adjust if necessary\n",
    "    else:\n",
    "        start_idx = 0\n",
    "        end_idx = len(df) - 1\n",
    "\n",
    "    for column in df.columns:\n",
    "        # Find the first non-NaN index in the current column\n",
    "        first_valid_index = df[column].first_valid_index()\n",
    "        if first_valid_index is not None and df.index.get_loc(first_valid_index) > df.index.get_loc(start_idx):\n",
    "            start_idx = first_valid_index\n",
    "\n",
    "        # Find the last non-NaN index in the current column\n",
    "        last_valid_index = df[column].last_valid_index()\n",
    "        if last_valid_index is not None and df.index.get_loc(last_valid_index) < df.index.get_loc(end_idx):\n",
    "            end_idx = last_valid_index\n",
    "\n",
    "    # Trim the DataFrame\n",
    "    return df.loc[start_idx:end_idx]\n",
    "\n",
    "# Now, apply the updated function to the DataFrame\n",
    "\n",
    "def process_data_for_plot(plot_number, start_date='2023-07-20', end_date='2023-09-03'):\n",
    "    \"\"\"\n",
    "    Process data for a given plot number within a specified date range.\n",
    "\n",
    "    Parameters:\n",
    "    - plot_number: The plot number to filter the data by.\n",
    "    - start_date: The start date of the period to filter the data.\n",
    "    - end_date: The end date of the period to filter the data.\n",
    "\n",
    "    Returns:\n",
    "    - A processed DataFrame with the data for the specified plot and date range.\n",
    "    \"\"\"\n",
    "    # Connect to the database and load data\n",
    "    conn = sqlite3.connect('processed_data.db')\n",
    "    query = 'SELECT * from data_table'\n",
    "    df = pd.read_sql_query(query, conn)\n",
    "    conn.close()\n",
    "\n",
    "    # Filter by plot_number\n",
    "    df = df[df['plot_number'] == plot_number]\n",
    "\n",
    "    # Filter by date range\n",
    "    df = df[(df['TIMESTAMP'] >= start_date) & (df['TIMESTAMP'] <= end_date)]\n",
    "\n",
    "    # Timestamp cyclical encoding\n",
    "    df['TIMESTAMP'] = pd.to_datetime(df['TIMESTAMP'])\n",
    "    df['day_sin'] = np.sin(df['TIMESTAMP'].dt.dayofyear / 365 * 2 * np.pi)\n",
    "    df['day_cos'] = np.cos(df['TIMESTAMP'].dt.dayofyear / 365 * 2 * np.pi)\n",
    "    df['hour_sin'] = np.sin(df['TIMESTAMP'].dt.hour / 24 * 2 * np.pi)\n",
    "    df['hour_cos'] = np.cos(df['TIMESTAMP'].dt.hour / 24 * 2 * np.pi)\n",
    "    df['dow_sin'] = np.sin(df['TIMESTAMP'].dt.dayofweek / 7 * 2 * np.pi)\n",
    "    df['dow_cos'] = np.cos(df['TIMESTAMP'].dt.dayofweek / 7 * 2 * np.pi)\n",
    "\n",
    "    # Define columns for processing\n",
    "    time_columns = ['day_sin', 'day_cos', 'hour_sin', 'hour_cos', 'dow_sin', 'dow_cos']\n",
    "\n",
    "    # Columns for correlation matrix\n",
    "    corr_columns = [\n",
    "        'Ta_2m_Avg', 'RH_2m_Avg', 'Solar_2m_Avg', 'WndAveSpd_3m', \n",
    "        'Dp_2m_Avg', 'TaMax_2m', 'TaMin_2m', 'RHMax_2m', 'RHMin_2m', 'HeatIndex_2m_Avg', \n",
    "        'canopy_temp', 'VWC_06', 'VWC_18', 'VWC_30', \n",
    "        'daily_et', 'CWSI', 'SWSI', 'precip_irrig'\n",
    "    ]\n",
    "\n",
    "    # Eliminate duplicate indices and set TIMESTAMP as index\n",
    "    df = df.drop_duplicates().set_index('TIMESTAMP').sort_index()\n",
    "\n",
    "    # Assuming trim_start_end_nans is a predefined function to handle NaN values\n",
    "    df = trim_start_end_nans(df)\n",
    "\n",
    "    # Interpolate missing values\n",
    "    df = df[corr_columns + time_columns].interpolate(method='pchip')\n",
    "    \n",
    "    # run savgol filter with no differentiation an window = 10 to target columns\n",
    "    target_columns = ['VWC_06', 'VWC_18', 'VWC_30']\n",
    "    for column in target_columns:\n",
    "        df[column] = savgol_filter(x=df[column], window_length=20, polyorder=4, deriv=0)\n",
    "        \n",
    "    # testing different transforms\n",
    "    #df['precip_irrig'] = df['precip_irrig'].apply(lambda x: np.log(x) if x > 0 else 0)\n",
    "    df['precip_irrig_log'] = np.log(df['precip_irrig'] + 1)\n",
    "    \n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\bnsoh2\\AppData\\Local\\Temp\\ipykernel_16764\\2830911266.py:16: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "TensorFlow cannot find a GPU!\n",
      "Shape of transformed DataFrame: (820, 28)\n",
      "Shape of transformed DataFrame: (820, 28)\n",
      "Shape of transformed DataFrame: (1055, 28)\n",
      "Shape of transformed DataFrame: (1062, 28)\n",
      "Processing fold 1/5 for DataFrame_0\n",
      "Processing fold 2/5 for DataFrame_0\n",
      "Processing fold 3/5 for DataFrame_0\n",
      "Processing fold 4/5 for DataFrame_0\n",
      "Processing fold 5/5 for DataFrame_0\n",
      "Processing fold 1/5 for DataFrame_1\n",
      "Processing fold 2/5 for DataFrame_1\n",
      "Processing fold 3/5 for DataFrame_1\n",
      "Processing fold 4/5 for DataFrame_1\n",
      "Processing fold 5/5 for DataFrame_1\n",
      "Processing fold 1/5 for DataFrame_2\n",
      "Processing fold 2/5 for DataFrame_2\n",
      "Processing fold 3/5 for DataFrame_2\n",
      "Processing fold 4/5 for DataFrame_2\n",
      "Processing fold 5/5 for DataFrame_2\n",
      "Epoch 1/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.30798906087875366\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.2554037868976593\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.2216852456331253\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.09159483760595322\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.0366375632584095\n",
      "Average validation loss for epoch 1: 0.18266209959983826\n",
      "INFO:tensorflow:Assets written to: ./LSTM\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./LSTM\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at epoch 1 with validation loss: 0.18266209959983826\n",
      "Epoch 2/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.038564011454582214\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.015138220973312855\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.01222072821110487\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.019390946254134178\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.026493920013308525\n",
      "Average validation loss for epoch 2: 0.02236156538128853\n",
      "INFO:tensorflow:Assets written to: ./LSTM\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./LSTM\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at epoch 2 with validation loss: 0.02236156538128853\n",
      "Epoch 3/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.018414659425616264\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.00892320740967989\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.009763178415596485\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.013812348246574402\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.02662850357592106\n",
      "Average validation loss for epoch 3: 0.015508378855884075\n",
      "INFO:tensorflow:Assets written to: ./LSTM\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./LSTM\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at epoch 3 with validation loss: 0.015508378855884075\n",
      "Epoch 4/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.013277637772262096\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.008454856462776661\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.010583318769931793\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.017285482957959175\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.02858845703303814\n",
      "Average validation loss for epoch 4: 0.015637950971722603\n",
      "Epoch 5/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.011612716130912304\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.008599836379289627\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.010864618234336376\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.017498573288321495\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.029367754235863686\n",
      "Average validation loss for epoch 5: 0.015588698908686638\n",
      "Epoch 6/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.010544988326728344\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.008787850849330425\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.010689427144825459\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.017009630799293518\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03083040378987789\n",
      "Average validation loss for epoch 6: 0.015572460368275642\n",
      "Epoch 7/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.009592331014573574\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.009307119995355606\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.011195615865290165\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.01470166351646185\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.02562948502600193\n",
      "Average validation loss for epoch 7: 0.014085243456065655\n",
      "INFO:tensorflow:Assets written to: ./LSTM\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./LSTM\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at epoch 7 with validation loss: 0.014085243456065655\n",
      "Epoch 8/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.009732815437018871\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.017419898882508278\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.02900085784494877\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.021794438362121582\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.024693233892321587\n",
      "Average validation loss for epoch 8: 0.020528249442577362\n",
      "Epoch 9/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.010326256044209003\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.009137192741036415\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.00993222277611494\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.013788111507892609\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.02464907430112362\n",
      "Average validation loss for epoch 9: 0.013566571287810802\n",
      "INFO:tensorflow:Assets written to: ./LSTM\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./LSTM\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at epoch 9 with validation loss: 0.013566571287810802\n",
      "Epoch 10/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.009328033775091171\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.009412790648639202\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.009820633567869663\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.013725328259170055\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.025678003206849098\n",
      "Average validation loss for epoch 10: 0.013592958450317383\n",
      "Epoch 11/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.013419527560472488\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.011854670010507107\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.009761414490640163\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.013463572598993778\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.024218039587140083\n",
      "Average validation loss for epoch 11: 0.014543445780873299\n",
      "Epoch 12/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.018332360312342644\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.016306163743138313\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.011615465395152569\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.013450062833726406\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.023887300863862038\n",
      "Average validation loss for epoch 12: 0.016718272119760513\n",
      "Epoch 13/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.022338099777698517\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.017803175374865532\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.01167327631264925\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.01302326936274767\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.02334464155137539\n",
      "Average validation loss for epoch 13: 0.0176364928483963\n",
      "Epoch 14/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.025647876784205437\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.023817023262381554\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.00895664468407631\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.013534456491470337\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.02417384833097458\n",
      "Average validation loss for epoch 14: 0.019225969910621643\n",
      "Epoch 15/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.021049952134490013\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.0176318921148777\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.012973536737263203\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.014096119441092014\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.023953666910529137\n",
      "Average validation loss for epoch 15: 0.017941033467650414\n",
      "Epoch 16/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.011931371875107288\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.019024398177862167\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.007653991226106882\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.01114253606647253\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03030739165842533\n",
      "Average validation loss for epoch 16: 0.016011938452720642\n",
      "Epoch 17/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.012764316983520985\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.02365107275545597\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.012538383714854717\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.020917808637022972\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.02431453950703144\n",
      "Average validation loss for epoch 17: 0.018837224692106247\n",
      "Epoch 18/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.009897086769342422\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.0099901482462883\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.01830868609249592\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.009249904192984104\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.026075100526213646\n",
      "Average validation loss for epoch 18: 0.014704185537993908\n",
      "Epoch 19/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.320992112159729\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.13408054411411285\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.022076105698943138\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.03138144686818123\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.04196145758032799\n",
      "Average validation loss for epoch 19: 0.11009832471609116\n",
      "Epoch 20/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.024119459092617035\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.026296474039554596\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.015728896483778954\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.012098170816898346\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.025782184675335884\n",
      "Average validation loss for epoch 20: 0.020805036649107933\n",
      "Epoch 21/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.023060912266373634\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.022405236959457397\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.008320342749357224\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.009417143650352955\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.017811214551329613\n",
      "Average validation loss for epoch 21: 0.01620296947658062\n",
      "Epoch 22/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.005730194505304098\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.0085286321118474\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.0048588900826871395\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.009407225996255875\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.020651504397392273\n",
      "Average validation loss for epoch 22: 0.009835289791226387\n",
      "INFO:tensorflow:Assets written to: ./LSTM\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./LSTM\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at epoch 22 with validation loss: 0.009835289791226387\n",
      "Epoch 23/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.010519937612116337\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.011091209016740322\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.003916064742952585\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.011017397977411747\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.022808760404586792\n",
      "Average validation loss for epoch 23: 0.0118706738576293\n",
      "Epoch 24/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.021424921229481697\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.022469179704785347\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.0072481706738471985\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.013742762617766857\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.02191592939198017\n",
      "Average validation loss for epoch 24: 0.01736019179224968\n",
      "Epoch 25/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.037644967436790466\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.022475847974419594\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.012895348481833935\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.012250778265297413\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.023017527535557747\n",
      "Average validation loss for epoch 25: 0.02165689319372177\n",
      "Epoch 26/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.22539599239826202\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.11632750183343887\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.059378039091825485\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.007941300980746746\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.0171473678201437\n",
      "Average validation loss for epoch 26: 0.08523803949356079\n",
      "Epoch 27/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.013773682527244091\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.007740215864032507\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.005418386776000261\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.007374433800578117\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.01803244650363922\n",
      "Average validation loss for epoch 27: 0.010467832908034325\n",
      "Epoch 28/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.021893104538321495\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.009481132961809635\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.003793601179495454\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.009956764988601208\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.01545773446559906\n",
      "Average validation loss for epoch 28: 0.012116467580199242\n",
      "Epoch 29/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.00587086146697402\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.0068878731690347195\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.004711404908448458\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.008432594127953053\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03153535723686218\n",
      "Average validation loss for epoch 29: 0.011487618088722229\n",
      "Epoch 30/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.01835748739540577\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.019594216719269753\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.004454286303371191\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.008616621606051922\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.027041204273700714\n",
      "Average validation loss for epoch 30: 0.015612763352692127\n",
      "Epoch 31/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.026173243299126625\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.026599859818816185\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.011525832116603851\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.009333308786153793\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.024328529834747314\n",
      "Average validation loss for epoch 31: 0.019592154771089554\n",
      "Epoch 32/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.017754090949892998\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.00591761851683259\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.004086736124008894\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.010625242255628109\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.0272050891071558\n",
      "Average validation loss for epoch 32: 0.013117755763232708\n",
      "Epoch 33/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.010891277343034744\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.00689674774184823\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.0035483494866639376\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.011771216988563538\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.017476486042141914\n",
      "Average validation loss for epoch 33: 0.010116815567016602\n",
      "Epoch 34/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.008060192689299583\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.005998373031616211\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.0052786353044211864\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.012625192292034626\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03378411754965782\n",
      "Average validation loss for epoch 34: 0.013149303384125233\n",
      "Epoch 35/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.019059445708990097\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.023538922891020775\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.0070592910051345825\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.008256481029093266\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.034482602030038834\n",
      "Average validation loss for epoch 35: 0.018479347229003906\n",
      "Epoch 36/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.01868012361228466\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.02650591731071472\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.022799259051680565\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.012273629195988178\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03708488866686821\n",
      "Average validation loss for epoch 36: 0.02346876636147499\n",
      "Epoch 37/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.03653658553957939\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01883583702147007\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.005303865764290094\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.008870460093021393\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.028197085484862328\n",
      "Average validation loss for epoch 37: 0.019548768177628517\n",
      "Epoch 38/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.09786032885313034\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.051288798451423645\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.009243488311767578\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.01008541788905859\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.017415279522538185\n",
      "Average validation loss for epoch 38: 0.03717866167426109\n",
      "Epoch 39/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.016434013843536377\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.021785059943795204\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.007964303717017174\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.02429635263979435\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.05826227739453316\n",
      "Average validation loss for epoch 39: 0.025748401880264282\n",
      "Epoch 40/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.019033581018447876\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.03904646262526512\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.019671807065606117\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.012488313019275665\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03463604673743248\n",
      "Average validation loss for epoch 40: 0.0249752439558506\n",
      "Epoch 41/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.3262834846973419\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.2958318293094635\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.05281678959727287\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.03736388310790062\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.22209614515304565\n",
      "Average validation loss for epoch 41: 0.18687842786312103\n",
      "Epoch 42/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.34514880180358887\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.15165983140468597\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.33891698718070984\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.2819285988807678\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.27339985966682434\n",
      "Average validation loss for epoch 42: 0.2782108187675476\n",
      "Epoch 43/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.3584555685520172\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.31147366762161255\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.35634079575538635\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.2204931378364563\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.27407339215278625\n",
      "Average validation loss for epoch 43: 0.30416733026504517\n",
      "Epoch 44/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.45862746238708496\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.4188215732574463\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.30866241455078125\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.22348463535308838\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.2326483130455017\n",
      "Average validation loss for epoch 44: 0.3284488618373871\n",
      "Epoch 45/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.38240930438041687\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.34561339020729065\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.3392564356327057\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.25078925490379333\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.227361261844635\n",
      "Average validation loss for epoch 45: 0.3090859353542328\n",
      "Epoch 46/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.34261202812194824\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.08608024567365646\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.11969111114740372\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.052296072244644165\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.1153440773487091\n",
      "Average validation loss for epoch 46: 0.1432047188282013\n",
      "Epoch 47/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.39852702617645264\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.19101399183273315\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.23319487273693085\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.20828378200531006\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.1754903942346573\n",
      "Average validation loss for epoch 47: 0.2413020133972168\n",
      "Epoch 48/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.3767980635166168\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.07782769203186035\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.1473161280155182\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.08714673668146133\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.02175656147301197\n",
      "Average validation loss for epoch 48: 0.1421690434217453\n",
      "Epoch 49/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.4110420048236847\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.04572248086333275\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.004498261958360672\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.00999231357127428\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03225279226899147\n",
      "Average validation loss for epoch 49: 0.10070157051086426\n",
      "Epoch 50/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.37003517150878906\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.016400815919041634\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.005060879047960043\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.010943610221147537\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03415883705019951\n",
      "Average validation loss for epoch 50: 0.08731986582279205\n",
      "Epoch 51/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0020539213437587023\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.015749042853713036\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.005203618202358484\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.010893379338085651\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.0350433886051178\n",
      "Average validation loss for epoch 51: 0.013788670301437378\n",
      "Epoch 52/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0013919720659032464\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.015937425196170807\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.005436213221400976\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.010532950051128864\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.036099426448345184\n",
      "Average validation loss for epoch 52: 0.013879597187042236\n",
      "Epoch 53/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.004541429691016674\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.018571941182017326\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.005862155929207802\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.010241867043077946\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.040123727172613144\n",
      "Average validation loss for epoch 53: 0.01586822420358658\n",
      "Epoch 54/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0033218369353562593\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.018768327310681343\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.0065480549819767475\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.010267860256135464\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03753390535712242\n",
      "Average validation loss for epoch 54: 0.01528799720108509\n",
      "Epoch 55/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002260028850287199\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.016849840059876442\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.006257286760956049\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.011244247667491436\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03897315263748169\n",
      "Average validation loss for epoch 55: 0.015116912312805653\n",
      "Epoch 56/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0062660048715770245\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.02159600704908371\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.008625517599284649\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.012109006755053997\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.0477595180273056\n",
      "Average validation loss for epoch 56: 0.019271211698651314\n",
      "Epoch 57/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.00914433877915144\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.018876120448112488\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.014133025892078876\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.020852388814091682\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.05512797832489014\n",
      "Average validation loss for epoch 57: 0.023626770824193954\n",
      "Epoch 58/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.005590918008238077\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.018295766785740852\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.009558776393532753\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.015637602657079697\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.04510378837585449\n",
      "Average validation loss for epoch 58: 0.018837371841073036\n",
      "Epoch 59/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.012966156005859375\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.020649230107665062\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.007834142073988914\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.011767853982746601\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.043668877333402634\n",
      "Average validation loss for epoch 59: 0.019377252086997032\n",
      "Epoch 60/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.010989011265337467\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.020634742453694344\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.005661955568939447\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.010717254132032394\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.048521459102630615\n",
      "Average validation loss for epoch 60: 0.01930488459765911\n",
      "Epoch 61/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.01119507011026144\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.020856590941548347\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.013396351598203182\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.014608004130423069\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.04890058934688568\n",
      "Average validation loss for epoch 61: 0.02179132029414177\n",
      "Epoch 62/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.008499945513904095\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.018012162297964096\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.0064427293837070465\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.00921157468110323\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.04639874026179314\n",
      "Average validation loss for epoch 62: 0.01771303080022335\n",
      "Epoch 63/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.008048505522310734\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.018242619931697845\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.01688527502119541\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.014591461978852749\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.052405163645744324\n",
      "Average validation loss for epoch 63: 0.022034604102373123\n",
      "Epoch 64/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.009476830251514912\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.020315922796726227\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.006681285332888365\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.009673125110566616\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.04690632224082947\n",
      "Average validation loss for epoch 64: 0.018610697239637375\n",
      "Epoch 65/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.011010485701262951\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.018979471176862717\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.011470767669379711\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.011785046197474003\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.049305468797683716\n",
      "Average validation loss for epoch 65: 0.020510246977210045\n",
      "Epoch 66/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.007140644360333681\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01725924015045166\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.005881045013666153\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.009030899964272976\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.04434781149029732\n",
      "Average validation loss for epoch 66: 0.016731929033994675\n",
      "Epoch 67/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.010967244394123554\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.018558530136942863\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.009348883293569088\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.012542503885924816\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.044652219861745834\n",
      "Average validation loss for epoch 67: 0.019213875755667686\n",
      "Epoch 68/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.008543622680008411\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.018571406602859497\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.005221636965870857\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.010511357337236404\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.04955419898033142\n",
      "Average validation loss for epoch 68: 0.018480444326996803\n",
      "Epoch 69/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.008919264189898968\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.019575228914618492\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.019267193973064423\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.02118384838104248\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.05264351889491081\n",
      "Average validation loss for epoch 69: 0.02431781031191349\n",
      "Epoch 70/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.006886199116706848\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.019182419404387474\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.006374519318342209\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.01027608010917902\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.04822373017668724\n",
      "Average validation loss for epoch 70: 0.018188590183854103\n",
      "Epoch 71/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.009204857982695103\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.021583842113614082\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.019553737714886665\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.021609492599964142\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.05531584098935127\n",
      "Average validation loss for epoch 71: 0.025453556329011917\n",
      "Epoch 72/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.009605764411389828\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.016386279836297035\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.004922820720821619\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.008069123141467571\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.04030672833323479\n",
      "Average validation loss for epoch 72: 0.01585814356803894\n",
      "Epoch 73/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.011443681083619595\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.02242247760295868\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.011471427045762539\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.017181508243083954\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.036630794405937195\n",
      "Average validation loss for epoch 73: 0.019829977303743362\n",
      "Epoch 74/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.00439936900511384\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.016681669279932976\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.005346391815692186\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.014367564581334591\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.034711603075265884\n",
      "Average validation loss for epoch 74: 0.015101319178938866\n",
      "Epoch 75/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.01751299574971199\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.031297121196985245\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.007064987439662218\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.009699282236397266\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.04542248323559761\n",
      "Average validation loss for epoch 75: 0.022199373692274094\n",
      "Epoch 76/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.007799641694873571\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01931075006723404\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.005224546883255243\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.010111905634403229\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03804587945342064\n",
      "Average validation loss for epoch 76: 0.016098544001579285\n",
      "Epoch 77/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0026687367353588343\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.017116913571953773\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.006321290507912636\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.010913106612861156\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.04349078610539436\n",
      "Average validation loss for epoch 77: 0.01610216684639454\n",
      "Epoch 78/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.003972198348492384\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.016554169356822968\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.006057229358702898\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.011145669035613537\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.0424942784011364\n",
      "Average validation loss for epoch 78: 0.01604470983147621\n",
      "Epoch 79/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.004823233466595411\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.017662737518548965\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.006272545084357262\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.010772372595965862\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.0349477156996727\n",
      "Average validation loss for epoch 79: 0.014895720407366753\n",
      "Epoch 80/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.01022664736956358\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.018442252650856972\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.0036384856794029474\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.009115352295339108\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.04001423344016075\n",
      "Average validation loss for epoch 80: 0.016287395730614662\n",
      "Epoch 81/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.01036797370761633\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.022074168547987938\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.015838731080293655\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.017058664932847023\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.05128200724720955\n",
      "Average validation loss for epoch 81: 0.023324307054281235\n",
      "Epoch 82/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.006111084017902613\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.016629241406917572\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.006224460434168577\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.013280258513987064\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.04744720086455345\n",
      "Average validation loss for epoch 82: 0.01793844997882843\n",
      "Epoch 83/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.012256530113518238\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.028196906670928\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.01867286115884781\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.016969017684459686\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.02080298773944378\n",
      "Average validation loss for epoch 83: 0.019379660487174988\n",
      "Epoch 84/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.12052008509635925\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.007906577549874783\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.017732925713062286\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.022777393460273743\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.0639488473534584\n",
      "Average validation loss for epoch 84: 0.04657716676592827\n",
      "Epoch 85/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.009796726517379284\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.04095926880836487\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.011229153722524643\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.026692168787121773\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.04547062888741493\n",
      "Average validation loss for epoch 85: 0.026829589158296585\n",
      "Epoch 86/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.007602063938975334\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.012926775962114334\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.006290132645517588\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.036289751529693604\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.1818142980337143\n",
      "Average validation loss for epoch 86: 0.04898460581898689\n",
      "Epoch 87/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.3400242328643799\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.27658042311668396\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.2730740010738373\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.18769319355487823\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.1688607931137085\n",
      "Average validation loss for epoch 87: 0.24924655258655548\n",
      "Epoch 88/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.3532524108886719\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.2923724353313446\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.2928924560546875\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.06821798533201218\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.05282973125576973\n",
      "Average validation loss for epoch 88: 0.21191301941871643\n",
      "Epoch 89/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.003501076251268387\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.015568278729915619\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.007574792485684156\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.011312912218272686\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.052143048495054245\n",
      "Average validation loss for epoch 89: 0.01802002266049385\n",
      "Epoch 90/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0033215649891644716\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.015487074851989746\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.02239113859832287\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.019472891464829445\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.05523031949996948\n",
      "Average validation loss for epoch 90: 0.02318059839308262\n",
      "Epoch 91/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002523477654904127\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.012397680431604385\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.00912811141461134\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.012448485940694809\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.05806828662753105\n",
      "Average validation loss for epoch 91: 0.018913209438323975\n",
      "Epoch 92/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0045677293092012405\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01617402769625187\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.02223275788128376\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.019274087622761726\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.0547906719148159\n",
      "Average validation loss for epoch 92: 0.02340785600244999\n",
      "Epoch 93/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.004300745669752359\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.015223979949951172\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.00932572316378355\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.013937041163444519\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.05622014030814171\n",
      "Average validation loss for epoch 93: 0.01980152539908886\n",
      "Epoch 94/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.007010745350271463\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.018719257786870003\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.01848783530294895\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.018129689618945122\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.058728232979774475\n",
      "Average validation loss for epoch 94: 0.024215152487158775\n",
      "Epoch 95/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.00783874373883009\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01985727995634079\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.021095117554068565\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.019127503037452698\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.05531877651810646\n",
      "Average validation loss for epoch 95: 0.024647483602166176\n",
      "Epoch 96/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.006717741955071688\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01705302484333515\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.009653464891016483\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.01656472124159336\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.05761348083615303\n",
      "Average validation loss for epoch 96: 0.02152048610150814\n",
      "Epoch 97/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.008120991289615631\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.020525600761175156\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.015859002247452736\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.018498996272683144\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.05785616859793663\n",
      "Average validation loss for epoch 97: 0.02417215146124363\n",
      "Epoch 98/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.006817432586103678\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01580069027841091\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.007090380415320396\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.016397589817643166\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.05169982090592384\n",
      "Average validation loss for epoch 98: 0.01956118270754814\n",
      "Epoch 99/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.008341397158801556\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.02505841851234436\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.021066248416900635\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.030566180124878883\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.06512060761451721\n",
      "Average validation loss for epoch 99: 0.030030572786927223\n",
      "Epoch 100/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.005635506007820368\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.017289357259869576\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.016719402745366096\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.02784351445734501\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.04670928418636322\n",
      "Average validation loss for epoch 100: 0.022839412093162537\n",
      "Epoch 101/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.009209091775119305\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.02869962900876999\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.0180231723934412\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.012545797042548656\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.0340583436191082\n",
      "Average validation loss for epoch 101: 0.0205072071403265\n",
      "Epoch 102/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0017035654745995998\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.0076733739115297794\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.002695593051612377\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.008429290726780891\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.04319417476654053\n",
      "Average validation loss for epoch 102: 0.012739199213683605\n",
      "Epoch 103/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.004698997363448143\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.018215885385870934\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.011202971450984478\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.012764756567776203\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.053426820784807205\n",
      "Average validation loss for epoch 103: 0.020061885938048363\n",
      "Epoch 104/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.004879670683294535\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.016171498224139214\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.005075323395431042\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.01587235927581787\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.055922750383615494\n",
      "Average validation loss for epoch 104: 0.01958432048559189\n",
      "Epoch 105/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.005859078373759985\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.021496182307600975\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.021104151383042336\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.02049602009356022\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.05811868980526924\n",
      "Average validation loss for epoch 105: 0.02541482448577881\n",
      "Epoch 106/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.006093224510550499\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.016347723081707954\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.0060663106851279736\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.011673332192003727\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.05233245715498924\n",
      "Average validation loss for epoch 106: 0.01850260980427265\n",
      "Epoch 107/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.007253364194184542\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.022566044703125954\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.019873572513461113\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.02165325917303562\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.05676671862602234\n",
      "Average validation loss for epoch 107: 0.025622591376304626\n",
      "Epoch 108/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0032542452681809664\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01280258595943451\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.005964769050478935\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.008536792360246181\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.052407652139663696\n",
      "Average validation loss for epoch 108: 0.0165932085365057\n",
      "Epoch 109/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.008839738555252552\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.022751620039343834\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.020980149507522583\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.030120402574539185\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.06172533333301544\n",
      "Average validation loss for epoch 109: 0.028883447870612144\n",
      "Epoch 110/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.003968851640820503\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.014339831657707691\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.005444636102765799\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.007924799807369709\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.0503334105014801\n",
      "Average validation loss for epoch 110: 0.016402307897806168\n",
      "Epoch 111/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.010842169634997845\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.02508823573589325\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.019869567826390266\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.019989371299743652\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.05880194902420044\n",
      "Average validation loss for epoch 111: 0.026918258517980576\n",
      "Epoch 112/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0028132740408182144\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.013291933573782444\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.004628295544534922\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.007634321693331003\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.04249749705195427\n",
      "Average validation loss for epoch 112: 0.014173063449561596\n",
      "Epoch 113/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.006324993912130594\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01734553463757038\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.006876111030578613\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.011751328594982624\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.05568906292319298\n",
      "Average validation loss for epoch 113: 0.019597405567765236\n",
      "Epoch 114/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0037591794971376657\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.013312660157680511\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.003886277787387371\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.008030439727008343\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.044211823493242264\n",
      "Average validation loss for epoch 114: 0.014640076085925102\n",
      "Epoch 115/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.011055936105549335\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.025071382522583008\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.007292422000318766\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.011556060053408146\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.05733056738972664\n",
      "Average validation loss for epoch 115: 0.02246127463877201\n",
      "Epoch 116/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.003033705987036228\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01430545374751091\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.011542960070073605\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.016971662640571594\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.04711952805519104\n",
      "Average validation loss for epoch 116: 0.018594661727547646\n",
      "Epoch 117/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.013367409817874432\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.02874782495200634\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.010681179352104664\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.0143856480717659\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.049748826771974564\n",
      "Average validation loss for epoch 117: 0.02338617667555809\n",
      "Epoch 118/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0018451855285093188\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.010605054907500744\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.0063144308514893055\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.019901718944311142\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.056704625487327576\n",
      "Average validation loss for epoch 118: 0.019074203446507454\n",
      "Epoch 119/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.007367018610239029\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.025151574984192848\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.01905684545636177\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.018535124137997627\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.05184409022331238\n",
      "Average validation loss for epoch 119: 0.02439093217253685\n",
      "Epoch 120/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.003924171905964613\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.011842381209135056\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.0063528940081596375\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.009118708781898022\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.05809428170323372\n",
      "Average validation loss for epoch 120: 0.01786648854613304\n",
      "Epoch 121/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.006275116000324488\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.02281392551958561\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.02211054600775242\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.030699461698532104\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.054774194955825806\n",
      "Average validation loss for epoch 121: 0.027334649115800858\n",
      "Epoch 122/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.004828399047255516\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.016170622780919075\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.00564691424369812\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.008658410981297493\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.056065987795591354\n",
      "Average validation loss for epoch 122: 0.018274065107107162\n",
      "Epoch 123/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.007296898867934942\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.022811315953731537\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.022944770753383636\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.031389813870191574\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.05598750337958336\n",
      "Average validation loss for epoch 123: 0.028086060658097267\n",
      "Epoch 124/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0020827052649110556\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01454630121588707\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.005821742117404938\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.008033030666410923\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.04980519041419029\n",
      "Average validation loss for epoch 124: 0.01605779305100441\n",
      "Epoch 125/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.006852664053440094\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.023059487342834473\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.017882755026221275\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.014295332133769989\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.05392713472247124\n",
      "Average validation loss for epoch 125: 0.023203473538160324\n",
      "Epoch 126/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.005096935201436281\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.0177158173173666\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.0036938681732863188\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.008137398399412632\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.04866916313767433\n",
      "Average validation loss for epoch 126: 0.016662636771798134\n",
      "Epoch 127/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.011598262004554272\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.023463496938347816\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.011212634854018688\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.01167664211243391\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.030166586861014366\n",
      "Average validation loss for epoch 127: 0.017623525112867355\n",
      "Epoch 128/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0021761306561529636\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.011211966164410114\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.006477667484432459\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.011245128698647022\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.06185181811451912\n",
      "Average validation loss for epoch 128: 0.01859254203736782\n",
      "Epoch 129/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0038445608224719763\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.018468046560883522\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.022430190816521645\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.03114175796508789\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.05999463424086571\n",
      "Average validation loss for epoch 129: 0.027175838127732277\n",
      "Epoch 130/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.007624594494700432\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.015984442085027695\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.0023941239342093468\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.009497012011706829\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.01858418993651867\n",
      "Average validation loss for epoch 130: 0.010816872119903564\n",
      "Epoch 131/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.022053180262446404\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.020144132897257805\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.006101945880800486\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.011113894172012806\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.045669395476579666\n",
      "Average validation loss for epoch 131: 0.02101651020348072\n",
      "Epoch 132/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.008706986904144287\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.022081971168518066\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.005731611978262663\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.00894245970994234\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.0459662564098835\n",
      "Average validation loss for epoch 132: 0.018285857513546944\n",
      "Epoch 133/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.008434715680778027\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.017368009313941002\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.022725751623511314\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.02346629835665226\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.0566452331840992\n",
      "Average validation loss for epoch 133: 0.025728002190589905\n",
      "Epoch 134/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.008670143783092499\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.02083684504032135\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.02244252897799015\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.016146278008818626\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.04856078326702118\n",
      "Average validation loss for epoch 134: 0.02333131618797779\n",
      "Epoch 135/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.006366523448377848\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.019886182621121407\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.013020959682762623\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.021035870537161827\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.06786945462226868\n",
      "Average validation loss for epoch 135: 0.025635797530412674\n",
      "Epoch 136/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.010442615486681461\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.021749453619122505\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.015344101004302502\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.007577081676572561\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.0386819951236248\n",
      "Average validation loss for epoch 136: 0.018759049475193024\n",
      "Epoch 137/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.017714399844408035\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.023726871237158775\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.005452929530292749\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.010517637245357037\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.025697307661175728\n",
      "Average validation loss for epoch 137: 0.016621829941868782\n",
      "Epoch 138/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.011167935095727444\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.024364523589611053\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.006440330296754837\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.03005463443696499\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03653951361775398\n",
      "Average validation loss for epoch 138: 0.021713387221097946\n",
      "Epoch 139/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0021753946784883738\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.019422443583607674\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.018040357157588005\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.02472667582333088\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.021626649424433708\n",
      "Average validation loss for epoch 139: 0.01719830557703972\n",
      "Epoch 140/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.01880546845495701\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.015063569881021976\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.004889647476375103\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.060592059046030045\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.06429114937782288\n",
      "Average validation loss for epoch 140: 0.03272838145494461\n",
      "Epoch 141/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.016552897170186043\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.029667699709534645\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.01871882565319538\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.027958208695054054\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.05436807870864868\n",
      "Average validation loss for epoch 141: 0.029453139752149582\n",
      "Epoch 142/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.27932605147361755\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.24370808899402618\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.24515056610107422\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.03314408287405968\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.09788186103105545\n",
      "Average validation loss for epoch 142: 0.17984212934970856\n",
      "Epoch 143/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.016822559759020805\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.045725155621767044\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.042627643793821335\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.0856063961982727\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.20204739272594452\n",
      "Average validation loss for epoch 143: 0.07856582850217819\n",
      "Epoch 144/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.3337228298187256\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.2739352285861969\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.007213793694972992\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.03408481553196907\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.05300135910511017\n",
      "Average validation loss for epoch 144: 0.14039158821105957\n",
      "Epoch 145/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002927271882072091\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.023695627227425575\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.029251793399453163\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.2188986986875534\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.21461714804172516\n",
      "Average validation loss for epoch 145: 0.0978781133890152\n",
      "Epoch 146/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.3437082767486572\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.2986736297607422\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.2879849374294281\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.21367281675338745\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.20628739893436432\n",
      "Average validation loss for epoch 146: 0.27006539702415466\n",
      "Epoch 147/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.349184513092041\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.30962449312210083\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.29576027393341064\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.21411466598510742\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.196555495262146\n",
      "Average validation loss for epoch 147: 0.27304789423942566\n",
      "Epoch 148/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.3276280164718628\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.09433155506849289\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.046823758631944656\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.16163571178913116\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.16019068658351898\n",
      "Average validation loss for epoch 148: 0.1581219583749771\n",
      "Epoch 149/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.35250139236450195\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.08264821022748947\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.20397774875164032\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.20278091728687286\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.10968399792909622\n",
      "Average validation loss for epoch 149: 0.19031845033168793\n",
      "Epoch 150/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.00376954791136086\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.02086065150797367\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.02257128618657589\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.05161042883992195\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.06214091181755066\n",
      "Average validation loss for epoch 150: 0.03219056501984596\n",
      "Epoch 151/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0074952407740056515\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.023818733170628548\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.12090376019477844\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.04191732034087181\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.05962205305695534\n",
      "Average validation loss for epoch 151: 0.050751425325870514\n",
      "Epoch 152/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.005757467355579138\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.019054263830184937\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.03856571391224861\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.013355091214179993\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.04026105999946594\n",
      "Average validation loss for epoch 152: 0.02339871972799301\n",
      "Epoch 153/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.007753442972898483\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.02176814340054989\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.01968560926616192\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.010935124941170216\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.035425979644060135\n",
      "Average validation loss for epoch 153: 0.019113659858703613\n",
      "Epoch 154/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.007234049495309591\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.02110009640455246\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.01684269867837429\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.008448060601949692\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.02192196063697338\n",
      "Average validation loss for epoch 154: 0.01510937325656414\n",
      "Epoch 155/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.006129998713731766\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01765921339392662\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.01779930852353573\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.009550626389682293\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.022219030186533928\n",
      "Average validation loss for epoch 155: 0.014671635814011097\n",
      "Epoch 156/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.006734342779964209\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.018346788361668587\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.01429351419210434\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.008384838700294495\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.02201252616941929\n",
      "Average validation loss for epoch 156: 0.0139544028788805\n",
      "Epoch 157/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.006557701155543327\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.017063388600945473\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.012558646500110626\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.008288691751658916\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.020660124719142914\n",
      "Average validation loss for epoch 157: 0.013025710359215736\n",
      "Epoch 158/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.007029046770185232\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.018188245594501495\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.004505433142185211\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.00805534329265356\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.02156861312687397\n",
      "Average validation loss for epoch 158: 0.011869336478412151\n",
      "Epoch 159/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.006909383460879326\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.016801273450255394\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.007393496576696634\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.008343184366822243\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.02144448459148407\n",
      "Average validation loss for epoch 159: 0.012178364209830761\n",
      "Epoch 160/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.005633251275867224\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.016209132969379425\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.01122305542230606\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.007915881462395191\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.02167193591594696\n",
      "Average validation loss for epoch 160: 0.01253065187484026\n",
      "Epoch 161/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.004960873629897833\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.013292218558490276\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.013721548020839691\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.0088212164118886\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.026553265750408173\n",
      "Average validation loss for epoch 161: 0.013469824567437172\n",
      "Epoch 162/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.006466247607022524\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.022162189707159996\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.01261082198470831\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.010719428770244122\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.023857736960053444\n",
      "Average validation loss for epoch 162: 0.015163284726440907\n",
      "Epoch 163/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0023049446754157543\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.00957932323217392\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.01695030741393566\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.008736114017665386\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.02901502512395382\n",
      "Average validation loss for epoch 163: 0.013317142613232136\n",
      "Epoch 164/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002110246801748872\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01558203250169754\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.016403287649154663\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.009532704018056393\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.019672386348247528\n",
      "Average validation loss for epoch 164: 0.012660130858421326\n",
      "Epoch 165/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.00781689491122961\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.010748051106929779\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.003392866812646389\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.007232218980789185\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.023555420339107513\n",
      "Average validation loss for epoch 165: 0.010549090802669525\n",
      "Epoch 166/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.004447449930012226\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.013358548283576965\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.01881474256515503\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.010899599641561508\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.02655852399766445\n",
      "Average validation loss for epoch 166: 0.014815772883594036\n",
      "Epoch 167/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.006854673381894827\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.013844448141753674\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.0035968387965112925\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.007555975113064051\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.01832364685833454\n",
      "Average validation loss for epoch 167: 0.010035117156803608\n",
      "Epoch 168/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0049214125610888\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.016457820311188698\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.005314739421010017\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.00848388485610485\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.02109193243086338\n",
      "Average validation loss for epoch 168: 0.011253957636654377\n",
      "Epoch 169/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.004070601891726255\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.010772856883704662\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.00867523718625307\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.006844090763479471\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.025706082582473755\n",
      "Average validation loss for epoch 169: 0.011213773861527443\n",
      "Epoch 170/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.005476916674524546\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.019108325242996216\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.015123528428375721\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.008111250586807728\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.022429393604397774\n",
      "Average validation loss for epoch 170: 0.014049883000552654\n",
      "Epoch 171/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0037542947102338076\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01221457403153181\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.009746423922479153\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.007348005194216967\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.02729114331305027\n",
      "Average validation loss for epoch 171: 0.01207088865339756\n",
      "Epoch 172/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.005458366125822067\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.018030298873782158\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.017142660915851593\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.009080534800887108\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.022356437519192696\n",
      "Average validation loss for epoch 172: 0.01441365946084261\n",
      "Epoch 173/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0025652216281741858\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.0076043568551540375\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.004868862684816122\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.007743753492832184\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.023340439423918724\n",
      "Average validation loss for epoch 173: 0.009224526584148407\n",
      "INFO:tensorflow:Assets written to: ./LSTM\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./LSTM\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at epoch 173 with validation loss: 0.009224526584148407\n",
      "Epoch 174/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.005588842090219259\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01774754375219345\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.016072267666459084\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.009197383187711239\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.023969456553459167\n",
      "Average validation loss for epoch 174: 0.014515099115669727\n",
      "Epoch 175/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0038103994447737932\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.008031962439417839\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.0037505896762013435\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.008799022994935513\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.01811392791569233\n",
      "Average validation loss for epoch 175: 0.00850118137896061\n",
      "INFO:tensorflow:Assets written to: ./LSTM\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./LSTM\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at epoch 175 with validation loss: 0.00850118137896061\n",
      "Epoch 176/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.006251208018511534\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.021872421726584435\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.0160777997225523\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.00887781847268343\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.02849803864955902\n",
      "Average validation loss for epoch 176: 0.016315456479787827\n",
      "Epoch 177/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002301508327946067\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.010311919264495373\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.004316740203648806\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.008423383347690105\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03008621372282505\n",
      "Average validation loss for epoch 177: 0.011087952181696892\n",
      "Epoch 178/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.005211658775806427\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01869938336312771\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.016461985185742378\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.008507497608661652\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.0244255680590868\n",
      "Average validation loss for epoch 178: 0.014661218039691448\n",
      "Epoch 179/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.005217059049755335\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.014078526757657528\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.004834058228880167\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.008288074284791946\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.0216983649879694\n",
      "Average validation loss for epoch 179: 0.01082321722060442\n",
      "Epoch 180/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.004092735704034567\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.013449366204440594\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.009762294590473175\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.007542229723185301\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.02376432903110981\n",
      "Average validation loss for epoch 180: 0.01172219030559063\n",
      "Epoch 181/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.006668950896710157\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.020356586202979088\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.004391415975987911\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.007686752825975418\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.019873270764946938\n",
      "Average validation loss for epoch 181: 0.011795395985245705\n",
      "Epoch 182/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0036928579211235046\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.013765600509941578\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.008691499009728432\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.007210997398942709\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.02072492614388466\n",
      "Average validation loss for epoch 182: 0.010817175731062889\n",
      "Epoch 183/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.00799163244664669\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.02291727624833584\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.004143979866057634\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.0071832574903965\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.020033910870552063\n",
      "Average validation loss for epoch 183: 0.012454011477530003\n",
      "Epoch 184/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002438809024170041\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.005304096732288599\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.004595618695020676\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.006681979168206453\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.028683697804808617\n",
      "Average validation loss for epoch 184: 0.009540840052068233\n",
      "Epoch 185/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.008562600240111351\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.02740943245589733\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.004525500815361738\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.007672020699828863\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.024800539016723633\n",
      "Average validation loss for epoch 185: 0.014594018459320068\n",
      "Epoch 186/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.005687276367098093\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.015353036113083363\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.0052865841425955296\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.007047975901514292\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03890591114759445\n",
      "Average validation loss for epoch 186: 0.014456155709922314\n",
      "Epoch 187/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.007311222609132528\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.02889072336256504\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.003889523446559906\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.007488959934562445\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.01851179264485836\n",
      "Average validation loss for epoch 187: 0.013218444772064686\n",
      "Epoch 188/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.018926242366433144\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.009385383687913418\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.004493982996791601\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.009607709012925625\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.051351696252822876\n",
      "Average validation loss for epoch 188: 0.01875300332903862\n",
      "Epoch 189/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0030429502949118614\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01668543927371502\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.0214384738355875\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.011509586125612259\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.0238474253565073\n",
      "Average validation loss for epoch 189: 0.015304775908589363\n",
      "Epoch 190/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.021518021821975708\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.026861419901251793\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.0058943964540958405\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.00587436044588685\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.020482173189520836\n",
      "Average validation loss for epoch 190: 0.016126075759530067\n",
      "Epoch 191/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.004988240543752909\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.02186717838048935\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.020279817283153534\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.01410570740699768\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.030009062960743904\n",
      "Average validation loss for epoch 191: 0.0182499997317791\n",
      "Epoch 192/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002610129304230213\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01213249284774065\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.010189997963607311\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.006824567914009094\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03246336802840233\n",
      "Average validation loss for epoch 192: 0.01284411083906889\n",
      "Epoch 193/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.009074031375348568\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.0275794118642807\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.005862669553607702\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.008970933966338634\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.02361907809972763\n",
      "Average validation loss for epoch 193: 0.015021225437521935\n",
      "Epoch 194/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0019042246276512742\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.0055707418359816074\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.004619866609573364\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.010683084838092327\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.027318233624100685\n",
      "Average validation loss for epoch 194: 0.010019230656325817\n",
      "Epoch 195/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.010403585620224476\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.02697245590388775\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.005873700138181448\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.01042873878031969\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.02171776257455349\n",
      "Average validation loss for epoch 195: 0.015079247765243053\n",
      "Epoch 196/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.004871023818850517\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.00813827570527792\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.002185752848163247\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.007025302853435278\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03409215435385704\n",
      "Average validation loss for epoch 196: 0.0112625015899539\n",
      "Epoch 197/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.006124962121248245\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.021835600957274437\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.01778780296444893\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.010809297673404217\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.02420930564403534\n",
      "Average validation loss for epoch 197: 0.016153395175933838\n",
      "Epoch 198/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0017388969426974654\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.008483516052365303\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.0046523860655725\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.0087568499147892\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.01779135875403881\n",
      "Average validation loss for epoch 198: 0.008284601382911205\n",
      "INFO:tensorflow:Assets written to: ./LSTM\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./LSTM\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at epoch 198 with validation loss: 0.008284601382911205\n",
      "Epoch 199/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.005144247319549322\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.028767017647624016\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.01916475035250187\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.011149992235004902\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.027841439470648766\n",
      "Average validation loss for epoch 199: 0.018413489684462547\n",
      "Epoch 200/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.007067052181810141\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.011734627187252045\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.0037019681185483932\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.009450588375329971\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.018282070755958557\n",
      "Average validation loss for epoch 200: 0.010047261603176594\n",
      "Epoch 201/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.01283286977559328\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.002871248172596097\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.004026756156235933\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.008253968320786953\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.020677916705608368\n",
      "Average validation loss for epoch 201: 0.009732551872730255\n",
      "Epoch 202/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.009972531348466873\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.014698642306029797\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.002213480416685343\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.00872014183551073\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.01832135207951069\n",
      "Average validation loss for epoch 202: 0.010785229504108429\n",
      "Epoch 203/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0040412177331745625\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.012973384000360966\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.004345387686043978\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.0076834275387227535\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.021602964028716087\n",
      "Average validation loss for epoch 203: 0.010129275731742382\n",
      "Epoch 204/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.007674486842006445\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.011607709340751171\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.003691368969157338\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.00733020668849349\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.019270341843366623\n",
      "Average validation loss for epoch 204: 0.0099148228764534\n",
      "Epoch 205/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0032552285119891167\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.013658788986504078\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.016178572550415993\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.009123559109866619\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.026666423305869102\n",
      "Average validation loss for epoch 205: 0.013776513747870922\n",
      "Epoch 206/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.005954144522547722\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01216860581189394\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.0042005497962236404\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.007131129503250122\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.020173748955130577\n",
      "Average validation loss for epoch 206: 0.009925635531544685\n",
      "Epoch 207/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.005534685682505369\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.017320407554507256\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.019033363088965416\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.012290950864553452\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03642256557941437\n",
      "Average validation loss for epoch 207: 0.01812039501965046\n",
      "Epoch 208/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.006843356415629387\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.017976947128772736\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.009725404903292656\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.0064467513002455235\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.021703431382775307\n",
      "Average validation loss for epoch 208: 0.012539178133010864\n",
      "Epoch 209/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.004662250634282827\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.017438242211937904\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.018293729051947594\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.00875560101121664\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.039050258696079254\n",
      "Average validation loss for epoch 209: 0.017640016973018646\n",
      "Epoch 210/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.007430113852024078\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.019351735711097717\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.004306045360863209\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.00583963468670845\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.035048048943281174\n",
      "Average validation loss for epoch 210: 0.014395114965736866\n",
      "Epoch 211/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.004387321416288614\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.0164924468845129\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.01765311509370804\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.007251288276165724\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.045044612139463425\n",
      "Average validation loss for epoch 211: 0.01816575601696968\n",
      "Epoch 212/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.007059609517455101\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.020504986867308617\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.005280762445181608\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.006659410893917084\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03520217537879944\n",
      "Average validation loss for epoch 212: 0.014941388741135597\n",
      "Epoch 213/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0025691816117614508\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.009534652344882488\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.009272628463804722\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.0069384281523525715\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.04150088131427765\n",
      "Average validation loss for epoch 213: 0.013963153585791588\n",
      "Epoch 214/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.008008070290088654\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.022423287853598595\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.005758379120379686\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.007065262645483017\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.028605898842215538\n",
      "Average validation loss for epoch 214: 0.014372180216014385\n",
      "Epoch 215/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.005639290902763605\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01355806365609169\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.004938881378620863\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.006420718040317297\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.02502262592315674\n",
      "Average validation loss for epoch 215: 0.011115916073322296\n",
      "Epoch 216/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.008559513837099075\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.028307607397437096\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.0048119681887328625\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.0076222545467317104\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.01990010216832161\n",
      "Average validation loss for epoch 216: 0.013840287923812866\n",
      "Epoch 217/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.004764395300298929\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.009223251603543758\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.005030902102589607\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.006285263225436211\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.016425790265202522\n",
      "Average validation loss for epoch 217: 0.008345920592546463\n",
      "Epoch 218/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.004170467145740986\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.020204154774546623\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.01460570190101862\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.009856075048446655\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03435216844081879\n",
      "Average validation loss for epoch 218: 0.016637712717056274\n",
      "Epoch 219/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.004790500272065401\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.011387895792722702\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.011435209773480892\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.007029673550277948\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.02218594402074814\n",
      "Average validation loss for epoch 219: 0.011365844868123531\n",
      "Epoch 220/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.010187922976911068\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.015382825396955013\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.0715310350060463\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.011069752275943756\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.018835371360182762\n",
      "Average validation loss for epoch 220: 0.02540137991309166\n",
      "Epoch 221/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.02432972937822342\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.04712343215942383\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.012124055065214634\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.008729067631065845\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.030110254883766174\n",
      "Average validation loss for epoch 221: 0.02448330819606781\n",
      "Epoch 222/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.008114521391689777\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.024647757411003113\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.018180230632424355\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.01351176481693983\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.016240837052464485\n",
      "Average validation loss for epoch 222: 0.016139021143317223\n",
      "Epoch 223/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.2780328691005707\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.2341558188199997\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.012008510529994965\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.011643870733678341\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.01904127188026905\n",
      "Average validation loss for epoch 223: 0.11097647249698639\n",
      "Epoch 224/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.024923568591475487\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.025715971365571022\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.008589948527514935\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.2008335143327713\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.19141870737075806\n",
      "Average validation loss for epoch 224: 0.09029634296894073\n",
      "Epoch 225/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.15366853773593903\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.29064440727233887\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.13129456341266632\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.16180802881717682\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.13656462728977203\n",
      "Average validation loss for epoch 225: 0.17479601502418518\n",
      "Epoch 226/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.3077050447463989\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.27377599477767944\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.22616052627563477\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.05247745290398598\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.01544311735779047\n",
      "Average validation loss for epoch 226: 0.17511244118213654\n",
      "Epoch 227/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.035061705857515335\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01052780169993639\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.0046277232468128204\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.010035240091383457\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.01868247240781784\n",
      "Average validation loss for epoch 227: 0.01578698679804802\n",
      "Epoch 228/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0029879354406148195\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.009022943675518036\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.005183306988328695\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.0062735010869801044\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.017814135178923607\n",
      "Average validation loss for epoch 228: 0.008256363682448864\n",
      "INFO:tensorflow:Assets written to: ./LSTM\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./LSTM\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at epoch 228 with validation loss: 0.008256363682448864\n",
      "Epoch 229/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.00604754313826561\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.017811646685004234\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.008298373781144619\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.007817871868610382\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.021304870024323463\n",
      "Average validation loss for epoch 229: 0.012256060726940632\n",
      "Epoch 230/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.006812118459492922\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.017198244109749794\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.010247044265270233\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.007402002811431885\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.020761528983712196\n",
      "Average validation loss for epoch 230: 0.012484187260270119\n",
      "Epoch 231/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.007693461608141661\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.026208199560642242\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.013411189429461956\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.008217495866119862\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.022564953193068504\n",
      "Average validation loss for epoch 231: 0.015619060024619102\n",
      "Epoch 232/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.007410289719700813\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.020221835002303123\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.015643272548913956\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.008670743554830551\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.022379130125045776\n",
      "Average validation loss for epoch 232: 0.014865053817629814\n",
      "Epoch 233/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.008282522670924664\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.024366505444049835\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.015052665024995804\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.008051925338804722\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.02226012945175171\n",
      "Average validation loss for epoch 233: 0.015602749772369862\n",
      "Epoch 234/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0077553861774504185\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.017984122037887573\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.009618747048079967\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.007393791805952787\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.020238399505615234\n",
      "Average validation loss for epoch 234: 0.012598088011145592\n",
      "Epoch 235/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.008594614453613758\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.02439303696155548\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.004147976636886597\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.008033092133700848\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.021178260445594788\n",
      "Average validation loss for epoch 235: 0.013269396498799324\n",
      "Epoch 236/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0058035701513290405\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01359544973820448\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.005118522327393293\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.006985826883465052\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.019764522090554237\n",
      "Average validation loss for epoch 236: 0.010253578424453735\n",
      "Epoch 237/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.005983781069517136\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.026753006502985954\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.010769232176244259\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.00796700082719326\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.046267975121736526\n",
      "Average validation loss for epoch 237: 0.019548198208212852\n",
      "Epoch 238/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.008121072314679623\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.02452397346496582\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.014363907277584076\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.006413355469703674\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.018970495089888573\n",
      "Average validation loss for epoch 238: 0.014478561468422413\n",
      "Epoch 239/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.005879154894500971\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.026559771969914436\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.012260504066944122\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.008374041877686977\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.023162515833973885\n",
      "Average validation loss for epoch 239: 0.015247197821736336\n",
      "Epoch 240/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.005348594859242439\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01808810420334339\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.016819432377815247\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.006523247342556715\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.016316087916493416\n",
      "Average validation loss for epoch 240: 0.01261909306049347\n",
      "Epoch 241/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.005090606864541769\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.025203675031661987\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.027226882055401802\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.012731227092444897\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.02688494883477688\n",
      "Average validation loss for epoch 241: 0.01942746713757515\n",
      "Epoch 242/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0096786143258214\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.02055220492184162\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.009657801128923893\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.006427185609936714\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.016407299786806107\n",
      "Average validation loss for epoch 242: 0.012544619850814342\n",
      "Epoch 243/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.007651550695300102\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.02602998912334442\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.0045941416174173355\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.009821626357734203\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.0208999365568161\n",
      "Average validation loss for epoch 243: 0.013799449428915977\n",
      "Epoch 244/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.004498274531215429\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.009873809292912483\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.008134095929563046\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.006311485078185797\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.01748751290142536\n",
      "Average validation loss for epoch 244: 0.009261036291718483\n",
      "Epoch 245/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.005047803279012442\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.023592745885252953\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.014322638511657715\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.014479103498160839\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.04925740882754326\n",
      "Average validation loss for epoch 245: 0.021339941769838333\n",
      "Epoch 246/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.010751304216682911\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.02330007590353489\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.017295248806476593\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.009516561403870583\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.019633634015917778\n",
      "Average validation loss for epoch 246: 0.016099365428090096\n",
      "Epoch 247/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.004124004859477282\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.016220340505242348\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.015419453382492065\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.01053024921566248\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.021521324291825294\n",
      "Average validation loss for epoch 247: 0.013563074171543121\n",
      "Epoch 248/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.005266886204481125\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.010464229620993137\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.0034406110644340515\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.006042157765477896\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.016851961612701416\n",
      "Average validation loss for epoch 248: 0.008413168601691723\n",
      "Epoch 249/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.004806194920092821\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.022075669839978218\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.009023251943290234\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.007309990003705025\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.02046445943415165\n",
      "Average validation loss for epoch 249: 0.012735912576317787\n",
      "Epoch 250/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.006722178775817156\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.019207147881388664\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.011159083805978298\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.0070954239927232265\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.0184796005487442\n",
      "Average validation loss for epoch 250: 0.012532686814665794\n",
      "Epoch 251/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.004817861597985029\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.021705210208892822\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.01276386808604002\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.0073162526823580265\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.04554028436541557\n",
      "Average validation loss for epoch 251: 0.01842869445681572\n",
      "Epoch 252/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.008858706802129745\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.02383728139102459\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.005028656218200922\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.0061882976442575455\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.01891353726387024\n",
      "Average validation loss for epoch 252: 0.012565295211970806\n",
      "Epoch 253/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0033981911838054657\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.012668532319366932\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.005029929801821709\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.007407441735267639\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.020767340436577797\n",
      "Average validation loss for epoch 253: 0.009854286909103394\n",
      "Epoch 254/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.009599252603948116\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.022143207490444183\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.013009182177484035\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.012690170668065548\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.021152272820472717\n",
      "Average validation loss for epoch 254: 0.015718817710876465\n",
      "Epoch 255/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0038142569828778505\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01561619620770216\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.009372877888381481\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.0066431667655706406\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.02017480693757534\n",
      "Average validation loss for epoch 255: 0.01112426072359085\n",
      "Epoch 256/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.005774023476988077\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.023532917723059654\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.017455777153372765\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.01181168481707573\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.020328355953097343\n",
      "Average validation loss for epoch 256: 0.015780551359057426\n",
      "Epoch 257/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0036945445463061333\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.014024394564330578\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.003077590139582753\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.0063342805951833725\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.019666312262415886\n",
      "Average validation loss for epoch 257: 0.00935942493379116\n",
      "Epoch 258/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.006053919438272715\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.021896064281463623\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.013353053480386734\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.007466232869774103\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.021851180121302605\n",
      "Average validation loss for epoch 258: 0.014124090783298016\n",
      "Epoch 259/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.007493697572499514\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.023530585691332817\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.002765226410701871\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.005696153733879328\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.02374023199081421\n",
      "Average validation loss for epoch 259: 0.012645179405808449\n",
      "Epoch 260/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.004076050128787756\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.020404286682605743\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.008175492286682129\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.006855817046016455\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.024190517142415047\n",
      "Average validation loss for epoch 260: 0.012740431353449821\n",
      "Epoch 261/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.006277462001889944\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.027210155501961708\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.008317465893924236\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.006399107631295919\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.017180031165480614\n",
      "Average validation loss for epoch 261: 0.013076844625175\n",
      "Epoch 262/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.003439207561314106\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.022444767877459526\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.005027323495596647\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.007121147587895393\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.018895411863923073\n",
      "Average validation loss for epoch 262: 0.011385572142899036\n",
      "Epoch 263/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.007570523768663406\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.016211725771427155\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.003637114306911826\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.006933330092579126\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.020466113463044167\n",
      "Average validation loss for epoch 263: 0.010963762179017067\n",
      "Epoch 264/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.003205083077773452\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.021066201850771904\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.0327286459505558\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.008259463123977184\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.0205689650028944\n",
      "Average validation loss for epoch 264: 0.017165672034025192\n",
      "Epoch 265/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.00702160969376564\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.02363341487944126\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.007049358915537596\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.006027644500136375\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.02091135084629059\n",
      "Average validation loss for epoch 265: 0.012928674928843975\n",
      "Epoch 266/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.003339247778058052\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.010295169427990913\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.012356705963611603\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.011504348367452621\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.02101021446287632\n",
      "Average validation loss for epoch 266: 0.011701136827468872\n",
      "Epoch 267/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.008656731806695461\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.023244276642799377\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.010486800223588943\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.006790952291339636\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.029797956347465515\n",
      "Average validation loss for epoch 267: 0.01579534448683262\n",
      "Epoch 268/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0017549480544403195\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.017934272065758705\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.04400019720196724\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.006975696887820959\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.021233493462204933\n",
      "Average validation loss for epoch 268: 0.01837972179055214\n",
      "Epoch 269/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.011501808650791645\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.02350483275949955\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.003156062215566635\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.005965829361230135\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.02114981971681118\n",
      "Average validation loss for epoch 269: 0.013055670075118542\n",
      "Epoch 270/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.00204567052423954\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.013939405791461468\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.03440306708216667\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.00690767727792263\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.021804064512252808\n",
      "Average validation loss for epoch 270: 0.015819977968931198\n",
      "Epoch 271/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.010806296020746231\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.02324056625366211\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.0032530268654227257\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.007227800786495209\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.027767427265644073\n",
      "Average validation loss for epoch 271: 0.014459023252129555\n",
      "Epoch 272/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.004431994166225195\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.020866626873612404\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.02084619551897049\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.009844699874520302\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.01976904831826687\n",
      "Average validation loss for epoch 272: 0.015151713974773884\n",
      "Epoch 273/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.006506625562906265\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.02192026376724243\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.013365790247917175\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.013701342046260834\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.031691115349531174\n",
      "Average validation loss for epoch 273: 0.017437027767300606\n",
      "Epoch 274/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0068726204335689545\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.02371750958263874\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.014380197040736675\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.006633041426539421\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.02962302416563034\n",
      "Average validation loss for epoch 274: 0.0162452794611454\n",
      "Epoch 275/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.007575627416372299\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.02289711683988571\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.021181801334023476\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.028903009369969368\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.057565927505493164\n",
      "Average validation loss for epoch 275: 0.027624696493148804\n",
      "Epoch 276/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.00813292432576418\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.026056334376335144\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.0021428782492876053\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.010756753385066986\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.015325414948165417\n",
      "Average validation loss for epoch 276: 0.012482861056923866\n",
      "Epoch 277/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.022856421768665314\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.011851437389850616\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.009734051302075386\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.016602979972958565\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.038505155593156815\n",
      "Average validation loss for epoch 277: 0.01991000771522522\n",
      "Epoch 278/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.013654558919370174\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.03866899013519287\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.023300953209400177\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.01135112065821886\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.1871170997619629\n",
      "Average validation loss for epoch 278: 0.05481854826211929\n",
      "Epoch 279/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.3080829083919525\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.22267794609069824\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.03008800931274891\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.03581373766064644\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.17946381866931915\n",
      "Average validation loss for epoch 279: 0.15522529184818268\n",
      "Epoch 280/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.016309505328536034\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.12632162868976593\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.2556104063987732\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.1831791251897812\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.20379556715488434\n",
      "Average validation loss for epoch 280: 0.1570432484149933\n",
      "Epoch 281/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.3321121335029602\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.15314732491970062\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.019005892798304558\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.20982778072357178\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.09911652654409409\n",
      "Average validation loss for epoch 281: 0.16264192759990692\n",
      "Epoch 282/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.023663712665438652\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.03976871073246002\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.04141514003276825\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.14848987758159637\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.034766387194395065\n",
      "Average validation loss for epoch 282: 0.05762076377868652\n",
      "Epoch 283/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.029574783518910408\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.06905952841043472\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.09480589628219604\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.0636855810880661\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03396577015519142\n",
      "Average validation loss for epoch 283: 0.05821831151843071\n",
      "Epoch 284/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0048145512118935585\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.021650725975632668\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.02931438945233822\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.12205350399017334\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03339184448122978\n",
      "Average validation loss for epoch 284: 0.04224500432610512\n",
      "Epoch 285/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.005812063813209534\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.022877229377627373\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.020846256986260414\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.11504682153463364\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.028402673080563545\n",
      "Average validation loss for epoch 285: 0.03859701007604599\n",
      "Epoch 286/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.00565392104908824\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.021066447719931602\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.02164893038570881\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.11794191598892212\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.022195443511009216\n",
      "Average validation loss for epoch 286: 0.037701331079006195\n",
      "Epoch 287/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.005682958289980888\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.020424803718924522\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.020788567140698433\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.07866091281175613\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.029326440766453743\n",
      "Average validation loss for epoch 287: 0.030976736918091774\n",
      "Epoch 288/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0055374279618263245\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.021226083859801292\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.020327484235167503\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.06158560514450073\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.021510856226086617\n",
      "Average validation loss for epoch 288: 0.026037489995360374\n",
      "Epoch 289/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.005316108465194702\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.020566577091813087\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.019480042159557343\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.058283817023038864\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.021956073120236397\n",
      "Average validation loss for epoch 289: 0.02512052282691002\n",
      "Epoch 290/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0059438105672597885\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.020777275785803795\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.019965624436736107\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.0722169503569603\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.024770701304078102\n",
      "Average validation loss for epoch 290: 0.028734872117638588\n",
      "Epoch 291/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.006028895732015371\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.022400418296456337\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.018803652375936508\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.032291073352098465\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.02258407510817051\n",
      "Average validation loss for epoch 291: 0.020421622321009636\n",
      "Epoch 292/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.005644902121275663\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.02119840681552887\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.019083736464381218\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.0074756755493581295\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.020020755007863045\n",
      "Average validation loss for epoch 292: 0.014684694819152355\n",
      "Epoch 293/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.005858883261680603\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.020806675776839256\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.018703065812587738\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.04189012572169304\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.022611627355217934\n",
      "Average validation loss for epoch 293: 0.021974075585603714\n",
      "Epoch 294/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.00570873124524951\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.020211102440953255\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.019487833604216576\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.017353815957903862\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.02317533828318119\n",
      "Average validation loss for epoch 294: 0.017187364399433136\n",
      "Epoch 295/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.006084761116653681\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.02254592813551426\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.016652343794703484\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.00816348660737276\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.022073080763220787\n",
      "Average validation loss for epoch 295: 0.015103919431567192\n",
      "Epoch 296/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0061076246201992035\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.021268337965011597\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.017979400232434273\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.007608325686305761\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.022981440648436546\n",
      "Average validation loss for epoch 296: 0.015189026482403278\n",
      "Epoch 297/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.006187402177602053\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.02175789140164852\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.019554419443011284\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.040574342012405396\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.02795233763754368\n",
      "Average validation loss for epoch 297: 0.02320527844130993\n",
      "Epoch 298/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0063615404069423676\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.022117778658866882\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.011414807289838791\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.007184593006968498\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.026189476251602173\n",
      "Average validation loss for epoch 298: 0.014653639867901802\n",
      "Epoch 299/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.007254533935338259\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.02358558215200901\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.015022226609289646\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.008201071061193943\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.02739829383790493\n",
      "Average validation loss for epoch 299: 0.01629234105348587\n",
      "Epoch 300/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0059045846574008465\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.021663911640644073\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.011010296642780304\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.007043598685413599\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.0231598112732172\n",
      "Average validation loss for epoch 300: 0.013756440952420235\n",
      "Epoch 301/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.007424152921885252\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.02462499588727951\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.01914631389081478\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.013877873308956623\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.0315505713224411\n",
      "Average validation loss for epoch 301: 0.019324783235788345\n",
      "Epoch 302/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.005672310013324022\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.022860711440443993\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.016679001972079277\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.006495253648608923\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.024625733494758606\n",
      "Average validation loss for epoch 302: 0.01526660192757845\n",
      "Epoch 303/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.009236926212906837\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.026105163618922234\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.013618570752441883\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.009295125491917133\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.030089063569903374\n",
      "Average validation loss for epoch 303: 0.017668969929218292\n",
      "Epoch 304/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.005941741168498993\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.02295500785112381\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.01815226674079895\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.007199691142886877\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.025870025157928467\n",
      "Average validation loss for epoch 304: 0.016023745760321617\n",
      "Epoch 305/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.007912621833384037\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.028344592079520226\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.0035039307549595833\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.00773996626958251\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.029585110023617744\n",
      "Average validation loss for epoch 305: 0.015417243354022503\n",
      "Epoch 306/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.006899524480104446\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.026446321979165077\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.0042731501162052155\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.006002879235893488\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.017789172008633614\n",
      "Average validation loss for epoch 306: 0.012282210402190685\n",
      "Epoch 307/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0067433244548738\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.0278319139033556\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.003955889958888292\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.007663465570658445\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.027544276788830757\n",
      "Average validation loss for epoch 307: 0.014747774228453636\n",
      "Epoch 308/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.006675179582089186\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.027252068743109703\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.010866567492485046\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.007075998932123184\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.024559445679187775\n",
      "Average validation loss for epoch 308: 0.015285852365195751\n",
      "Epoch 309/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.006124634295701981\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.025218576192855835\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.012632896192371845\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.008480963297188282\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.02990618906915188\n",
      "Average validation loss for epoch 309: 0.016472650691866875\n",
      "Epoch 310/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.006349195260554552\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.023357508704066277\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.008190867491066456\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.006367105524986982\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.016349244862794876\n",
      "Average validation loss for epoch 310: 0.012122784741222858\n",
      "Epoch 311/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.004677033517509699\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.02102472633123398\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.012458429671823978\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.00812553334981203\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.023647094145417213\n",
      "Average validation loss for epoch 311: 0.013986563310027122\n",
      "Epoch 312/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.006520546972751617\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.021278297528624535\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.007238471414893866\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.0068499017506837845\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.01860961876809597\n",
      "Average validation loss for epoch 312: 0.012099367566406727\n",
      "Epoch 313/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.005024367943406105\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.02116583287715912\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.01717349700629711\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.01894502528011799\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.033167753368616104\n",
      "Average validation loss for epoch 313: 0.019095296040177345\n",
      "Epoch 314/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.005247829016298056\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.019511213526129723\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.017351137474179268\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.007866285741329193\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.027961308136582375\n",
      "Average validation loss for epoch 314: 0.01558755524456501\n",
      "Epoch 315/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.006004836410284042\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.023627812042832375\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.019076040014624596\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.02785387448966503\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.038470059633255005\n",
      "Average validation loss for epoch 315: 0.02300652489066124\n",
      "Epoch 316/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.00559777207672596\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.021909864619374275\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.019613979384303093\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.007633992936462164\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.01944883167743683\n",
      "Average validation loss for epoch 316: 0.014840887859463692\n",
      "Epoch 317/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.004859356675297022\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.021544931456446648\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.01834980584681034\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.030200501903891563\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.02630358189344406\n",
      "Average validation loss for epoch 317: 0.02025163546204567\n",
      "Epoch 318/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.005794832948595285\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.022480487823486328\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.01603206992149353\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.006943269167095423\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.026068514212965965\n",
      "Average validation loss for epoch 318: 0.015463834628462791\n",
      "Epoch 319/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0051290602423250675\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.022291487082839012\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.01903746835887432\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.03424184396862984\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.026469282805919647\n",
      "Average validation loss for epoch 319: 0.02143382839858532\n",
      "Epoch 320/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.00579327205196023\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.023609066382050514\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.009044154547154903\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.007111756596714258\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.023500895127654076\n",
      "Average validation loss for epoch 320: 0.013811829499900341\n",
      "Epoch 321/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.003856263356283307\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.02131522446870804\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.01765601523220539\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.007856136187911034\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.0306283887475729\n",
      "Average validation loss for epoch 321: 0.01626240648329258\n",
      "Epoch 322/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.007253529969602823\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.029563546180725098\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.014141286723315716\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.007092555519193411\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.01920274831354618\n",
      "Average validation loss for epoch 322: 0.015450733713805676\n",
      "Epoch 323/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0043665263801813126\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.02613879181444645\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.017905354499816895\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.00907799694687128\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.028261823579669\n",
      "Average validation loss for epoch 323: 0.017150098457932472\n",
      "Epoch 324/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.009737289510667324\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.029492998495697975\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.00964199285954237\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.007716676685959101\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.025846397504210472\n",
      "Average validation loss for epoch 324: 0.01648707129061222\n",
      "Epoch 325/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.004710724111646414\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.022170035168528557\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.01682968996465206\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.00879670586436987\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.019183620810508728\n",
      "Average validation loss for epoch 325: 0.014338155277073383\n",
      "Epoch 326/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.005410069599747658\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.022180885076522827\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.019274577498435974\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.00995913427323103\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.036894068121910095\n",
      "Average validation loss for epoch 326: 0.01874374784529209\n",
      "Epoch 327/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0066621736623346806\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.02281126193702221\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.019211387261748314\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.034956254065036774\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.021557895466685295\n",
      "Average validation loss for epoch 327: 0.021039795130491257\n",
      "Epoch 328/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.004405161365866661\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.018045304343104362\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.016440564766526222\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.009576135315001011\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.022321000695228577\n",
      "Average validation loss for epoch 328: 0.014157633297145367\n",
      "Epoch 329/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.005368519574403763\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.020084351301193237\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.012564475648105145\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.008234928362071514\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.02176482044160366\n",
      "Average validation loss for epoch 329: 0.013603419065475464\n",
      "Epoch 330/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.005606757011264563\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.021266723051667213\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.019576095044612885\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.008982201106846333\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.025799458846449852\n",
      "Average validation loss for epoch 330: 0.016246248036623\n",
      "Epoch 331/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.007151945028454065\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.02380087785422802\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.01556828711181879\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.02168760448694229\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.021418096497654915\n",
      "Average validation loss for epoch 331: 0.017925361171364784\n",
      "Epoch 332/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.005609745625406504\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.021110141649842262\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.021305924281477928\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.04293615743517876\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.02059594728052616\n",
      "Average validation loss for epoch 332: 0.022311581298708916\n",
      "Epoch 333/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.005203357897698879\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.020369797945022583\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.02000705897808075\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.01250533014535904\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.022419938817620277\n",
      "Average validation loss for epoch 333: 0.01610109582543373\n",
      "Epoch 334/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.006078692618757486\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.022053079679608345\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.020478632301092148\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.026172533631324768\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.019954247400164604\n",
      "Average validation loss for epoch 334: 0.018947437405586243\n",
      "Epoch 335/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.005687337834388018\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.021259769797325134\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.02051996998488903\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.0240200012922287\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.021359920501708984\n",
      "Average validation loss for epoch 335: 0.018569398671388626\n",
      "Epoch 336/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.006511332932859659\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.0232724379748106\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.020450979471206665\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.0377366878092289\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.019510610029101372\n",
      "Average validation loss for epoch 336: 0.02149640955030918\n",
      "Epoch 337/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.005869223270565271\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.021549029275774956\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.015289503149688244\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.017028337344527245\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.036299753934144974\n",
      "Average validation loss for epoch 337: 0.019207170233130455\n",
      "Epoch 338/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.006464909762144089\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.021274512633681297\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.019765688106417656\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.0653725191950798\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.015289629809558392\n",
      "Average validation loss for epoch 338: 0.025633450597524643\n",
      "Epoch 339/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0033085772302001715\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01929982751607895\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.01542662177234888\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.12212574481964111\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.16444559395313263\n",
      "Average validation loss for epoch 339: 0.06492127478122711\n",
      "Epoch 340/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.00634000264108181\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.027148989960551262\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.03485895320773125\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.02748878300189972\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.07290706038475037\n",
      "Average validation loss for epoch 340: 0.03374875709414482\n",
      "Epoch 341/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.020780008286237717\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.053859319537878036\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.00488370331004262\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.015436557121574879\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.022248804569244385\n",
      "Average validation loss for epoch 341: 0.023441679775714874\n",
      "Epoch 342/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.028651287779211998\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.02099677175283432\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.006430251989513636\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.02005971223115921\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.025053486227989197\n",
      "Average validation loss for epoch 342: 0.020238302648067474\n",
      "Epoch 343/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.022300848737359047\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.014684546738862991\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.004781524185091257\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.015844181180000305\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.017298175022006035\n",
      "Average validation loss for epoch 343: 0.014981855638325214\n",
      "Epoch 344/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.011197502724826336\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.013596732169389725\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.001364532858133316\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.0066683534532785416\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.031164640560746193\n",
      "Average validation loss for epoch 344: 0.012798352167010307\n",
      "Epoch 345/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.006688547786325216\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01932716742157936\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.005056348163634539\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.008240113966166973\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.030352070927619934\n",
      "Average validation loss for epoch 345: 0.013932849280536175\n",
      "Epoch 346/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.007181195076555014\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.019352512434124947\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.01006699725985527\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.0103908721357584\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.04013536870479584\n",
      "Average validation loss for epoch 346: 0.01742538996040821\n",
      "Epoch 347/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.004593762569129467\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01959354244172573\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.017984643578529358\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.01104478444904089\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.035260725766420364\n",
      "Average validation loss for epoch 347: 0.017695492133498192\n",
      "Epoch 348/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.006293380167335272\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.019227514043450356\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.01829294115304947\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.023170912638306618\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.04303170368075371\n",
      "Average validation loss for epoch 348: 0.022003289312124252\n",
      "Epoch 349/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0044481768272817135\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.020029516890645027\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.020728806033730507\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.014436803758144379\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.034955959767103195\n",
      "Average validation loss for epoch 349: 0.018919851630926132\n",
      "Epoch 350/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0047928825952112675\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.019942035898566246\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.021891877055168152\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.02244003303349018\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.04859103634953499\n",
      "Average validation loss for epoch 350: 0.02353157475590706\n",
      "Epoch 351/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.004195038694888353\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.02077086642384529\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.021604878827929497\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.033715177327394485\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.04660738632082939\n",
      "Average validation loss for epoch 351: 0.025378670543432236\n",
      "Epoch 352/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.005160306580364704\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.019873084500432014\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.022645888850092888\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.033681176602840424\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.042278531938791275\n",
      "Average validation loss for epoch 352: 0.024727797135710716\n",
      "Epoch 353/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.004796598572283983\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.019762834534049034\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.021011972799897194\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.016969969496130943\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.040965065360069275\n",
      "Average validation loss for epoch 353: 0.02070128731429577\n",
      "Epoch 354/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.00498673552647233\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01820966601371765\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.018716074526309967\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.01987544447183609\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.0428876169025898\n",
      "Average validation loss for epoch 354: 0.02093510702252388\n",
      "Epoch 355/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.004435874987393618\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.017852649092674255\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.021013028919696808\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.02034854330122471\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.044836267828941345\n",
      "Average validation loss for epoch 355: 0.0216972716152668\n",
      "Epoch 356/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.005880538374185562\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.02141161821782589\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.018930228427052498\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.0209516491740942\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03641977161169052\n",
      "Average validation loss for epoch 356: 0.020718760788440704\n",
      "Epoch 357/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.004765242338180542\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.020891951397061348\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.019650699570775032\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.011609046719968319\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.02488613687455654\n",
      "Average validation loss for epoch 357: 0.016360614448785782\n",
      "Epoch 358/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.005323132034391165\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.02087255008518696\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.02071792632341385\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.02451387234032154\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.054335374385118484\n",
      "Average validation loss for epoch 358: 0.025152569636702538\n",
      "Epoch 359/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.003988851327449083\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.021062463521957397\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.020746953785419464\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.02957041561603546\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.05303266644477844\n",
      "Average validation loss for epoch 359: 0.025680270045995712\n",
      "Epoch 360/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.006068885792046785\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.025288188830018044\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.019247040152549744\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.01817101426422596\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.04424840584397316\n",
      "Average validation loss for epoch 360: 0.02260470762848854\n",
      "Epoch 361/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.004592005629092455\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.023194191977381706\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.020243005827069283\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.017979446798563004\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.0385698638856411\n",
      "Average validation loss for epoch 361: 0.020915701985359192\n",
      "Epoch 362/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.005272259470075369\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.023178549483418465\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.01695477031171322\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.00871084351092577\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.034844376146793365\n",
      "Average validation loss for epoch 362: 0.01779215969145298\n",
      "Epoch 363/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.007930298335850239\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.022653304040431976\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.013100323267281055\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.017548272386193275\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.05055731162428856\n",
      "Average validation loss for epoch 363: 0.02235790155827999\n",
      "Epoch 364/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0044270777143538\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.024740973487496376\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.021231159567832947\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.017621874809265137\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.04315755143761635\n",
      "Average validation loss for epoch 364: 0.022235726937651634\n",
      "Epoch 365/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.005908655002713203\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.022821536287665367\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.02001604251563549\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.028154077008366585\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.04706631228327751\n",
      "Average validation loss for epoch 365: 0.024793323129415512\n",
      "Epoch 366/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.00345637951977551\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.02061156928539276\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.02217787504196167\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.016055967658758163\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.04213899374008179\n",
      "Average validation loss for epoch 366: 0.020888157188892365\n",
      "Epoch 367/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.005715403705835342\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.020835256204009056\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.01987382024526596\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.008471649140119553\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.02742462046444416\n",
      "Average validation loss for epoch 367: 0.016464149579405785\n",
      "Epoch 368/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0032327743247151375\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01801416091620922\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.019974688068032265\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.01857493817806244\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.04529151692986488\n",
      "Average validation loss for epoch 368: 0.021017616614699364\n",
      "Epoch 369/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.005620410665869713\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.022280411794781685\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.020570510998368263\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.02371070347726345\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.04579600319266319\n",
      "Average validation loss for epoch 369: 0.02359560690820217\n",
      "Epoch 370/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0036535903345793486\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.0183669775724411\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.02185896597802639\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.02117694355547428\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.04475116729736328\n",
      "Average validation loss for epoch 370: 0.021961528807878494\n",
      "Epoch 371/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.004545462783426046\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01915033347904682\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.020459646359086037\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.018560990691184998\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.032869867980480194\n",
      "Average validation loss for epoch 371: 0.019117260351777077\n",
      "Epoch 372/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.004022353794425726\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.015685684978961945\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.020222468301653862\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.01731588877737522\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03847937285900116\n",
      "Average validation loss for epoch 372: 0.01914515346288681\n",
      "Epoch 373/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0043260385282337666\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.02024339698255062\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.02030683122575283\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.009745349176228046\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.0354347862303257\n",
      "Average validation loss for epoch 373: 0.01801128126680851\n",
      "Epoch 374/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.006554485764354467\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.0199932511895895\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.019621185958385468\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.021026097238063812\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.039577022194862366\n",
      "Average validation loss for epoch 374: 0.02135440893471241\n",
      "Epoch 375/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0045995344407856464\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.02350960113108158\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.014807467348873615\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.01406427938491106\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.014603744260966778\n",
      "Average validation loss for epoch 375: 0.014316925778985023\n",
      "Epoch 376/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0034687563311308622\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.007760647218674421\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.005806736648082733\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.04792900010943413\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.05225108191370964\n",
      "Average validation loss for epoch 376: 0.023443246260285378\n",
      "Epoch 377/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.007198886945843697\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.033697038888931274\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.01638183556497097\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.01216048002243042\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.023912839591503143\n",
      "Average validation loss for epoch 377: 0.0186702162027359\n",
      "Epoch 378/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.001789771136827767\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.017846141010522842\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.01993030123412609\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.0255908016115427\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.05723518133163452\n",
      "Average validation loss for epoch 378: 0.02447843924164772\n",
      "Epoch 379/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.004162884317338467\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.020827610045671463\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.021526901051402092\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.04962271451950073\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.049062635749578476\n",
      "Average validation loss for epoch 379: 0.02904054895043373\n",
      "Epoch 380/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.004749290179461241\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01815793663263321\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.011164329014718533\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.011834396980702877\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.024910690262913704\n",
      "Average validation loss for epoch 380: 0.01416332833468914\n",
      "Epoch 381/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.004672391340136528\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.020151397213339806\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.020724749192595482\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.0217325109988451\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.04274500533938408\n",
      "Average validation loss for epoch 381: 0.02200520969927311\n",
      "Epoch 382/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.007314789574593306\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.02045048028230667\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.01718093641102314\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.023307988420128822\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03194421902298927\n",
      "Average validation loss for epoch 382: 0.02003968320786953\n",
      "Epoch 383/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002762644551694393\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.017500026151537895\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.021631931886076927\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.04831533506512642\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.06086333468556404\n",
      "Average validation loss for epoch 383: 0.03021465241909027\n",
      "Epoch 384/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.00641033286228776\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.024435020983219147\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.02264476753771305\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.021329117938876152\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.020753972232341766\n",
      "Average validation loss for epoch 384: 0.019114641472697258\n",
      "Epoch 385/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0022004388738423586\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01570628397166729\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.020435459911823273\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.012595762498676777\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03803533688187599\n",
      "Average validation loss for epoch 385: 0.0177946574985981\n",
      "Epoch 386/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.003867930732667446\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.02063952572643757\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.021471960470080376\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.01329217478632927\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03852333873510361\n",
      "Average validation loss for epoch 386: 0.019558986648917198\n",
      "Epoch 387/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.005650647450238466\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.016765587031841278\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.02007570117712021\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.01050278265029192\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.029738759621977806\n",
      "Average validation loss for epoch 387: 0.016546694561839104\n",
      "Epoch 388/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.004527245182543993\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.016545502468943596\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.0029553144704550505\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.009541473351418972\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.04324895143508911\n",
      "Average validation loss for epoch 388: 0.015363696031272411\n",
      "Epoch 389/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0026372356805950403\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.012846135534346104\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.021331066265702248\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.024565434083342552\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.023564031347632408\n",
      "Average validation loss for epoch 389: 0.016988780349493027\n",
      "Epoch 390/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.004645739682018757\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.02282404713332653\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.010802251286804676\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.006714408751577139\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.024768829345703125\n",
      "Average validation loss for epoch 390: 0.013951053842902184\n",
      "Epoch 391/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.004400916863232851\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.0235496386885643\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.022597208619117737\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.0784500315785408\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03943586349487305\n",
      "Average validation loss for epoch 391: 0.03368673473596573\n",
      "Epoch 392/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002477301750332117\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.007455842569470406\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.004252464044839144\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.013004467822611332\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.035333748906850815\n",
      "Average validation loss for epoch 392: 0.012504765763878822\n",
      "Epoch 393/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.010160129517316818\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.03294651582837105\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.0309233870357275\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.027530275285243988\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.06990742683410645\n",
      "Average validation loss for epoch 393: 0.03429354727268219\n",
      "Epoch 394/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002500890986993909\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.11196368932723999\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.014717690646648407\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.13520874083042145\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.04051881283521652\n",
      "Average validation loss for epoch 394: 0.06098196655511856\n",
      "Epoch 395/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.17848807573318481\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.26463714241981506\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.25599491596221924\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.06142592057585716\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.06388633698225021\n",
      "Average validation loss for epoch 395: 0.1648864895105362\n",
      "Epoch 396/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.02056163363158703\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.04280494526028633\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.07068154215812683\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.18232470750808716\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.17201171815395355\n",
      "Average validation loss for epoch 396: 0.09767691045999527\n",
      "Epoch 397/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.26696911454200745\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.23977141082286835\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.23642520606517792\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.032274145632982254\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.02487490512430668\n",
      "Average validation loss for epoch 397: 0.16006295382976532\n",
      "Epoch 398/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.29778382182121277\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.25927653908729553\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.25999656319618225\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.193131685256958\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.1889815330505371\n",
      "Average validation loss for epoch 398: 0.2398340255022049\n",
      "Epoch 399/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.29395249485969543\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.2663050591945648\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.2630155086517334\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.18305255472660065\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.178858682513237\n",
      "Average validation loss for epoch 399: 0.23703685402870178\n",
      "Epoch 400/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.2774682939052582\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.25484564900398254\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.25653979182243347\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.19818167388439178\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.15213580429553986\n",
      "Average validation loss for epoch 400: 0.22783425450325012\n",
      "Epoch 401/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.07195403426885605\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.26689276099205017\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.1872682422399521\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.05984184145927429\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.09097782522439957\n",
      "Average validation loss for epoch 401: 0.13538695871829987\n",
      "Epoch 402/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.07704269140958786\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.27094563841819763\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.0368611179292202\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.012984705157577991\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.016865352168679237\n",
      "Average validation loss for epoch 402: 0.08293990045785904\n",
      "Epoch 403/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002273891121149063\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.05184389278292656\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.01424268539994955\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.028996460139751434\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.018815813586115837\n",
      "Average validation loss for epoch 403: 0.023234549909830093\n",
      "Epoch 404/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002330529736354947\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01849217526614666\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.014088251627981663\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.014895320869982243\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.016880858689546585\n",
      "Average validation loss for epoch 404: 0.013337427750229836\n",
      "Epoch 405/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0023830083664506674\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.017397191375494003\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.013579624705016613\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.036798667162656784\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.017644623294472694\n",
      "Average validation loss for epoch 405: 0.017560623586177826\n",
      "Epoch 406/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0026291764806956053\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.016021622344851494\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.013471520505845547\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.0559963621199131\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.01764974184334278\n",
      "Average validation loss for epoch 406: 0.021153684705495834\n",
      "Epoch 407/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002618178026750684\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.015408177860081196\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.013590124435722828\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.052424147725105286\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.01849195547401905\n",
      "Average validation loss for epoch 407: 0.020506516098976135\n",
      "Epoch 408/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002868802985176444\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.013804667629301548\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.013390193693339825\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.05123221501708031\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.01811925508081913\n",
      "Average validation loss for epoch 408: 0.01988302543759346\n",
      "Epoch 409/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002812631195411086\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.014306123368442059\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.013761614449322224\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.05901331827044487\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.018068449571728706\n",
      "Average validation loss for epoch 409: 0.021592427045106888\n",
      "Epoch 410/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002615788020193577\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.015819061547517776\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.013736267574131489\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.03975236415863037\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.018329143524169922\n",
      "Average validation loss for epoch 410: 0.018050525337457657\n",
      "Epoch 411/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0026596442330628633\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.013211815617978573\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.012601551599800587\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.053013090044260025\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.01758589595556259\n",
      "Average validation loss for epoch 411: 0.019814400002360344\n",
      "Epoch 412/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0026006074622273445\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.015343982726335526\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.01471457164734602\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.060924116522073746\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.017909595742821693\n",
      "Average validation loss for epoch 412: 0.022298574447631836\n",
      "Epoch 413/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0025278462562710047\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.013196933083236217\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.013223634101450443\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.05438151955604553\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.01795666478574276\n",
      "Average validation loss for epoch 413: 0.020257320255041122\n",
      "Epoch 414/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002492444356903434\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01480113621801138\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.013937919400632381\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.06087839975953102\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.017626924440264702\n",
      "Average validation loss for epoch 414: 0.021947365254163742\n",
      "Epoch 415/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002573853125795722\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.013526532799005508\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.012490104883909225\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.06324028223752975\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.01826935075223446\n",
      "Average validation loss for epoch 415: 0.022020025178790092\n",
      "Epoch 416/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0026665404438972473\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.015699712559580803\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.014050539582967758\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.0722518339753151\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.016912532970309258\n",
      "Average validation loss for epoch 416: 0.02431623265147209\n",
      "Epoch 417/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0027456050738692284\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.014312215149402618\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.013504880480468273\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.09064269810914993\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.017687691375613213\n",
      "Average validation loss for epoch 417: 0.027778619900345802\n",
      "Epoch 418/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.00289342924952507\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01678611896932125\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.013590849004685879\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.06259968131780624\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.01613251119852066\n",
      "Average validation loss for epoch 418: 0.022400517016649246\n",
      "Epoch 419/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0026221212465316057\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.014138140715658665\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.019404122605919838\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.10010755062103271\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.019954673945903778\n",
      "Average validation loss for epoch 419: 0.031245321035385132\n",
      "Epoch 420/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002621019259095192\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.018191685900092125\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.025166237726807594\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.06821554154157639\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.026761546730995178\n",
      "Average validation loss for epoch 420: 0.028191205114126205\n",
      "Epoch 421/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002473971340805292\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.015567396767437458\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.01468982920050621\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.1319291740655899\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.016355423256754875\n",
      "Average validation loss for epoch 421: 0.036203157156705856\n",
      "Epoch 422/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0022504664957523346\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01633368246257305\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.015372593887150288\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.14045585691928864\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03018270432949066\n",
      "Average validation loss for epoch 422: 0.04091906175017357\n",
      "Epoch 423/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002364197513088584\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01703835465013981\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.011822606436908245\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.010519924573600292\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.013961846940219402\n",
      "Average validation loss for epoch 423: 0.011141386814415455\n",
      "Epoch 424/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0028358586132526398\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.019849887117743492\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.012097607366740704\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.006021620240062475\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.013027352280914783\n",
      "Average validation loss for epoch 424: 0.010766464285552502\n",
      "Epoch 425/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.003080322640016675\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.019722728058695793\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.006653906777501106\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.006859252694994211\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.014167525805532932\n",
      "Average validation loss for epoch 425: 0.010096747428178787\n",
      "Epoch 426/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0024609810207039118\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.0171903558075428\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.014323490671813488\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.066768579185009\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.017923874780535698\n",
      "Average validation loss for epoch 426: 0.023733455687761307\n",
      "Epoch 427/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002584961010143161\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.014540781266987324\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.014459691941738129\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.058055486530065536\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.017809497192502022\n",
      "Average validation loss for epoch 427: 0.021490082144737244\n",
      "Epoch 428/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0030408028978854418\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01778816245496273\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.014954802580177784\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.06598525494337082\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.018181411549448967\n",
      "Average validation loss for epoch 428: 0.02399008721113205\n",
      "Epoch 429/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0025047326926141977\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.013648864813148975\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.011640280485153198\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.019555216655135155\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.01771080493927002\n",
      "Average validation loss for epoch 429: 0.01301197987049818\n",
      "Epoch 430/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002958259778097272\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01560512650758028\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.015571638010442257\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.06613459438085556\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.02029760368168354\n",
      "Average validation loss for epoch 430: 0.02411344274878502\n",
      "Epoch 431/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0021484713070094585\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.013196330517530441\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.014473008923232555\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.06290539354085922\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.02276485227048397\n",
      "Average validation loss for epoch 431: 0.023097611963748932\n",
      "Epoch 432/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002566470066085458\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01700170524418354\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.016790911555290222\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.073239766061306\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.018534576520323753\n",
      "Average validation loss for epoch 432: 0.025626685470342636\n",
      "Epoch 433/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0023323881905525923\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.012496293522417545\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.012458809651434422\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.05079548433423042\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.01728782244026661\n",
      "Average validation loss for epoch 433: 0.01907416060566902\n",
      "Epoch 434/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002855505095794797\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.015772022306919098\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.014514072798192501\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.06458746641874313\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.017153631895780563\n",
      "Average validation loss for epoch 434: 0.02297654189169407\n",
      "Epoch 435/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002795302076265216\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.0124500198289752\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.011438424699008465\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.060446012765169144\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.01787414774298668\n",
      "Average validation loss for epoch 435: 0.021000782027840614\n",
      "Epoch 436/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0026398387271910906\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.016527267172932625\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.01514870673418045\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.0788615345954895\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.018279902637004852\n",
      "Average validation loss for epoch 436: 0.02629144862294197\n",
      "Epoch 437/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0019902146887034178\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.013251948170363903\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.01343965157866478\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.039642948657274246\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.015199084766209126\n",
      "Average validation loss for epoch 437: 0.016704769805073738\n",
      "Epoch 438/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002617309568449855\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.015139561146497726\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.014721023850142956\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.06311696022748947\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.018971053883433342\n",
      "Average validation loss for epoch 438: 0.02291318215429783\n",
      "Epoch 439/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0019263066351413727\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.013304009102284908\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.014827795326709747\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.011315773241221905\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.014183209277689457\n",
      "Average validation loss for epoch 439: 0.011111418716609478\n",
      "Epoch 440/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0026859852951020002\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.015104919672012329\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.013573690317571163\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.02883925288915634\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.018091650679707527\n",
      "Average validation loss for epoch 440: 0.01565909944474697\n",
      "Epoch 441/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002245574491098523\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.013530158437788486\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.004872647114098072\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.008045495487749577\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.013396442867815495\n",
      "Average validation loss for epoch 441: 0.008418062701821327\n",
      "Epoch 442/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0025381918530911207\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01674252189695835\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.010707871057093143\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.07611467689275742\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.01497812569141388\n",
      "Average validation loss for epoch 442: 0.02421627566218376\n",
      "Epoch 443/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0016402354231104255\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.014252119697630405\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.005266362335532904\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.013299246318638325\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.015876026824116707\n",
      "Average validation loss for epoch 443: 0.010066797956824303\n",
      "Epoch 444/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0020110609475523233\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01582956127822399\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.012068968266248703\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.0863061174750328\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.016359807923436165\n",
      "Average validation loss for epoch 444: 0.02651510201394558\n",
      "Epoch 445/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.001697514788247645\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01721126399934292\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.014506679028272629\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.04832957684993744\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.018644152209162712\n",
      "Average validation loss for epoch 445: 0.020077837631106377\n",
      "Epoch 446/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0024247458204627037\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.018001077696681023\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.015032504685223103\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.07718250900506973\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.019468549638986588\n",
      "Average validation loss for epoch 446: 0.02642187848687172\n",
      "Epoch 447/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002184406155720353\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.016748791560530663\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.01565195806324482\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.06884193420410156\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.019777361303567886\n",
      "Average validation loss for epoch 447: 0.024640891700983047\n",
      "Epoch 448/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0030113712418824434\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.018211033195257187\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.015811795368790627\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.07527346163988113\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.019639557227492332\n",
      "Average validation loss for epoch 448: 0.02638944424688816\n",
      "Epoch 449/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002694370923563838\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.017386751249432564\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.017427565529942513\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.07669863849878311\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.018617892637848854\n",
      "Average validation loss for epoch 449: 0.02656504511833191\n",
      "Epoch 450/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0032134223729372025\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.017011018469929695\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.015583503991365433\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.08097600936889648\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.017965322360396385\n",
      "Average validation loss for epoch 450: 0.02694985643029213\n",
      "Epoch 451/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0029452319722622633\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.017526960000395775\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.015814797952771187\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.05442832410335541\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.01649601384997368\n",
      "Average validation loss for epoch 451: 0.021442264318466187\n",
      "Epoch 452/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0024106253404170275\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.013793651945888996\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.012798984535038471\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.03875289857387543\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.018428189679980278\n",
      "Average validation loss for epoch 452: 0.017236869782209396\n",
      "Epoch 453/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0026087623555213213\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.017370304092764854\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.016911543905735016\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.07023123651742935\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.01874847710132599\n",
      "Average validation loss for epoch 453: 0.025174062699079514\n",
      "Epoch 454/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0018625924130901694\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.014609988778829575\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.015101662836968899\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.09037074446678162\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.01869027316570282\n",
      "Average validation loss for epoch 454: 0.028127053752541542\n",
      "Epoch 455/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.003378244349732995\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.019831083714962006\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.015752514824271202\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.022054612636566162\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.016999632120132446\n",
      "Average validation loss for epoch 455: 0.015603217296302319\n",
      "Epoch 456/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0012296796776354313\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.015412536449730396\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.008994408883154392\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.010799732990562916\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.014621810056269169\n",
      "Average validation loss for epoch 456: 0.010211633518338203\n",
      "Epoch 457/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.004783969838172197\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.02463887631893158\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.013021036982536316\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.018606528639793396\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.01888922043144703\n",
      "Average validation loss for epoch 457: 0.015987927094101906\n",
      "Epoch 458/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002274254569783807\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.013756551779806614\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.015918290242552757\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.026859717443585396\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.016761286184191704\n",
      "Average validation loss for epoch 458: 0.015114019624888897\n",
      "Epoch 459/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0023571227211505175\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.015985416248440742\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.014340282417833805\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.04145403951406479\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.017918189987540245\n",
      "Average validation loss for epoch 459: 0.01841101050376892\n",
      "Epoch 460/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0015379730612039566\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.014333095401525497\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.017209045588970184\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.05649494007229805\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.01720329187810421\n",
      "Average validation loss for epoch 460: 0.02135566994547844\n",
      "Epoch 461/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002702579600736499\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.016877615824341774\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.015711380168795586\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.06251605600118637\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.033868785947561264\n",
      "Average validation loss for epoch 461: 0.026335284113883972\n",
      "Epoch 462/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.001988915028050542\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.017565416172146797\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.02004401572048664\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.05672907829284668\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.01686219684779644\n",
      "Average validation loss for epoch 462: 0.022637924179434776\n",
      "Epoch 463/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0029153383802622557\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.015214369632303715\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.013391776941716671\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.05733606219291687\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.020530031993985176\n",
      "Average validation loss for epoch 463: 0.02187751606106758\n",
      "Epoch 464/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0021059836726635695\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01671246439218521\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.01984693855047226\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.06677164882421494\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.023823246359825134\n",
      "Average validation loss for epoch 464: 0.025852054357528687\n",
      "Epoch 465/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002354937605559826\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.017139866948127747\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.016389217227697372\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.05356617644429207\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.019886359572410583\n",
      "Average validation loss for epoch 465: 0.021867310628294945\n",
      "Epoch 466/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.00233060447499156\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01696467585861683\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.01816611923277378\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.06447561830282211\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.019800672307610512\n",
      "Average validation loss for epoch 466: 0.024347538128495216\n",
      "Epoch 467/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0021559870801866055\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.013943672180175781\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.015164579264819622\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.0625031366944313\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.0191031601279974\n",
      "Average validation loss for epoch 467: 0.022574108093976974\n",
      "Epoch 468/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0029320830944925547\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.013239559717476368\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.01617239974439144\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.06946031749248505\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.019049495458602905\n",
      "Average validation loss for epoch 468: 0.02417077124118805\n",
      "Epoch 469/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002628147602081299\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.011866666376590729\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.014863493852317333\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.06112932041287422\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.02214854396879673\n",
      "Average validation loss for epoch 469: 0.022527234628796577\n",
      "Epoch 470/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0031950052361935377\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.014118216931819916\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.018280616030097008\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.09397512674331665\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.01909351721405983\n",
      "Average validation loss for epoch 470: 0.029732495546340942\n",
      "Epoch 471/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0032563323620706797\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.012484200298786163\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.015632804483175278\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.06992007791996002\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.017633602023124695\n",
      "Average validation loss for epoch 471: 0.02378540299832821\n",
      "Epoch 472/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0028673436027020216\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.011318893171846867\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.015528838150203228\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.07323847711086273\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.01764562726020813\n",
      "Average validation loss for epoch 472: 0.02411983534693718\n",
      "Epoch 473/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0026322014164179564\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01097708847373724\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.014933302998542786\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.06973505020141602\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.017751671373844147\n",
      "Average validation loss for epoch 473: 0.023205863311886787\n",
      "Epoch 474/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0024727240670472383\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.014181519858539104\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.014789707027375698\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.046836573630571365\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.01830093190073967\n",
      "Average validation loss for epoch 474: 0.019316291436553\n",
      "Epoch 475/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0015925044426694512\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.010113242082297802\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.005376577377319336\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.012329655699431896\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.015371478162705898\n",
      "Average validation loss for epoch 475: 0.00895669125020504\n",
      "Epoch 476/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002334486460313201\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01329732034355402\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.014284864999353886\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.03740483149886131\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.01845904253423214\n",
      "Average validation loss for epoch 476: 0.01715610921382904\n",
      "Epoch 477/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0018889307975769043\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.013846833258867264\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.0194221381098032\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.0209279153496027\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03204191476106644\n",
      "Average validation loss for epoch 477: 0.01762554608285427\n",
      "Epoch 478/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002025218680500984\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01880907081067562\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.017364727333188057\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.047800999134778976\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.016987096518278122\n",
      "Average validation loss for epoch 478: 0.020597422495484352\n",
      "Epoch 479/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0017779594054445624\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.018231907859444618\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.0008105605375021696\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.007585418876260519\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.021785790100693703\n",
      "Average validation loss for epoch 479: 0.010038327425718307\n",
      "Epoch 480/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.005381268914788961\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.027326621115207672\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.00830504298210144\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.013849441893398762\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.015826869755983353\n",
      "Average validation loss for epoch 480: 0.01413784921169281\n",
      "Epoch 481/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0011340472847223282\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.015154057182371616\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.004247654695063829\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.00814885925501585\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.035573381930589676\n",
      "Average validation loss for epoch 481: 0.012851600535213947\n",
      "Epoch 482/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.007312844041734934\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.024698613211512566\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.026709675788879395\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.11442265659570694\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.07083885371685028\n",
      "Average validation loss for epoch 482: 0.048796527087688446\n",
      "Epoch 483/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002115207491442561\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.21950088441371918\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.31397974491119385\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.1166568174958229\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.039224352687597275\n",
      "Average validation loss for epoch 483: 0.13829539716243744\n",
      "Epoch 484/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.005149221979081631\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01858699508011341\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.005006317514926195\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.0063745551742613316\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.018353497609496117\n",
      "Average validation loss for epoch 484: 0.010694118216633797\n",
      "Epoch 485/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.01952877640724182\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.004493374843150377\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.0028724309522658587\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.015273512341082096\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.020520322024822235\n",
      "Average validation loss for epoch 485: 0.012537683360278606\n",
      "Epoch 486/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.008645923808217049\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.016392657533288002\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.008654508739709854\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.029706919565796852\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.026179639622569084\n",
      "Average validation loss for epoch 486: 0.017915930598974228\n",
      "Epoch 487/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.001821391866542399\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.017164841294288635\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.016689665615558624\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.014426236040890217\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.01774340309202671\n",
      "Average validation loss for epoch 487: 0.01356910727918148\n",
      "Epoch 488/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0011011866154149175\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01595405302941799\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.02012227661907673\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.01924431324005127\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.02582554519176483\n",
      "Average validation loss for epoch 488: 0.016449475660920143\n",
      "Epoch 489/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002146699232980609\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.013872521929442883\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.01615084894001484\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.01579103246331215\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.018720345571637154\n",
      "Average validation loss for epoch 489: 0.01333629060536623\n",
      "Epoch 490/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0027338191866874695\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.016255313530564308\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.01616119220852852\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.020616773515939713\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.018193257972598076\n",
      "Average validation loss for epoch 490: 0.014792071655392647\n",
      "Epoch 491/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0023676499258726835\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01198498997837305\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.006794534623622894\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.019641224294900894\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.01746368408203125\n",
      "Average validation loss for epoch 491: 0.011650416068732738\n",
      "Epoch 492/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0026028777938336134\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.016249077394604683\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.016211871057748795\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.01897183246910572\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.01803973689675331\n",
      "Average validation loss for epoch 492: 0.014415079727768898\n",
      "Epoch 493/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0022300381679087877\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01534254476428032\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.01328343991190195\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.022244751453399658\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.016956334933638573\n",
      "Average validation loss for epoch 493: 0.014011422172188759\n",
      "Epoch 494/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002130750799551606\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.015117154456675053\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.017031587660312653\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.01771196722984314\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.02349293977022171\n",
      "Average validation loss for epoch 494: 0.015096880495548248\n",
      "Epoch 495/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002418443327769637\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01766769029200077\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.015893755480647087\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.022720014676451683\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.017426462844014168\n",
      "Average validation loss for epoch 495: 0.015225273557007313\n",
      "Epoch 496/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0023136811796575785\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.017008911818265915\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.017244650050997734\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.020851269364356995\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.021716350689530373\n",
      "Average validation loss for epoch 496: 0.01582697220146656\n",
      "Epoch 497/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002601569751277566\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.017092542722821236\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.016322163864970207\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.023144349455833435\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.02877821959555149\n",
      "Average validation loss for epoch 497: 0.017587769776582718\n",
      "Epoch 498/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0030320037622004747\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.018115133047103882\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.01630345545709133\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.022549055516719818\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.01824859343469143\n",
      "Average validation loss for epoch 498: 0.015649648383259773\n",
      "Epoch 499/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002227633958682418\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.016133973374962807\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.016615426167845726\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.02253040485084057\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.019633635878562927\n",
      "Average validation loss for epoch 499: 0.015428215265274048\n",
      "Epoch 500/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002891042036935687\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01714503765106201\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.01574985310435295\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.021389253437519073\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.018435180187225342\n",
      "Average validation loss for epoch 500: 0.015122073702514172\n",
      "Epoch 501/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0031019009184092283\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.012762208469212055\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.0056655979715287685\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.016006065532565117\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.01722242496907711\n",
      "Average validation loss for epoch 501: 0.010951640084385872\n",
      "Epoch 502/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0022790157236158848\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.013762873597443104\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.017678847536444664\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.02053936943411827\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.01998339407145977\n",
      "Average validation loss for epoch 502: 0.014848699793219566\n",
      "Epoch 503/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002066928194835782\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.014120814390480518\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.019038809463381767\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.025297602638602257\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.01790764182806015\n",
      "Average validation loss for epoch 503: 0.015686359256505966\n",
      "Epoch 504/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.001983456313610077\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.013127240352332592\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.01775471307337284\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.02305031381547451\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.022441402077674866\n",
      "Average validation loss for epoch 504: 0.015671424567699432\n",
      "Epoch 505/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.00373862124979496\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.012558015994727612\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.01890370436012745\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.023404436185956\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.01754286140203476\n",
      "Average validation loss for epoch 505: 0.015229527838528156\n",
      "Epoch 506/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0028189688455313444\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.005798252299427986\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.01608027145266533\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.02194940485060215\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.031928349286317825\n",
      "Average validation loss for epoch 506: 0.01571505144238472\n",
      "Epoch 507/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0020947426091879606\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.014537121169269085\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.019256824627518654\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.02067929320037365\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.017731662839651108\n",
      "Average validation loss for epoch 507: 0.01485992968082428\n",
      "Epoch 508/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0017626791959628463\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01264877151697874\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.017427703365683556\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.02223406918346882\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.021172957494854927\n",
      "Average validation loss for epoch 508: 0.01504923589527607\n",
      "Epoch 509/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0025701208505779505\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.016809355467557907\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.01825680397450924\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.023522518575191498\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.017220046371221542\n",
      "Average validation loss for epoch 509: 0.01567576825618744\n",
      "Epoch 510/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002744436264038086\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.012144286185503006\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.016137806698679924\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.023524513468146324\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.02396683394908905\n",
      "Average validation loss for epoch 510: 0.015703575685620308\n",
      "Epoch 511/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.003725136863067746\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01755632273852825\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.01679009385406971\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.023556986823678017\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.016529276967048645\n",
      "Average validation loss for epoch 511: 0.01563156396150589\n",
      "Epoch 512/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0019138175994157791\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.013522113673388958\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.019674090668559074\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.02432669699192047\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.01786796934902668\n",
      "Average validation loss for epoch 512: 0.015460938215255737\n",
      "Epoch 513/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002857401967048645\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.014869275502860546\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.017040632665157318\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.023551741614937782\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.016708873212337494\n",
      "Average validation loss for epoch 513: 0.015005585737526417\n",
      "Epoch 514/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0015988497762009501\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.012766879983246326\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.016442405059933662\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.023034414276480675\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.01885659620165825\n",
      "Average validation loss for epoch 514: 0.014539828523993492\n",
      "Epoch 515/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0025664533022791147\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.016979271546006203\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.0195362139493227\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.022770604118704796\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03127901628613472\n",
      "Average validation loss for epoch 515: 0.018626311793923378\n",
      "Epoch 516/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.001520570949651301\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.015491127967834473\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.0033317848574370146\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.00856250524520874\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.027663568034768105\n",
      "Average validation loss for epoch 516: 0.011313910596072674\n",
      "Epoch 517/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0034452714025974274\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.021904276683926582\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.007339932024478912\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.020461514592170715\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.04494196176528931\n",
      "Average validation loss for epoch 517: 0.01961859129369259\n",
      "Epoch 518/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0008256039000116289\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.015926538035273552\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.01548489648848772\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.018638774752616882\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.05700753256678581\n",
      "Average validation loss for epoch 518: 0.021576669067144394\n",
      "Epoch 519/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.007508145645260811\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.02622923254966736\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.02078799530863762\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.01556019950658083\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.024262720718979836\n",
      "Average validation loss for epoch 519: 0.018869657069444656\n",
      "Epoch 520/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0020875369664281607\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.016500454396009445\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.013936682604253292\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.02183976210653782\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03178929165005684\n",
      "Average validation loss for epoch 520: 0.017230745404958725\n",
      "Epoch 521/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.004653965122997761\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.023404350504279137\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.019576946273446083\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.02254265733063221\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03474811092019081\n",
      "Average validation loss for epoch 521: 0.020985206589102745\n",
      "Epoch 522/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0020507515873759985\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.015437126159667969\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.020263671875\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.025581762194633484\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.061768483370542526\n",
      "Average validation loss for epoch 522: 0.025020357221364975\n",
      "Epoch 523/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0033429330214858055\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.019444407895207405\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.023987481370568275\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.02864157222211361\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.043797969818115234\n",
      "Average validation loss for epoch 523: 0.02384287305176258\n",
      "Epoch 524/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0020055980421602726\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01919860951602459\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.020030466839671135\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.023276707157492638\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.05440565571188927\n",
      "Average validation loss for epoch 524: 0.023783406242728233\n",
      "Epoch 525/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0021117564756423235\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01745820976793766\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.020330339670181274\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.018266858533024788\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.018453793600201607\n",
      "Average validation loss for epoch 525: 0.015324192121624947\n",
      "Epoch 526/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0013219374231994152\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.009517352096736431\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.015637939795851707\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.02032601274549961\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03802458569407463\n",
      "Average validation loss for epoch 526: 0.016965564340353012\n",
      "Epoch 527/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0018252910813316703\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01873468980193138\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.01949167437851429\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.02048926241695881\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.01868659071624279\n",
      "Average validation loss for epoch 527: 0.01584550179541111\n",
      "Epoch 528/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.001876689144410193\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.011904464103281498\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.015132889151573181\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.01833552122116089\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.01756514422595501\n",
      "Average validation loss for epoch 528: 0.012962942011654377\n",
      "Epoch 529/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0030801661778241396\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.016442999243736267\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.015330188907682896\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.02242540754377842\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03722618892788887\n",
      "Average validation loss for epoch 529: 0.01890099048614502\n",
      "Epoch 530/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0026152562350034714\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.019400276243686676\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.018307656049728394\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.02349749207496643\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03572303429245949\n",
      "Average validation loss for epoch 530: 0.01990874484181404\n",
      "Epoch 531/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002490818500518799\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01952260732650757\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.017232194542884827\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.02219962328672409\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.02470307983458042\n",
      "Average validation loss for epoch 531: 0.01722966507077217\n",
      "Epoch 532/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0017412310699000955\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.015300322324037552\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.014791019260883331\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.01979137398302555\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.016251197084784508\n",
      "Average validation loss for epoch 532: 0.01357502955943346\n",
      "Epoch 533/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.001497277058660984\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.011216931976377964\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.005380372982472181\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.01015851367264986\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.032495319843292236\n",
      "Average validation loss for epoch 533: 0.012149683199822903\n",
      "Epoch 534/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.009410134516656399\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.019282419234514236\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.013896946795284748\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.014778506942093372\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.034413937479257584\n",
      "Average validation loss for epoch 534: 0.018356388434767723\n",
      "Epoch 535/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.006004521157592535\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.024446003139019012\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.021179551258683205\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.018843619152903557\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.019021639600396156\n",
      "Average validation loss for epoch 535: 0.01789906620979309\n",
      "Epoch 536/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0007920055650174618\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.00739246467128396\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.008798651397228241\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.01096680760383606\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.016681646928191185\n",
      "Average validation loss for epoch 536: 0.008926315233111382\n",
      "Epoch 537/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0006015290273353457\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.013891537673771381\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.017948955297470093\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.018116867169737816\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.017561668530106544\n",
      "Average validation loss for epoch 537: 0.01362411119043827\n",
      "Epoch 538/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.001156082027591765\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.014614399522542953\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.01458857674151659\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.023005181923508644\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.037453025579452515\n",
      "Average validation loss for epoch 538: 0.01816345378756523\n",
      "Epoch 539/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0021042509470134974\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01883179508149624\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.015727795660495758\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.022200509905815125\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03095175139605999\n",
      "Average validation loss for epoch 539: 0.017963219434022903\n",
      "Epoch 540/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0027284950483590364\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.0208682119846344\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.01932118833065033\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.022269828245043755\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.019478168338537216\n",
      "Average validation loss for epoch 540: 0.016933178529143333\n",
      "Epoch 541/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0012062854366376996\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.013991587795317173\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.005258605349808931\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.01645614020526409\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.017137140035629272\n",
      "Average validation loss for epoch 541: 0.010809952393174171\n",
      "Epoch 542/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.005880052223801613\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.023633325472474098\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.018041836097836494\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.025425216183066368\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03916535899043083\n",
      "Average validation loss for epoch 542: 0.02242915891110897\n",
      "Epoch 543/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0012718710349872708\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.016351059079170227\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.013254244811832905\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.01655244082212448\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.04513855651021004\n",
      "Average validation loss for epoch 543: 0.01851363480091095\n",
      "Epoch 544/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.006682998966425657\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.02697966992855072\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.02558925189077854\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.024878473952412605\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.038639768958091736\n",
      "Average validation loss for epoch 544: 0.02455403283238411\n",
      "Epoch 545/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0034724250435829163\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.017210833728313446\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.020380327478051186\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.027188727632164955\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.057178795337677\n",
      "Average validation loss for epoch 545: 0.02508622035384178\n",
      "Epoch 546/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0009826257592067122\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.015994427725672722\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.019383080303668976\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.023734623566269875\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.07685191184282303\n",
      "Average validation loss for epoch 546: 0.02738933637738228\n",
      "Epoch 547/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0014431480085477233\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.029209256172180176\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.0207210686057806\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.023084178566932678\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.041535086929798126\n",
      "Average validation loss for epoch 547: 0.023198548704385757\n",
      "Epoch 548/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.01465828251093626\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.0321359746158123\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.02094408869743347\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.006138549651950598\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.023607635870575905\n",
      "Average validation loss for epoch 548: 0.01949690654873848\n",
      "Epoch 549/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.045053720474243164\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.2544912099838257\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.21000482141971588\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.012025333009660244\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.02163795940577984\n",
      "Average validation loss for epoch 549: 0.10864261537790298\n",
      "Epoch 550/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.006591095123440027\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.026821495965123177\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.021686697378754616\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.022557133808732033\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.0189664289355278\n",
      "Average validation loss for epoch 550: 0.019324569031596184\n",
      "Epoch 551/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.010935625992715359\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.022670647129416466\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.013867291621863842\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.021594196557998657\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.031076088547706604\n",
      "Average validation loss for epoch 551: 0.020028769969940186\n",
      "Epoch 552/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002041826955974102\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.016058022156357765\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.019549397751688957\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.014852155931293964\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.015972867608070374\n",
      "Average validation loss for epoch 552: 0.013694852590560913\n",
      "Epoch 553/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0028684844728559256\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.019613461568951607\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.014224008657038212\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.02093157172203064\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.030212854966521263\n",
      "Average validation loss for epoch 553: 0.017570076510310173\n",
      "Epoch 554/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002428126521408558\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.018054375424981117\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.020806385204195976\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.02028486877679825\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.02579723484814167\n",
      "Average validation loss for epoch 554: 0.01747419871389866\n",
      "Epoch 555/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.005435503553599119\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.018157409504055977\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.010678339749574661\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.02027869038283825\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03213870897889137\n",
      "Average validation loss for epoch 555: 0.017337730154395103\n",
      "Epoch 556/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.001878466922789812\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.016643907874822617\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.01722460798919201\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.015979131683707237\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.024637915194034576\n",
      "Average validation loss for epoch 556: 0.015272806398570538\n",
      "Epoch 557/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.004111905116587877\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.009789193980395794\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.0007924767560325563\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.00842425785958767\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.028814325109124184\n",
      "Average validation loss for epoch 557: 0.010386431589722633\n",
      "Epoch 558/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0027328699361532927\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.017579233273863792\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.016505220904946327\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.020240360870957375\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.028661126270890236\n",
      "Average validation loss for epoch 558: 0.01714376173913479\n",
      "Epoch 559/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0025180100928992033\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.019621592015028\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.01123197004199028\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.020358458161354065\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03431373089551926\n",
      "Average validation loss for epoch 559: 0.017608752474188805\n",
      "Epoch 560/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.001975710503757\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01719478704035282\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.014285523444414139\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.015307076275348663\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.026590997353196144\n",
      "Average validation loss for epoch 560: 0.015070818364620209\n",
      "Epoch 561/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.001552656409330666\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.014847076497972012\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.01258915662765503\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.02196970395743847\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.033156249672174454\n",
      "Average validation loss for epoch 561: 0.016822969540953636\n",
      "Epoch 562/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0022513391450047493\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.020443955436348915\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.017277725040912628\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.013010929338634014\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.02850504219532013\n",
      "Average validation loss for epoch 562: 0.016297798603773117\n",
      "Epoch 563/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0016860078321769834\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.012480012141168118\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.007255304604768753\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.01654326729476452\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.038562651723623276\n",
      "Average validation loss for epoch 563: 0.01530544739216566\n",
      "Epoch 564/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0021537707652896643\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01805979199707508\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.016544148325920105\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.0172348041087389\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.02163771353662014\n",
      "Average validation loss for epoch 564: 0.015126046724617481\n",
      "Epoch 565/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002085500629618764\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.014571942389011383\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.008578351698815823\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.019618919119238853\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.043247345834970474\n",
      "Average validation loss for epoch 565: 0.01762041077017784\n",
      "Epoch 566/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.003315912326797843\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.021421587094664574\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.020502107217907906\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.02387061156332493\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.039242830127477646\n",
      "Average validation loss for epoch 566: 0.021670609712600708\n",
      "Epoch 567/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.00247769127599895\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.0199175626039505\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.02059330977499485\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.02443288452923298\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.038728609681129456\n",
      "Average validation loss for epoch 567: 0.02123001031577587\n",
      "Epoch 568/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002442306140437722\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01872715726494789\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.020754361525177956\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.02242872305214405\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.036995790898799896\n",
      "Average validation loss for epoch 568: 0.020269667729735374\n",
      "Epoch 569/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0017705740174278617\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.018986115232110023\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.018356936052441597\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.02155306376516819\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.036658722907304764\n",
      "Average validation loss for epoch 569: 0.01946508325636387\n",
      "Epoch 570/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0029882651288062334\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.02085292898118496\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.01885010488331318\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.020133934915065765\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03333711251616478\n",
      "Average validation loss for epoch 570: 0.01923247054219246\n",
      "Epoch 571/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0024637484457343817\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.015035233460366726\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.012948382645845413\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.019429504871368408\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.02230898104608059\n",
      "Average validation loss for epoch 571: 0.014437170699238777\n",
      "Epoch 572/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.004020053427666426\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.05533934757113457\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.2169722318649292\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.062394339591264725\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.0450657457113266\n",
      "Average validation loss for epoch 572: 0.07675834745168686\n",
      "Epoch 573/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002642278326675296\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.016323735937476158\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.004856977611780167\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.010637777857482433\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.030121490359306335\n",
      "Average validation loss for epoch 573: 0.012916451320052147\n",
      "Epoch 574/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.008239115588366985\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.023075630888342857\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.008359679952263832\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.021631771698594093\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.04007967934012413\n",
      "Average validation loss for epoch 574: 0.020277176052331924\n",
      "Epoch 575/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.007463639136403799\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.026552816852927208\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.018993953242897987\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.024888915941119194\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.042113590985536575\n",
      "Average validation loss for epoch 575: 0.02400258556008339\n",
      "Epoch 576/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.003471101401373744\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.019972966983914375\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.020201358944177628\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.019301462918519974\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.04210779070854187\n",
      "Average validation loss for epoch 576: 0.021010935306549072\n",
      "Epoch 577/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0025505051016807556\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.020283769816160202\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.02068450301885605\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.026737285777926445\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.04339911416172981\n",
      "Average validation loss for epoch 577: 0.022731035947799683\n",
      "Epoch 578/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002088167006149888\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.017237914726138115\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.01811167038977146\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.023792872205376625\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.0550076998770237\n",
      "Average validation loss for epoch 578: 0.02324766479432583\n",
      "Epoch 579/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.003048791317269206\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01827566884458065\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.023610664531588554\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.026254942640662193\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03830936551094055\n",
      "Average validation loss for epoch 579: 0.021899886429309845\n",
      "Epoch 580/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0022231878247112036\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.018251169472932816\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.01809520833194256\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.022425657138228416\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.048717185854911804\n",
      "Average validation loss for epoch 580: 0.02194248139858246\n",
      "Epoch 581/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002862677676603198\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01860421895980835\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.020488755777478218\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.023929446935653687\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.045904114842414856\n",
      "Average validation loss for epoch 581: 0.022357841953635216\n",
      "Epoch 582/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002842458663508296\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.017109567299485207\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.019560109823942184\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.028140276670455933\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.05218281224370003\n",
      "Average validation loss for epoch 582: 0.023967046290636063\n",
      "Epoch 583/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.005601642653346062\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.022735660895705223\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.023901624605059624\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.025582609698176384\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.01653388701379299\n",
      "Average validation loss for epoch 583: 0.018871085718274117\n",
      "Epoch 584/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0018543429905548692\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.004117797128856182\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.001976744504645467\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.01568593829870224\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03560060262680054\n",
      "Average validation loss for epoch 584: 0.011847084388136864\n",
      "Epoch 585/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0019699130207300186\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.0185759998857975\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.01604568399488926\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.012404829263687134\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.01835498958826065\n",
      "Average validation loss for epoch 585: 0.013470282778143883\n",
      "Epoch 586/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.007215132471174002\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.011413137428462505\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.0030852986965328455\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.010722248815000057\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.01803893782198429\n",
      "Average validation loss for epoch 586: 0.010094950906932354\n",
      "Epoch 587/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.00892895832657814\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.027706677094101906\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.01256483793258667\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.020655976608395576\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03962279483675957\n",
      "Average validation loss for epoch 587: 0.02189585007727146\n",
      "Epoch 588/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.008772770874202251\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.020123789086937904\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.01776367984712124\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.019693518057465553\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.04810994490981102\n",
      "Average validation loss for epoch 588: 0.02289273962378502\n",
      "Epoch 589/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.2224920243024826\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.2526388168334961\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.2411760538816452\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.01557870488613844\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.0519288070499897\n",
      "Average validation loss for epoch 589: 0.15676288306713104\n",
      "Epoch 590/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0024341277312487364\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.020207230001688004\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.02492467314004898\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.035478513687849045\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.05524861440062523\n",
      "Average validation loss for epoch 590: 0.027658632025122643\n",
      "Epoch 591/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002889009425416589\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.016107209026813507\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.02353656478226185\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.031164443120360374\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.05418533459305763\n",
      "Average validation loss for epoch 591: 0.025576511397957802\n",
      "Epoch 592/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.004053653683513403\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.02107849530875683\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.02369759976863861\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.027631506323814392\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.0455201156437397\n",
      "Average validation loss for epoch 592: 0.024396274238824844\n",
      "Epoch 593/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.004323525819927454\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.02071026898920536\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.024341782554984093\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.025823524221777916\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03615662083029747\n",
      "Average validation loss for epoch 593: 0.02227114513516426\n",
      "Epoch 594/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.004510379862040281\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.022274075075984\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.0233506727963686\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.021638737991452217\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.021998772397637367\n",
      "Average validation loss for epoch 594: 0.01875452697277069\n",
      "Epoch 595/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0037872896064072847\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.020369386300444603\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.02277393825352192\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.020469369366765022\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.021719902753829956\n",
      "Average validation loss for epoch 595: 0.017823977395892143\n",
      "Epoch 596/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0036839942913502455\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.02216316945850849\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.023186810314655304\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.020690564066171646\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.01906009018421173\n",
      "Average validation loss for epoch 596: 0.017756925895810127\n",
      "Epoch 597/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.003078918671235442\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.020330702885985374\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.01682303287088871\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.0131860775873065\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.01760195381939411\n",
      "Average validation loss for epoch 597: 0.014204137027263641\n",
      "Epoch 598/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.003023972036316991\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.018936902284622192\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.015103179030120373\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.019343314692378044\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.01827293075621128\n",
      "Average validation loss for epoch 598: 0.014936059713363647\n",
      "Epoch 599/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002974018221721053\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.019714130088686943\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.018358783796429634\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.01996775157749653\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.020810825750231743\n",
      "Average validation loss for epoch 599: 0.01636510156095028\n",
      "Epoch 600/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.004297720268368721\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.02183683030307293\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.019558100029826164\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.021243514493107796\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.0306573286652565\n",
      "Average validation loss for epoch 600: 0.019518699496984482\n",
      "Epoch 601/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.004428936634212732\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.016447266563773155\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.0124186547473073\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.010396498255431652\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.01637113094329834\n",
      "Average validation loss for epoch 601: 0.012012497521936893\n",
      "Epoch 602/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0024311647284775972\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.014951254241168499\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.009212368167936802\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.010303594172000885\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.01909901387989521\n",
      "Average validation loss for epoch 602: 0.01119947899132967\n",
      "Epoch 603/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.003191995434463024\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.019354432821273804\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.013828154653310776\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.014736433513462543\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.01656258851289749\n",
      "Average validation loss for epoch 603: 0.013534721918404102\n",
      "Epoch 604/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0017702882178127766\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.018754350021481514\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.01452882681041956\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.014054006896913052\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.01943756826221943\n",
      "Average validation loss for epoch 604: 0.013709008693695068\n",
      "Epoch 605/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.003112967824563384\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.02030661329627037\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.015412556938827038\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.019954312592744827\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.017037391662597656\n",
      "Average validation loss for epoch 605: 0.015164768323302269\n",
      "Epoch 606/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0023867797572165728\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.020783813670277596\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.015226922929286957\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.013596449978649616\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.019094528630375862\n",
      "Average validation loss for epoch 606: 0.014217698946595192\n",
      "Epoch 607/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0034778278786689043\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.015216059051454067\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.006698735058307648\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.006754477974027395\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.015827355906367302\n",
      "Average validation loss for epoch 607: 0.009594890289008617\n",
      "Epoch 608/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0014332197606563568\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.014508061110973358\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.006316173356026411\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.007153403013944626\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.0174028892070055\n",
      "Average validation loss for epoch 608: 0.009362749755382538\n",
      "Epoch 609/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0029111907351762056\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.017692100256681442\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.011639242060482502\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.01570107974112034\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.01704096980392933\n",
      "Average validation loss for epoch 609: 0.01299691665917635\n",
      "Epoch 610/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0013256827369332314\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.018031584098935127\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.013934125192463398\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.0064710150472819805\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.025619560852646828\n",
      "Average validation loss for epoch 610: 0.01307639293372631\n",
      "Epoch 611/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.004149741493165493\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.02000267244875431\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.01371106505393982\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.016650604084134102\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.016535034403204918\n",
      "Average validation loss for epoch 611: 0.014209823682904243\n",
      "Epoch 612/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002548624062910676\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.020796509459614754\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.012277547270059586\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.009844624437391758\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.013274963945150375\n",
      "Average validation loss for epoch 612: 0.011748453602194786\n",
      "Epoch 613/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0019984785467386246\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.014713932760059834\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.008152705617249012\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.012673911638557911\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.016078276559710503\n",
      "Average validation loss for epoch 613: 0.010723461396992207\n",
      "Epoch 614/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.00043638082570396364\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.007874648086726665\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.0035332634579390287\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.01164016779512167\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.016109170392155647\n",
      "Average validation loss for epoch 614: 0.007918725721538067\n",
      "INFO:tensorflow:Assets written to: ./LSTM\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./LSTM\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at epoch 614 with validation loss: 0.007918725721538067\n",
      "Epoch 615/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0007548244320787489\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.007597966119647026\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.005575912073254585\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.010662364773452282\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.01565857045352459\n",
      "Average validation loss for epoch 615: 0.008049927651882172\n",
      "Epoch 616/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0018331571482121944\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.008297598920762539\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.0022264444269239902\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.006845443043857813\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.01674392819404602\n",
      "Average validation loss for epoch 616: 0.007189313881099224\n",
      "INFO:tensorflow:Assets written to: ./LSTM\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./LSTM\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at epoch 616 with validation loss: 0.007189313881099224\n",
      "Epoch 617/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.001729644020088017\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.012603186070919037\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.007935619913041592\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.017319783568382263\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.0306246355175972\n",
      "Average validation loss for epoch 617: 0.014042573980987072\n",
      "Epoch 618/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0022010651882737875\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.02010790817439556\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.02125220000743866\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.01857358030974865\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.017308853566646576\n",
      "Average validation loss for epoch 618: 0.015888722613453865\n",
      "Epoch 619/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0019043394131585956\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.017764972522854805\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.011151458136737347\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.0073076095432043076\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03345727548003197\n",
      "Average validation loss for epoch 619: 0.014317130669951439\n",
      "Epoch 620/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.006331074982881546\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.018645435571670532\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.014900212176144123\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.011433057487010956\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.04020807147026062\n",
      "Average validation loss for epoch 620: 0.01830356940627098\n",
      "Epoch 621/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.006299913395196199\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.022226950153708458\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.018233953043818474\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.019944660365581512\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03720635548233986\n",
      "Average validation loss for epoch 621: 0.020782366394996643\n",
      "Epoch 622/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.004346262663602829\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.02097022719681263\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.02326393686234951\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.022267647087574005\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.030318239703774452\n",
      "Average validation loss for epoch 622: 0.020233262330293655\n",
      "Epoch 623/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002137357136234641\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.020672453567385674\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.01664489135146141\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.011850195936858654\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.01656504161655903\n",
      "Average validation loss for epoch 623: 0.013573987409472466\n",
      "Epoch 624/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0023498248774558306\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.021488690748810768\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.018930474296212196\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.014039668254554272\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.025045035406947136\n",
      "Average validation loss for epoch 624: 0.016370739787817\n",
      "Epoch 625/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.003425753442570567\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01223553717136383\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.001324663870036602\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.006278961431235075\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.014037811197340488\n",
      "Average validation loss for epoch 625: 0.007460544817149639\n",
      "Epoch 626/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0010403466876596212\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.0059667970053851604\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.0035210223868489265\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.007316234987229109\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.02547304891049862\n",
      "Average validation loss for epoch 626: 0.008663490414619446\n",
      "Epoch 627/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.007212028373032808\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.02409195713698864\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.011584616266191006\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.005875805858522654\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.029214033856987953\n",
      "Average validation loss for epoch 627: 0.015595689415931702\n",
      "Epoch 628/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0035896894987672567\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.02236834727227688\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.01977425068616867\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.018360698595643044\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.04016711935400963\n",
      "Average validation loss for epoch 628: 0.020852020010352135\n",
      "Epoch 629/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0031757738906890154\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.020433848723769188\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.018993275240063667\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.005680616945028305\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.028765952214598656\n",
      "Average validation loss for epoch 629: 0.015409892424941063\n",
      "Epoch 630/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.006963783409446478\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.011249515227973461\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.004802146926522255\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.011006467044353485\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.01574300415813923\n",
      "Average validation loss for epoch 630: 0.009952982887625694\n",
      "Epoch 631/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.005803185049444437\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.011230353266000748\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.0028990060091018677\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.0074268546886742115\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.04302581772208214\n",
      "Average validation loss for epoch 631: 0.014077043160796165\n",
      "Epoch 632/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.00896072294563055\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.023008763790130615\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.018223470076918602\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.016933677718043327\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.04435734078288078\n",
      "Average validation loss for epoch 632: 0.02229679562151432\n",
      "Epoch 633/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0076013170182704926\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.02486136555671692\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.02304459549486637\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.028031930327415466\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03716949000954628\n",
      "Average validation loss for epoch 633: 0.024141740053892136\n",
      "Epoch 634/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0035136507358402014\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.018635371699929237\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.016542723402380943\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.019797898828983307\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.018604377284646034\n",
      "Average validation loss for epoch 634: 0.015418803319334984\n",
      "Epoch 635/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002544770250096917\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.020512312650680542\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.02150898613035679\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.024580927565693855\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.028149008750915527\n",
      "Average validation loss for epoch 635: 0.019459201022982597\n",
      "Epoch 636/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0037147055845707655\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.017001336440443993\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.007091902662068605\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.009885452687740326\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.019462333992123604\n",
      "Average validation loss for epoch 636: 0.01143114548176527\n",
      "Epoch 637/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0020675973501056433\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01987200230360031\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.02248726226389408\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.021903499960899353\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.027777662500739098\n",
      "Average validation loss for epoch 637: 0.018821604549884796\n",
      "Epoch 638/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002158179646357894\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.019214309751987457\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.008903061039745808\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.010318056680262089\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.028296658769249916\n",
      "Average validation loss for epoch 638: 0.013778053224086761\n",
      "Epoch 639/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0023031600285321474\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.019200541079044342\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.020534774288535118\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.024430006742477417\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.028891583904623985\n",
      "Average validation loss for epoch 639: 0.019072014838457108\n",
      "Epoch 640/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002808347111567855\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.021226385608315468\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.01928303949534893\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.016300972551107407\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.02179858088493347\n",
      "Average validation loss for epoch 640: 0.016283463686704636\n",
      "Epoch 641/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0021765991114079952\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.018434124067425728\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.014317840337753296\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.02539180777966976\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.04008013382554054\n",
      "Average validation loss for epoch 641: 0.020080100744962692\n",
      "Epoch 642/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.004640183877199888\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.022260958328843117\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.015331808477640152\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.014006967656314373\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03685131296515465\n",
      "Average validation loss for epoch 642: 0.018618246540427208\n",
      "Epoch 643/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0033396175131201744\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.019641833379864693\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.015967566519975662\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.021089641377329826\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03016759641468525\n",
      "Average validation loss for epoch 643: 0.018041249364614487\n",
      "Epoch 644/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0011542531428858638\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.015410765074193478\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.012740147300064564\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.013612235896289349\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.016978440806269646\n",
      "Average validation loss for epoch 644: 0.01197916828095913\n",
      "Epoch 645/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002183423610404134\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.020809350535273552\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.002713387133553624\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.011994843371212482\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.02003481797873974\n",
      "Average validation loss for epoch 645: 0.011547164991497993\n",
      "Epoch 646/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002039270242676139\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.007489571813493967\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.001403014175593853\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.010936029255390167\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.015871234238147736\n",
      "Average validation loss for epoch 646: 0.007547824177891016\n",
      "Epoch 647/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0008867566357366741\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.005319241434335709\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.0051740482449531555\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.009770091623067856\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.016497576609253883\n",
      "Average validation loss for epoch 647: 0.007529543247073889\n",
      "Epoch 648/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002556727034971118\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.013100557029247284\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.005244441796094179\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.01356583833694458\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.017244458198547363\n",
      "Average validation loss for epoch 648: 0.010342404246330261\n",
      "Epoch 649/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0019841475877910852\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01865709386765957\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.016722509637475014\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.022827783599495888\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.04317175969481468\n",
      "Average validation loss for epoch 649: 0.02067265845835209\n",
      "Epoch 650/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0031607449054718018\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.021002965047955513\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.02293272130191326\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.022430086508393288\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.032407116144895554\n",
      "Average validation loss for epoch 650: 0.020386725664138794\n",
      "Epoch 651/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.001433023251593113\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.018113479018211365\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.021799752488732338\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.019275834783911705\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.017464257776737213\n",
      "Average validation loss for epoch 651: 0.015617269091308117\n",
      "Epoch 652/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0008167133782990277\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01519074011594057\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.01596466638147831\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.017368054017424583\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.020874574780464172\n",
      "Average validation loss for epoch 652: 0.014042949303984642\n",
      "Epoch 653/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0032651331275701523\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.02159097231924534\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.019107267260551453\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.015272720716893673\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.018675973638892174\n",
      "Average validation loss for epoch 653: 0.015582414343953133\n",
      "Epoch 654/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.004016953986138105\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01879660040140152\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.012106765061616898\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.006420825142413378\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.01716843619942665\n",
      "Average validation loss for epoch 654: 0.011701916344463825\n",
      "Epoch 655/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.006908781826496124\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.014850358478724957\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.0024836440570652485\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.00839584693312645\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.04304065927863121\n",
      "Average validation loss for epoch 655: 0.01513585727661848\n",
      "Epoch 656/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.00425171572715044\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.019052779302001\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.016251573339104652\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.018800927326083183\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.034453779458999634\n",
      "Average validation loss for epoch 656: 0.018562156707048416\n",
      "Epoch 657/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0029338058084249496\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.02138056792318821\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.01493805181235075\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.00791330635547638\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03616344556212425\n",
      "Average validation loss for epoch 657: 0.016665834933519363\n",
      "Epoch 658/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.005777622107416391\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.022194599732756615\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.011953134089708328\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.010862976312637329\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.04292464628815651\n",
      "Average validation loss for epoch 658: 0.018742594867944717\n",
      "Epoch 659/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002612697659060359\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.02089828811585903\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.019231721758842468\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.02187434770166874\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.027332087978720665\n",
      "Average validation loss for epoch 659: 0.018389828503131866\n",
      "Epoch 660/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0014229003572836518\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01838320679962635\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.020805152133107185\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.018918639048933983\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.01616629585623741\n",
      "Average validation loss for epoch 660: 0.015139239840209484\n",
      "Epoch 661/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0022744459565728903\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01780545338988304\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.009621438570320606\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.006494197994470596\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.019765594974160194\n",
      "Average validation loss for epoch 661: 0.01119222678244114\n",
      "Epoch 662/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.005908676888793707\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01447435561567545\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.003760111518204212\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.007286569103598595\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03905901312828064\n",
      "Average validation loss for epoch 662: 0.014097745530307293\n",
      "Epoch 663/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.007001817226409912\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.023676792159676552\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.020766040310263634\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.028647080063819885\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.05084322765469551\n",
      "Average validation loss for epoch 663: 0.0261869914829731\n",
      "Epoch 664/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0033973250538110733\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.020736267790198326\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.023011857643723488\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.026279369369149208\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.04180446267127991\n",
      "Average validation loss for epoch 664: 0.0230458565056324\n",
      "Epoch 665/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0034161258954554796\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.020910030230879784\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.019305536523461342\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.025158224627375603\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03254988417029381\n",
      "Average validation loss for epoch 665: 0.02026795968413353\n",
      "Epoch 666/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0037875473499298096\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.009052222594618797\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.0069497316144406796\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.014729800634086132\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.02025393396615982\n",
      "Average validation loss for epoch 666: 0.010954647324979305\n",
      "Epoch 667/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002833420177921653\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.014587565325200558\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.007246222347021103\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.017844097688794136\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.030454019084572792\n",
      "Average validation loss for epoch 667: 0.014593064785003662\n",
      "Epoch 668/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0028499385807663202\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.021070778369903564\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.021673545241355896\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.019496364519000053\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.017244113609194756\n",
      "Average validation loss for epoch 668: 0.01646694913506508\n",
      "Epoch 669/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0010745906038209796\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.014980785548686981\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.014111816883087158\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.0182321909815073\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.0174173004925251\n",
      "Average validation loss for epoch 669: 0.013163337484002113\n",
      "Epoch 670/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0026969604659825563\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.020783502608537674\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.022675611078739166\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.023006757721304893\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.0346352756023407\n",
      "Average validation loss for epoch 670: 0.020759621635079384\n",
      "Epoch 671/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.004126641433686018\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.023244336247444153\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.01690790243446827\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.006246556993573904\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.01720924861729145\n",
      "Average validation loss for epoch 671: 0.013546938076615334\n",
      "Epoch 672/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0040420484729111195\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.019945316016674042\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.012947797775268555\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.015681304037570953\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.041494220495224\n",
      "Average validation loss for epoch 672: 0.018822137266397476\n",
      "Epoch 673/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.005886551458388567\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.023260576650500298\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.02145545743405819\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.03011392056941986\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.04595879837870598\n",
      "Average validation loss for epoch 673: 0.02533506229519844\n",
      "Epoch 674/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.005603244062513113\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.021516142413020134\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.017220893874764442\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.013006114400923252\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.030584538355469704\n",
      "Average validation loss for epoch 674: 0.01758618652820587\n",
      "Epoch 675/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0014251578832045197\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.009434289298951626\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.012682504951953888\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.024366898462176323\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.023458709940314293\n",
      "Average validation loss for epoch 675: 0.014273512177169323\n",
      "Epoch 676/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0015925359912216663\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.017743708565831184\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.01859467849135399\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.0203227661550045\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.037743132561445236\n",
      "Average validation loss for epoch 676: 0.019199363887310028\n",
      "Epoch 677/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0020867299754172564\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.019251612946391106\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.0187288299202919\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.016826335340738297\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.01709514670073986\n",
      "Average validation loss for epoch 677: 0.01479773037135601\n",
      "Epoch 678/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0013229460455477238\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.008216078393161297\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.0024352523032575846\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.014207479543983936\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.021109076216816902\n",
      "Average validation loss for epoch 678: 0.009458166547119617\n",
      "Epoch 679/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0031315230298787355\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.02161773480474949\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.020667148754000664\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.020241200923919678\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.01844249665737152\n",
      "Average validation loss for epoch 679: 0.016820020973682404\n",
      "Epoch 680/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002407532650977373\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.020190447568893433\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.020480668172240257\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.02452942728996277\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.036932751536369324\n",
      "Average validation loss for epoch 680: 0.020908165723085403\n",
      "Epoch 681/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0020291132386773825\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.020128658041357994\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.02084493078291416\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.023542778566479683\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.0241871178150177\n",
      "Average validation loss for epoch 681: 0.018146518617868423\n",
      "Epoch 682/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0020483306143432856\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01900695078074932\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.013621985912322998\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.01640111580491066\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.020539352670311928\n",
      "Average validation loss for epoch 682: 0.01432354748249054\n",
      "Epoch 683/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002110893838107586\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01996910758316517\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.019705206155776978\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.021630892530083656\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.042783647775650024\n",
      "Average validation loss for epoch 683: 0.021239949390292168\n",
      "Epoch 684/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0019650289323180914\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.02072940208017826\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.01432332769036293\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.00895664095878601\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.01772947423160076\n",
      "Average validation loss for epoch 684: 0.01274077408015728\n",
      "Epoch 685/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0013224423164501786\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01584445871412754\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.015351873822510242\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.02123166061937809\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.042372893542051315\n",
      "Average validation loss for epoch 685: 0.019224664196372032\n",
      "Epoch 686/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0014449754962697625\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01965385489165783\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.01571536809206009\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.008345345966517925\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.024471065029501915\n",
      "Average validation loss for epoch 686: 0.013926121406257153\n",
      "Epoch 687/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0015101032331585884\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.015653274953365326\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.012550552375614643\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.014402044005692005\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03376137837767601\n",
      "Average validation loss for epoch 687: 0.0155754704028368\n",
      "Epoch 688/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002265411429107189\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.021214887499809265\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.014190043322741985\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.014504939317703247\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.04220633581280708\n",
      "Average validation loss for epoch 688: 0.018876323476433754\n",
      "Epoch 689/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0024959903676062822\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.020617499947547913\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.016808906570076942\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.020843228325247765\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.047864269465208054\n",
      "Average validation loss for epoch 689: 0.021725978702306747\n",
      "Epoch 690/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.00310615636408329\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.02068949304521084\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.018896223977208138\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.010227976366877556\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.020534023642539978\n",
      "Average validation loss for epoch 690: 0.014690774492919445\n",
      "Epoch 691/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0025529859121888876\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.017646515741944313\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.012965870089828968\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.008112835697829723\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.030933380126953125\n",
      "Average validation loss for epoch 691: 0.014442319050431252\n",
      "Epoch 692/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.004105701576918364\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.019460542127490044\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.01013732235878706\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.0070141213946044445\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.039901770651340485\n",
      "Average validation loss for epoch 692: 0.01612389087677002\n",
      "Epoch 693/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0021340104285627604\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.019579796120524406\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.020882681012153625\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.022077389061450958\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.026067480444908142\n",
      "Average validation loss for epoch 693: 0.01814827136695385\n",
      "Epoch 694/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002783403964713216\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.022072091698646545\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.005562445614486933\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.01351005956530571\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.01860523782670498\n",
      "Average validation loss for epoch 694: 0.012506647035479546\n",
      "Epoch 695/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0040041860193014145\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.008581387810409069\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.004726054612547159\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.014246744103729725\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.020226480439305305\n",
      "Average validation loss for epoch 695: 0.010356970131397247\n",
      "Epoch 696/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.00350191886536777\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01708756946027279\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.018099704757332802\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.01741785742342472\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.02526693604886532\n",
      "Average validation loss for epoch 696: 0.016274798661470413\n",
      "Epoch 697/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0016945763491094112\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.016702130436897278\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.01731777936220169\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.018608810380101204\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03156527504324913\n",
      "Average validation loss for epoch 697: 0.01717771217226982\n",
      "Epoch 698/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.001874410081654787\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.02095896750688553\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.021453166380524635\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.026519304141402245\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03783991560339928\n",
      "Average validation loss for epoch 698: 0.021729152649641037\n",
      "Epoch 699/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.00198967382311821\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01907079666852951\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.023714909330010414\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.029402777552604675\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.026999996975064278\n",
      "Average validation loss for epoch 699: 0.020235631614923477\n",
      "Epoch 700/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0023133272770792246\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.021355584263801575\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.02389802783727646\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.03052237629890442\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.04610002040863037\n",
      "Average validation loss for epoch 700: 0.02483786642551422\n",
      "Epoch 701/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0037764469161629677\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.021421343088150024\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.02385883964598179\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.027965789660811424\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.038442086428403854\n",
      "Average validation loss for epoch 701: 0.023092901334166527\n",
      "Epoch 702/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.008669222705066204\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.025666527450084686\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.02414078079164028\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.02819822169840336\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.042466092854738235\n",
      "Average validation loss for epoch 702: 0.02582816779613495\n",
      "Epoch 703/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.005442926660180092\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.021035073325037956\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.016374247148633003\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.023142069578170776\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.033193036913871765\n",
      "Average validation loss for epoch 703: 0.01983747072517872\n",
      "Epoch 704/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.01198005210608244\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.02433665283024311\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.017382720485329628\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.010684150271117687\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.055054355412721634\n",
      "Average validation loss for epoch 704: 0.02388758584856987\n",
      "Epoch 705/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.006637301295995712\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.017096756026148796\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.019839705899357796\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.024760214611887932\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.05816938355565071\n",
      "Average validation loss for epoch 705: 0.02530067227780819\n",
      "Epoch 706/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.007431716192513704\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.02829490415751934\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.02572701685130596\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.0532580129802227\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.059282198548316956\n",
      "Average validation loss for epoch 706: 0.034798771142959595\n",
      "Epoch 707/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.012196759693324566\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.020502187311649323\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.05916696414351463\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.03650279343128204\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.08267278224229813\n",
      "Average validation loss for epoch 707: 0.042208295315504074\n",
      "Epoch 708/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.02572108618915081\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.035640984773635864\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.0476815439760685\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.15666919946670532\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.18943548202514648\n",
      "Average validation loss for epoch 708: 0.09102965891361237\n",
      "Epoch 709/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.21852540969848633\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.1498616635799408\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.08530405163764954\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.12238579243421555\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.14392487704753876\n",
      "Average validation loss for epoch 709: 0.1440003663301468\n",
      "Epoch 710/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.18094772100448608\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.2666119635105133\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.2502756118774414\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.14898216724395752\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.14690305292606354\n",
      "Average validation loss for epoch 710: 0.19874410331249237\n",
      "Epoch 711/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.27206018567085266\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.2216806262731552\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.21304534375667572\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.14277471601963043\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.12331802397966385\n",
      "Average validation loss for epoch 711: 0.19457577168941498\n",
      "Epoch 712/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.23780220746994019\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.2187882512807846\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.20870625972747803\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.10019520670175552\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.026775343343615532\n",
      "Average validation loss for epoch 712: 0.15845346450805664\n",
      "Epoch 713/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.22787217795848846\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.18910960853099823\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.008061661384999752\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.014351730234920979\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.019308920949697495\n",
      "Average validation loss for epoch 713: 0.09174081683158875\n",
      "Epoch 714/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.16778646409511566\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.06168438866734505\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.004597661551088095\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.014718028716742992\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.02068350464105606\n",
      "Average validation loss for epoch 714: 0.053894005715847015\n",
      "Epoch 715/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.06213703379034996\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.011277451179921627\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.022079138085246086\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.01773044653236866\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03138835355639458\n",
      "Average validation loss for epoch 715: 0.028922483325004578\n",
      "Epoch 716/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002413088921457529\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01186417043209076\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.022003598511219025\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.01701248064637184\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03464331850409508\n",
      "Average validation loss for epoch 716: 0.0175873301923275\n",
      "Epoch 717/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002386430511251092\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.010956630110740662\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.018689559772610664\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.015596362762153149\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03774549067020416\n",
      "Average validation loss for epoch 717: 0.017074894160032272\n",
      "Epoch 718/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002833679551258683\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01244198065251112\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.01982708089053631\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.015929779037833214\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03967789188027382\n",
      "Average validation loss for epoch 718: 0.018142083659768105\n",
      "Epoch 719/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002576154191046953\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.018328281119465828\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.014826759696006775\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.014892581850290298\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03920121118426323\n",
      "Average validation loss for epoch 719: 0.01796499826014042\n",
      "Epoch 720/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0026027190033346415\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.017798615619540215\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.014438033103942871\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.014230716042220592\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.04127543047070503\n",
      "Average validation loss for epoch 720: 0.018069103360176086\n",
      "Epoch 721/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0026630887296050787\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.015111961401998997\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.015540543012320995\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.014313031919300556\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03381730988621712\n",
      "Average validation loss for epoch 721: 0.016289185732603073\n",
      "Epoch 722/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0021802191622555256\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.008762647397816181\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.01676992140710354\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.015143048949539661\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.04083846136927605\n",
      "Average validation loss for epoch 722: 0.016738858073949814\n",
      "Epoch 723/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002856225473806262\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.019550088793039322\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.018893403932452202\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.015730030834674835\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.036386121064424515\n",
      "Average validation loss for epoch 723: 0.0186831746250391\n",
      "Epoch 724/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0025448135565966368\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.012732189148664474\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.015098328702151775\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.008415959775447845\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03590284660458565\n",
      "Average validation loss for epoch 724: 0.01493882853537798\n",
      "Epoch 725/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0031287751626223326\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.018571607768535614\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.020922942087054253\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.01644398830831051\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03957488015294075\n",
      "Average validation loss for epoch 725: 0.019728440791368484\n",
      "Epoch 726/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0025700789410620928\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01959880441427231\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.023128768429160118\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.026572560891509056\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.04423778876662254\n",
      "Average validation loss for epoch 726: 0.02322160080075264\n",
      "Epoch 727/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0021851875353604555\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.019839158281683922\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.022634705528616905\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.023588821291923523\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03955957293510437\n",
      "Average validation loss for epoch 727: 0.02156148850917816\n",
      "Epoch 728/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0025479523465037346\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01922065205872059\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.02097667194902897\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.016957132145762444\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.035024065524339676\n",
      "Average validation loss for epoch 728: 0.018945295363664627\n",
      "Epoch 729/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0017329693073406816\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.016406623646616936\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.013412274420261383\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.010754406452178955\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03521816432476044\n",
      "Average validation loss for epoch 729: 0.015504887327551842\n",
      "Epoch 730/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0018719410290941596\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.008306102827191353\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.009096192196011543\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.007889172993600368\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.039699286222457886\n",
      "Average validation loss for epoch 730: 0.013372538611292839\n",
      "Epoch 731/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002303540473803878\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.020705033093690872\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.021574845537543297\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.026352688670158386\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.047842320054769516\n",
      "Average validation loss for epoch 731: 0.02375568449497223\n",
      "Epoch 732/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.001774631324224174\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.017818046733736992\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.021188102662563324\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.019116802141070366\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.040144313126802444\n",
      "Average validation loss for epoch 732: 0.020008379593491554\n",
      "Epoch 733/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0020560426637530327\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.018164949491620064\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.020178435370326042\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.022806311026215553\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.041565902531147\n",
      "Average validation loss for epoch 733: 0.020954327657818794\n",
      "Epoch 734/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002247636206448078\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.017910828813910484\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.020882584154605865\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.023688867688179016\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.04455878958106041\n",
      "Average validation loss for epoch 734: 0.021857742220163345\n",
      "Epoch 735/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.001985582523047924\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.019073467701673508\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.02279014326632023\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.026621684432029724\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.04235374554991722\n",
      "Average validation loss for epoch 735: 0.022564923390746117\n",
      "Epoch 736/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002861590823158622\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.014293513260781765\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.018400397151708603\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.015659186989068985\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.04160861670970917\n",
      "Average validation loss for epoch 736: 0.018564660102128983\n",
      "Epoch 737/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.003320544958114624\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.020927583798766136\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.021052725613117218\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.018847515806555748\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.040073078125715256\n",
      "Average validation loss for epoch 737: 0.020844290032982826\n",
      "Epoch 738/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0031055535655468702\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.010136558674275875\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.011857610195875168\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.006912844721227884\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.040957555174827576\n",
      "Average validation loss for epoch 738: 0.014594024047255516\n",
      "Epoch 739/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0033188611268997192\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.019008716568350792\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.02315683476626873\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.019721882417798042\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.04294255003333092\n",
      "Average validation loss for epoch 739: 0.02162976935505867\n",
      "Epoch 740/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.001990520628169179\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.015870360657572746\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.022039351984858513\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.018347667530179024\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03610891103744507\n",
      "Average validation loss for epoch 740: 0.018871363252401352\n",
      "Epoch 741/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002782512456178665\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.012191951274871826\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.019851671531796455\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.01684763841331005\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.032376229763031006\n",
      "Average validation loss for epoch 741: 0.01681000180542469\n",
      "Epoch 742/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0027471024077385664\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.011213124729692936\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.020237721502780914\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.015636136755347252\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.034365177154541016\n",
      "Average validation loss for epoch 742: 0.016839852556586266\n",
      "Epoch 743/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.003517526900395751\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.019647497683763504\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.01966094598174095\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.023451371118426323\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.042051855474710464\n",
      "Average validation loss for epoch 743: 0.02166583761572838\n",
      "Epoch 744/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.00295426812954247\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.019985871389508247\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.021061966195702553\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.02353382296860218\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.0401742048561573\n",
      "Average validation loss for epoch 744: 0.021542027592658997\n",
      "Epoch 745/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002886332804337144\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.021311132237315178\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.01940886676311493\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.021930264309048653\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03785930946469307\n",
      "Average validation loss for epoch 745: 0.020679181441664696\n",
      "Epoch 746/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0032247973140329123\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.02004033699631691\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.020078545436263084\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.022593505680561066\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.04050934314727783\n",
      "Average validation loss for epoch 746: 0.02128930576145649\n",
      "Epoch 747/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002824553055688739\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.019719788804650307\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.021031631156802177\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.021352631971240044\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.040654946118593216\n",
      "Average validation loss for epoch 747: 0.02111670933663845\n",
      "Epoch 748/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002476339926943183\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.013633436523377895\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.019558779895305634\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.021678611636161804\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.039678867906332016\n",
      "Average validation loss for epoch 748: 0.01940520666539669\n",
      "Epoch 749/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.001520955003798008\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.014970784075558186\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.020389581099152565\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.022488906979560852\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03472047671675682\n",
      "Average validation loss for epoch 749: 0.018818140029907227\n",
      "Epoch 750/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0012849491322413087\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.011903908103704453\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.02057764306664467\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.023988649249076843\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03485820069909096\n",
      "Average validation loss for epoch 750: 0.01852267049252987\n",
      "Epoch 751/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0021658584009855986\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.014589324593544006\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.019497359171509743\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.020764045417308807\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.042864840477705\n",
      "Average validation loss for epoch 751: 0.019976284354925156\n",
      "Epoch 752/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.001748542650602758\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.019436074420809746\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.0205851923674345\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.02532990835607052\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.04031187668442726\n",
      "Average validation loss for epoch 752: 0.02148231863975525\n",
      "Epoch 753/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0018388261087238789\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.020019246265292168\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.023224562406539917\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.019347641617059708\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.04112245887517929\n",
      "Average validation loss for epoch 753: 0.021110547706484795\n",
      "Epoch 754/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.001698608510196209\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.016253309324383736\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.02016260288655758\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.011017203330993652\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.0315227210521698\n",
      "Average validation loss for epoch 754: 0.01613088883459568\n",
      "Epoch 755/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.00455353781580925\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.00956355407834053\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.008246148936450481\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.014393514953553677\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.031662654131650925\n",
      "Average validation loss for epoch 755: 0.013683882541954517\n",
      "Epoch 756/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.005051597487181425\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.022513581439852715\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.019859865307807922\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.010387393645942211\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.031042730435729027\n",
      "Average validation loss for epoch 756: 0.017771033570170403\n",
      "Epoch 757/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.00816777441650629\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.019539615139365196\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.001853151828981936\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.0068301670253276825\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.021453870460391045\n",
      "Average validation loss for epoch 757: 0.011568916030228138\n",
      "Epoch 758/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.01965494453907013\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01019152719527483\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.007111500948667526\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.018460644409060478\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03483133763074875\n",
      "Average validation loss for epoch 758: 0.018049990758299828\n",
      "Epoch 759/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002023154404014349\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.019979124888777733\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.023375583812594414\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.030185744166374207\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.05221671238541603\n",
      "Average validation loss for epoch 759: 0.025556063279509544\n",
      "Epoch 760/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.00212329113855958\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.018735868856310844\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.02224569581449032\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.0251480545848608\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.06280132383108139\n",
      "Average validation loss for epoch 760: 0.02621084824204445\n",
      "Epoch 761/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0033409472089260817\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.02168821357190609\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.025558268651366234\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.027017690241336823\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.04249667748808861\n",
      "Average validation loss for epoch 761: 0.02402035892009735\n",
      "Epoch 762/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.011383206583559513\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.02271120436489582\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.021336540579795837\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.015906818211078644\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.04149186611175537\n",
      "Average validation loss for epoch 762: 0.022565927356481552\n",
      "Epoch 763/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.007164938375353813\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.017211440950632095\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.011291221715509892\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.022227579727768898\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.039260316640138626\n",
      "Average validation loss for epoch 763: 0.01943109929561615\n",
      "Epoch 764/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0014266144717112184\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.015351780690252781\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.01247349288314581\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.01591631956398487\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03827909007668495\n",
      "Average validation loss for epoch 764: 0.01668945886194706\n",
      "Epoch 765/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002049987204372883\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.018922464922070503\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.0205332413315773\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.02728891931474209\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.057244718074798584\n",
      "Average validation loss for epoch 765: 0.025207865983247757\n",
      "Epoch 766/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002188819693401456\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.02062029391527176\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.02329101972281933\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.02590911090373993\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.050706326961517334\n",
      "Average validation loss for epoch 766: 0.024543114006519318\n",
      "Epoch 767/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0025428279768675566\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.018647832795977592\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.020810993388295174\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.023489920422434807\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.045198217034339905\n",
      "Average validation loss for epoch 767: 0.02213795855641365\n",
      "Epoch 768/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0025643224362283945\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.019743097946047783\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.022268908098340034\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.025744520127773285\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.04042502120137215\n",
      "Average validation loss for epoch 768: 0.02214917168021202\n",
      "Epoch 769/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002444572513923049\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.018289750441908836\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.019195185974240303\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.021986981853842735\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.04182334244251251\n",
      "Average validation loss for epoch 769: 0.020747967064380646\n",
      "Epoch 770/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.004055608529597521\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.022039467468857765\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.012778698466718197\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.007565904874354601\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03857026621699333\n",
      "Average validation loss for epoch 770: 0.017001990228891373\n",
      "Epoch 771/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0030613772105425596\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01486185286194086\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.008496883325278759\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.009871868416666985\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03518585488200188\n",
      "Average validation loss for epoch 771: 0.014295565895736217\n",
      "Epoch 772/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0020204188767820597\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.013870302587747574\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.017988739535212517\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.017184210941195488\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.039481502026319504\n",
      "Average validation loss for epoch 772: 0.0181090347468853\n",
      "Epoch 773/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0035134137142449617\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.021120456978678703\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.01846216805279255\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.019159957766532898\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03917991742491722\n",
      "Average validation loss for epoch 773: 0.020287182182073593\n",
      "Epoch 774/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0033035401720553637\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.019263802096247673\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.018481113016605377\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.012552018277347088\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03385145589709282\n",
      "Average validation loss for epoch 774: 0.017490386962890625\n",
      "Epoch 775/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0025022963527590036\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.012304666452109814\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.013103353790938854\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.012280597351491451\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03676527738571167\n",
      "Average validation loss for epoch 775: 0.015391238033771515\n",
      "Epoch 776/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002154599642381072\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.017308974638581276\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.018575528636574745\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.014636361040174961\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03440776839852333\n",
      "Average validation loss for epoch 776: 0.01741664670407772\n",
      "Epoch 777/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0018433141522109509\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.012631491757929325\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.012912299484014511\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.01155728567391634\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.035729631781578064\n",
      "Average validation loss for epoch 777: 0.01493480522185564\n",
      "Epoch 778/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002511903177946806\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.015449639409780502\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.019669031724333763\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.021235520020127296\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03630514815449715\n",
      "Average validation loss for epoch 778: 0.0190342478454113\n",
      "Epoch 779/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.00244087353348732\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.017145760357379913\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.01911795139312744\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.022618329152464867\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.04531669244170189\n",
      "Average validation loss for epoch 779: 0.021327922120690346\n",
      "Epoch 780/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.003009973093867302\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01992681808769703\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.020660435780882835\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.0249189380556345\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.043155670166015625\n",
      "Average validation loss for epoch 780: 0.022334367036819458\n",
      "Epoch 781/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.003017611801624298\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.020308077335357666\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.02031644620001316\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.024787597358226776\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03879031166434288\n",
      "Average validation loss for epoch 781: 0.021444007754325867\n",
      "Epoch 782/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0026931148022413254\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.018977394327521324\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.01904350332915783\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.023557988926768303\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.04186370596289635\n",
      "Average validation loss for epoch 782: 0.021227141842246056\n",
      "Epoch 783/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0024124248884618282\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.019965315237641335\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.02048608660697937\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.023844214156270027\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.04310714080929756\n",
      "Average validation loss for epoch 783: 0.021963035687804222\n",
      "Epoch 784/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.00211210735142231\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.018720870837569237\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.02056908793747425\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.021697914227843285\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.04239574447274208\n",
      "Average validation loss for epoch 784: 0.021099144592881203\n",
      "Epoch 785/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0024672045838087797\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.020179102197289467\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.017766572535037994\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.02407999336719513\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03211309760808945\n",
      "Average validation loss for epoch 785: 0.019321193918585777\n",
      "Epoch 786/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002517123008146882\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.008325156755745411\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.004323724191635847\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.010265941731631756\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03643922135233879\n",
      "Average validation loss for epoch 786: 0.012374233454465866\n",
      "Epoch 787/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0029002937953919172\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01314457505941391\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.008556829765439034\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.012417338788509369\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.039468225091695786\n",
      "Average validation loss for epoch 787: 0.015297451987862587\n",
      "Epoch 788/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002742338227108121\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01307462528347969\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.016345033422112465\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.00985915306955576\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03133634105324745\n",
      "Average validation loss for epoch 788: 0.014671498909592628\n",
      "Epoch 789/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0028015589341521263\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01587134413421154\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.017295323312282562\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.01919780857861042\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.04472281411290169\n",
      "Average validation loss for epoch 789: 0.019977768883109093\n",
      "Epoch 790/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002826915355399251\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.017716141417622566\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.020541436970233917\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.02035200595855713\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03141288086771965\n",
      "Average validation loss for epoch 790: 0.01856987550854683\n",
      "Epoch 791/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0021305037662386894\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.015767069533467293\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.01694532297551632\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.025610601529479027\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.04168696328997612\n",
      "Average validation loss for epoch 791: 0.020428091287612915\n",
      "Epoch 792/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002745877718552947\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.019218403846025467\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.020036838948726654\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.019402312114834785\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03912177309393883\n",
      "Average validation loss for epoch 792: 0.020105039700865746\n",
      "Epoch 793/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.003520115977153182\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.020897040143609047\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.0223026592284441\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.025579145178198814\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.05602927878499031\n",
      "Average validation loss for epoch 793: 0.0256656464189291\n",
      "Epoch 794/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002583871828392148\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.020225847139954567\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.02284519374370575\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.02594100870192051\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.05676991119980812\n",
      "Average validation loss for epoch 794: 0.025673165917396545\n",
      "Epoch 795/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0031330964993685484\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.021265534684062004\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.024904310703277588\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.033280763775110245\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.06533607840538025\n",
      "Average validation loss for epoch 795: 0.02958395704627037\n",
      "Epoch 796/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0024724863469600677\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.02080310881137848\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.024086548015475273\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.03100997768342495\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.05746771767735481\n",
      "Average validation loss for epoch 796: 0.027167966589331627\n",
      "Epoch 797/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0055943927727639675\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.021828895434737206\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.02482551522552967\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.028581274673342705\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.0501365065574646\n",
      "Average validation loss for epoch 797: 0.026193317025899887\n",
      "Epoch 798/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0018359790556132793\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01855800859630108\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.022219954058527946\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.02519230544567108\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03506018966436386\n",
      "Average validation loss for epoch 798: 0.020573286339640617\n",
      "Epoch 799/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.004308982752263546\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.0238649919629097\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.009908590465784073\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.004524828400462866\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03978258743882179\n",
      "Average validation loss for epoch 799: 0.016477996483445168\n",
      "Epoch 800/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.010685913264751434\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.023289309814572334\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.010290765203535557\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.007328636944293976\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.017071017995476723\n",
      "Average validation loss for epoch 800: 0.01373312808573246\n",
      "Epoch 801/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002758125076070428\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.008708822540938854\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.0075920759700238705\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.010360445827245712\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.04780656471848488\n",
      "Average validation loss for epoch 801: 0.015445207245647907\n",
      "Epoch 802/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0023157396353781223\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.020758720114827156\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.01854332722723484\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.023303845897316933\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.056182343512773514\n",
      "Average validation loss for epoch 802: 0.024220794439315796\n",
      "Epoch 803/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0016226144507527351\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01944245584309101\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.02350575663149357\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.02666402794420719\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.04251062497496605\n",
      "Average validation loss for epoch 803: 0.022749096155166626\n",
      "Epoch 804/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0019207136938348413\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.020585721358656883\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.021651091054081917\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.022665122523903847\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.04510705545544624\n",
      "Average validation loss for epoch 804: 0.022385939955711365\n",
      "Epoch 805/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002666608663275838\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.019303813576698303\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.013711684383451939\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.0159484650939703\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.04078380763530731\n",
      "Average validation loss for epoch 805: 0.01848287507891655\n",
      "Epoch 806/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.005218318197876215\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.0228304173797369\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.010800889693200588\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.023722326382994652\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.04339488223195076\n",
      "Average validation loss for epoch 806: 0.02119336649775505\n",
      "Epoch 807/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.003576204413548112\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.02048935368657112\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.02136871963739395\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.016925768926739693\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03948991373181343\n",
      "Average validation loss for epoch 807: 0.020369991660118103\n",
      "Epoch 808/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0032089243177324533\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01979335956275463\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.014899708330631256\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.02353508584201336\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.05084522068500519\n",
      "Average validation loss for epoch 808: 0.02245645970106125\n",
      "Epoch 809/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002733476459980011\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.02074691839516163\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.024771325290203094\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.026791101321578026\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.045588910579681396\n",
      "Average validation loss for epoch 809: 0.02412634715437889\n",
      "Epoch 810/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0023456912022083998\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.021195178851485252\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.02106478251516819\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.021825602278113365\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03654563054442406\n",
      "Average validation loss for epoch 810: 0.020595377311110497\n",
      "Epoch 811/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0016230401815846562\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01833942160010338\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.021219944581389427\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.019193915650248528\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.035929467529058456\n",
      "Average validation loss for epoch 811: 0.019261157140135765\n",
      "Epoch 812/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.001572726876474917\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.019541814923286438\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.022075191140174866\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.020521722733974457\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03903280571103096\n",
      "Average validation loss for epoch 812: 0.020548854023218155\n",
      "Epoch 813/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0018989919917657971\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.019954083487391472\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.023303722962737083\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.025054005905985832\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.045357707887887955\n",
      "Average validation loss for epoch 813: 0.023113703355193138\n",
      "Epoch 814/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0018555010901764035\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.019168706610798836\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.02190745808184147\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.01901070401072502\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03242852911353111\n",
      "Average validation loss for epoch 814: 0.01887417957186699\n",
      "Epoch 815/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0011450016172602773\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.017227033153176308\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.019215881824493408\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.022794747725129128\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.04404168948531151\n",
      "Average validation loss for epoch 815: 0.02088487148284912\n",
      "Epoch 816/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0012933575781062245\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01774672605097294\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.02195885218679905\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.011300412006676197\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.018261853605508804\n",
      "Average validation loss for epoch 816: 0.014112239703536034\n",
      "Epoch 817/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002576210768893361\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.00804197508841753\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.0028139010537415743\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.007841311395168304\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.021411174908280373\n",
      "Average validation loss for epoch 817: 0.008536914363503456\n",
      "Epoch 818/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0016301182331517339\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.004689380060881376\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.01031489111483097\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.008102701045572758\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.036102861166000366\n",
      "Average validation loss for epoch 818: 0.01216799020767212\n",
      "Epoch 819/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0036284339148551226\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.022754734382033348\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.022065287455916405\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.025876933708786964\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.046159956604242325\n",
      "Average validation loss for epoch 819: 0.02409707009792328\n",
      "Epoch 820/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0027200086042284966\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.019916629418730736\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.020435677841305733\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.01697520911693573\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03420582786202431\n",
      "Average validation loss for epoch 820: 0.018850669264793396\n",
      "Epoch 821/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0021642784122377634\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.018165500834584236\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.019622789695858955\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.02887432835996151\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.0497739277780056\n",
      "Average validation loss for epoch 821: 0.023720165714621544\n",
      "Epoch 822/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.001364965457469225\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.017300814390182495\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.022532237693667412\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.018863694742321968\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.025936007499694824\n",
      "Average validation loss for epoch 822: 0.017199542373418808\n",
      "Epoch 823/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0011472241021692753\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.0057242196053266525\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.002905789064243436\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.011118303053081036\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03295030817389488\n",
      "Average validation loss for epoch 823: 0.010769168846309185\n",
      "Epoch 824/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.004910531919449568\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.016576331108808517\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.018255161121487617\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.011187559925019741\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.038944557309150696\n",
      "Average validation loss for epoch 824: 0.01797482743859291\n",
      "Epoch 825/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.004723374266177416\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.02016766183078289\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.012851343490183353\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.008572667837142944\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03264999762177467\n",
      "Average validation loss for epoch 825: 0.015793008729815483\n",
      "Epoch 826/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0027203529607504606\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.020526984706521034\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.0091193662956357\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.007523102220147848\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03551472723484039\n",
      "Average validation loss for epoch 826: 0.015080906450748444\n",
      "Epoch 827/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.004616245161741972\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.02247714065015316\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.00513292383402586\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.017885832116007805\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.030159905552864075\n",
      "Average validation loss for epoch 827: 0.016054410487413406\n",
      "Epoch 828/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0013817643048241735\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.0163570623844862\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.021611591801047325\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.025486426427960396\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.02931801788508892\n",
      "Average validation loss for epoch 828: 0.018830973654985428\n",
      "Epoch 829/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0016871043480932713\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01775374449789524\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.022459765896201134\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.0246773362159729\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.041675224900245667\n",
      "Average validation loss for epoch 829: 0.021650634706020355\n",
      "Epoch 830/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002808989956974983\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.021365979686379433\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.02097149007022381\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.01948740892112255\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.038985781371593475\n",
      "Average validation loss for epoch 830: 0.02072392962872982\n",
      "Epoch 831/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.003633529879152775\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.009090538136661053\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.006286281626671553\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.009007741697132587\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.018409525975584984\n",
      "Average validation loss for epoch 831: 0.009285522624850273\n",
      "Epoch 832/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002541551599279046\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.0034554051235318184\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.007532765623182058\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.010915539227426052\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.04012930393218994\n",
      "Average validation loss for epoch 832: 0.012914913706481457\n",
      "Epoch 833/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002451537875458598\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.018347779288887978\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.01692632958292961\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.014760536141693592\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03715868666768074\n",
      "Average validation loss for epoch 833: 0.017928972840309143\n",
      "Epoch 834/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0022230849135667086\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.019336143508553505\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.021164193749427795\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.025701677426695824\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.05218617245554924\n",
      "Average validation loss for epoch 834: 0.02412225678563118\n",
      "Epoch 835/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0021430065389722586\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.02068057283759117\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.02474154345691204\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.02929898537695408\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.04618960618972778\n",
      "Average validation loss for epoch 835: 0.024610742926597595\n",
      "Epoch 836/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0019344515167176723\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.019632991403341293\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.022148974239826202\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.02218308486044407\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.02044490911066532\n",
      "Average validation loss for epoch 836: 0.01726888120174408\n",
      "Epoch 837/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0016451012343168259\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.014934207312762737\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.018136413767933846\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.023675674572587013\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03581291064620018\n",
      "Average validation loss for epoch 837: 0.018840860575437546\n",
      "Epoch 838/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0021016281098127365\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01995057426393032\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.017981110140681267\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.020052066072821617\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03856899216771126\n",
      "Average validation loss for epoch 838: 0.01973087526857853\n",
      "Epoch 839/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0015559904277324677\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01808871515095234\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.019284287467598915\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.016167042776942253\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03611091896891594\n",
      "Average validation loss for epoch 839: 0.018241390585899353\n",
      "Epoch 840/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0024609940592199564\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.019148990511894226\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.019260188564658165\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.02267231047153473\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.04718378186225891\n",
      "Average validation loss for epoch 840: 0.02214525267481804\n",
      "Epoch 841/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0019699472468346357\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.02027425728738308\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.02346186339855194\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.026410698890686035\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.048044875264167786\n",
      "Average validation loss for epoch 841: 0.02403232827782631\n",
      "Epoch 842/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0024437750689685345\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.020483041182160378\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.022692212834954262\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.025013789534568787\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.0443272739648819\n",
      "Average validation loss for epoch 842: 0.02299201861023903\n",
      "Epoch 843/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002743711695075035\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.020528610795736313\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.02330770157277584\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.023566119372844696\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.04026336595416069\n",
      "Average validation loss for epoch 843: 0.022081902250647545\n",
      "Epoch 844/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0025121010839939117\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.02034659869968891\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.020770719274878502\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.02361949346959591\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.04186592623591423\n",
      "Average validation loss for epoch 844: 0.021822968497872353\n",
      "Epoch 845/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0026178814005106688\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.020496219396591187\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.022080034017562866\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.025420675054192543\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.040860697627067566\n",
      "Average validation loss for epoch 845: 0.02229510061442852\n",
      "Epoch 846/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0021617827005684376\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.018876036629080772\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.0172062236815691\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.023690512403845787\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.04393082484602928\n",
      "Average validation loss for epoch 846: 0.02117307484149933\n",
      "Epoch 847/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0021904257591813803\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.019855422899127007\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.02199290506541729\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.02707850933074951\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.04145611450076103\n",
      "Average validation loss for epoch 847: 0.022514676675200462\n",
      "Epoch 848/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002418011426925659\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.021134665235877037\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.019374923780560493\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.023542016744613647\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.042318303138017654\n",
      "Average validation loss for epoch 848: 0.0217575840651989\n",
      "Epoch 849/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.002577973296865821\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.020075155422091484\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.019408849999308586\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.007343133445829153\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.016698071733117104\n",
      "Average validation loss for epoch 849: 0.013220636174082756\n",
      "Epoch 850/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.01749209128320217\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.0021561512257903814\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.005340854171663523\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.008024145849049091\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.04288095608353615\n",
      "Average validation loss for epoch 850: 0.015178839676082134\n",
      "Epoch 851/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0034663632977753878\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.02099287509918213\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.020166389644145966\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.022618276998400688\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.04529272019863129\n",
      "Average validation loss for epoch 851: 0.022507324814796448\n",
      "Epoch 852/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.0021645529195666313\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.018274955451488495\n",
      "Training on fold 3/5\n",
      "Validation loss for fold 3/5: 0.015550999902188778\n",
      "Training on fold 4/5\n",
      "Validation loss for fold 4/5: 0.016983825713396072\n",
      "Training on fold 5/5\n",
      "Validation loss for fold 5/5: 0.03716856241226196\n",
      "Average validation loss for epoch 852: 0.018028579652309418\n",
      "Epoch 853/8000\n",
      "Training on fold 1/5\n",
      "Validation loss for fold 1/5: 0.001425257883965969\n",
      "Training on fold 2/5\n",
      "Validation loss for fold 2/5: 0.01641877554357052\n",
      "Training on fold 3/5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 412\u001b[0m\n\u001b[0;32m    403\u001b[0m training_data_transformed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m: [transform_and_scale_data(df, target_columns, transformation_metadata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscalers\u001b[39m\u001b[38;5;124m'\u001b[39m], keep_original_cols) \u001b[38;5;28;01mfor\u001b[39;00m df \u001b[38;5;129;01min\u001b[39;00m training_data_dfs()]\n\u001b[0;32m    411\u001b[0m \u001b[38;5;66;03m# run the workflow for training the model\u001b[39;00m\n\u001b[1;32m--> 412\u001b[0m checkpoint_path \u001b[38;5;241m=\u001b[39m \u001b[43mrun_workflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_data_transformed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_columns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    413\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minput_window\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforecast_horizon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    415\u001b[0m \u001b[38;5;66;03m# run the workflow for training the model\u001b[39;00m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[2], line 328\u001b[0m, in \u001b[0;36mrun_workflow\u001b[1;34m(training_data_transformed, target_variables, input_window, forecast_horizon, stride, epochs, batch_size, patience, checkpoint_path)\u001b[0m\n\u001b[0;32m    325\u001b[0m dataset \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset\u001b[38;5;241m.\u001b[39mfrom_tensor_slices((X_train, y_train))\u001b[38;5;241m.\u001b[39mbatch(batch_size)\u001b[38;5;241m.\u001b[39mprefetch(tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mAUTOTUNE)\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x_batch, y_batch \u001b[38;5;129;01min\u001b[39;00m dataset:\n\u001b[1;32m--> 328\u001b[0m     \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    330\u001b[0m \u001b[38;5;66;03m# Validation\u001b[39;00m\n\u001b[0;32m    331\u001b[0m X_val, y_val \u001b[38;5;241m=\u001b[39m X_val_all[fold], y_val_all[fold]\n",
      "File \u001b[1;32mc:\\Users\\bnsoh2\\Desktop\\venvs\\ml_env\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\bnsoh2\\Desktop\\venvs\\ml_env\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\bnsoh2\\Desktop\\venvs\\ml_env\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\bnsoh2\\Desktop\\venvs\\ml_env\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    146\u001b[0m   (concrete_function,\n\u001b[0;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\bnsoh2\\Desktop\\venvs\\ml_env\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs)\u001b[0m\n\u001b[0;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1351\u001b[0m     args,\n\u001b[0;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1353\u001b[0m     executing_eagerly)\n\u001b[0;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\bnsoh2\\Desktop\\venvs\\ml_env\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
      "File \u001b[1;32mc:\\Users\\bnsoh2\\Desktop\\venvs\\ml_env\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1460\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1461\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1462\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1463\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1472\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\bnsoh2\\Desktop\\venvs\\ml_env\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.signal import savgol_filter\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Reshape, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l1, l2 \n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "# Check TensorFlow GPU availability\n",
    "if tf.test.is_gpu_available(cuda_only=False, min_cuda_compute_capability=None):\n",
    "    print(\"TensorFlow will use the GPU!\")\n",
    "else:\n",
    "    print(\"TensorFlow cannot find a GPU!\")\n",
    "\n",
    "\n",
    "\n",
    "def subtract_mean(df, target_columns):\n",
    "    mean_values = {}\n",
    "    for col in target_columns:\n",
    "        mean_value = df[col].mean()  \n",
    "        df[col] -= mean_value\n",
    "        mean_values[col] = mean_value\n",
    "    return df, mean_values\n",
    "\n",
    "\n",
    "\n",
    "def create_derivative_columns(df, target_columns, keep_original_cols=True):\n",
    "    \"\"\"Calculates difference-based derivatives of specified columns.\n",
    "\n",
    "    Args:\n",
    "        df: Pandas DataFrame containing the data.\n",
    "        target_columns: List of columns for which derivatives are calculated.\n",
    "        keep_original_cols: If True, creates new columns; otherwise overwrites.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with derivative columns, plus initial values if needed.\n",
    "    \"\"\"\n",
    "\n",
    "    initial_values = {}  # Store initial values for reconstruction\n",
    "\n",
    "    for col in target_columns:\n",
    "        deriv_col_name = f\"{col}_deriv\"\n",
    "\n",
    "        if keep_original_cols:\n",
    "            df[deriv_col_name] = df[col].diff()  # Calculate differences\n",
    "            \n",
    "            #  #Plot the original and derived columns\n",
    "            # plt.figure(figsize=(10, 6))\n",
    "            # plt.plot(df[col], label=col)\n",
    "            # plt.plot(df[deriv_col_name], label=deriv_col_name)\n",
    "            # plt.xlabel('Time')\n",
    "            # plt.ylabel('Value')\n",
    "            # plt.title(f'{col} vs {deriv_col_name}')\n",
    "            # plt.legend()\n",
    "            # plt.show()\n",
    "            \n",
    "        else:\n",
    "            initial_values[col] = df[col].iloc[0]  # Store initial value\n",
    "            df[col] = df[col].diff()  \n",
    "            \n",
    "\n",
    "    return df, initial_values  # Return initial values as well\n",
    "\n",
    "def scale_dataframe(df, scalers):\n",
    "    \"\"\"\n",
    "    Optimally scale all columns in a DataFrame using MinMaxScaler, adjusting for an expanded range with a buffer. \n",
    "    This involves creating a dummy range for scaler fitting, then scaling the original data with the adjusted scaler.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame with columns to be scaled.\n",
    "        scalers (dict): Dictionary storing the scalers for each column.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Scaled DataFrame using the optimally adjusted scalers.\n",
    "        dict: Dictionary of the adjusted scalers.\n",
    "    \"\"\"\n",
    "    scaled_df = pd.DataFrame()  # Initialize an empty DataFrame for scaled values\n",
    "    for column in df.columns:\n",
    "        # Check if a scaler already exists; if not, proceed to create and fit a new one\n",
    "        if column not in scalers:\n",
    "            # Calculate the original range and apply a 30% buffer\n",
    "            col_min, col_max = df[column].min(), df[column].max()\n",
    "            range_buffer = (col_max - col_min) * 0.3  # 30% buffer\n",
    "            buffered_min = col_min - range_buffer\n",
    "            buffered_max = col_max + range_buffer\n",
    "\n",
    "            # Create a new scaler and fit it on the buffered range\n",
    "            scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "            scaler.fit([[buffered_min], [buffered_max]])\n",
    "            scalers[column] = scaler\n",
    "\n",
    "        # Scale the original data with the adjusted scaler\n",
    "        scaled_values = scalers[column].transform(df[[column]].values.reshape(-1, 1)).flatten()  # Flatten the array here\n",
    "        scaled_df[column] = scaled_values\n",
    "\n",
    "\n",
    "    return scaled_df, scalers\n",
    "\n",
    "\n",
    "def transform_and_scale_data(df, target_columns, scalers, keep_original_cols=True):\n",
    "    \"\"\"\n",
    "    Transforms and scales the data in the DataFrame for neural network input, returning the\n",
    "    transformed DataFrame, updated scalers, and transformation metadata.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame.\n",
    "        target_columns (list): List of target column names.\n",
    "        scalers (dict): Dictionary containing MinMaxScalers for each column, can be empty.\n",
    "        keep_original_cols (bool): If True, keeps original columns unchanged except for scaling;\n",
    "                                   if False, applies transformations directly on the target columns.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The transformed and scaled DataFrame.\n",
    "        dict: Updated dictionary containing MinMaxScalers for each column.\n",
    "        dict: A dictionary containing transformation metadata for the target columns.\n",
    "    \"\"\"\n",
    "\n",
    "    # Copy DataFrame to avoid modifying the original\n",
    "    df_transformed = df.copy()\n",
    "\n",
    "    \n",
    "    # Subtract mean from target columns\n",
    "    df_transformed, mean_values = subtract_mean(df_transformed, target_columns)\n",
    "    \n",
    "    # Apply transformations directly using helper functions\n",
    "    df_transformed, initial_values = create_derivative_columns(df_transformed, target_columns, keep_original_cols)\n",
    "    \n",
    "    # Deleting or adjusting rows as necessary (e.g., due to NaN values from differentiation)\n",
    "    df_transformed = df_transformed.iloc[1:]\n",
    "    \n",
    "    # Scale all columns in df_transformed\n",
    "    df_transformed, scalers = scale_dataframe(df_transformed, scalers)\n",
    "    \n",
    "    print(f\"Shape of transformed DataFrame: {df_transformed.shape}\")\n",
    "    \n",
    "    # Metadata for reverse transformation\n",
    "    transformation_metadata = {\n",
    "        'means': mean_values,\n",
    "        'scalers': scalers,\n",
    "        'keep_original_cols': keep_original_cols,\n",
    "        'initial_values': initial_values\n",
    "    }\n",
    "    \n",
    "    # add 'precip_irrig_bool' as a binned column with 0 or 1\n",
    "    df_transformed['precip_irrig_bool'] = df_transformed['precip_irrig_log'].apply(lambda x: 1 if x > 0 else 0)\n",
    "    \n",
    "    # Metadata for reverse transformation\n",
    "    transformation_metadata = {\n",
    "        'means': mean_values,\n",
    "        'scalers': scalers,\n",
    "        'keep_original_cols': keep_original_cols,\n",
    "        'initial_values': initial_values,\n",
    "        'columns': df.columns.tolist()\n",
    "    }\n",
    "    \n",
    "\n",
    "\n",
    "    return df_transformed, transformation_metadata\n",
    "\n",
    "\n",
    "\n",
    "def reverse_transform_and_scale_data(df, transformation_metadata, target_columns):\n",
    "    \"\"\"\n",
    "    Reverses the transformations and scaling applied to the DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The transformed and scaled DataFrame.\n",
    "        transformation_metadata (dict): A dictionary containing transformation metadata.\n",
    "        target_columns (list): List of target columns to be reverse transformed and scaled.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with reversed transformations and scaling.\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract metadata\n",
    "    scalers = transformation_metadata['scalers']\n",
    "    mean_values = transformation_metadata['means']\n",
    "    initial_values = transformation_metadata['initial_values']\n",
    "    keep_original_cols = transformation_metadata['keep_original_cols']\n",
    "\n",
    "    # Print dimensions of df\n",
    "    print(f\"Shape of input DataFrame: {df.shape}\")\n",
    "\n",
    "    # Reverse scale the target columns\n",
    "    for column in target_columns:\n",
    "        if column in scalers:\n",
    "            # Reshape data for inverse_transform\n",
    "            scaled_data = df[[column]].values\n",
    "            # Apply inverse_transform\n",
    "            df[column] = scalers[column].inverse_transform(scaled_data)\n",
    "\n",
    "    # Apply undifferencing with cumsum() \n",
    "    for column in target_columns:\n",
    "        # Reverse subtract mean from target columns if they were mean-adjusted\n",
    "        if column in mean_values:\n",
    "            print(f\"Mean for {column}: \", mean_values[column])\n",
    "            df[column] = df[column] + mean_values[column]\n",
    "            print(f\"Reversed mean for {column}: \", df[column].head())\n",
    "\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Sequence Creation Function\n",
    "def create_sequences(input_data, target_data, input_window, forecast_horizon, stride=1):\n",
    "    X, y = [], []\n",
    "    for start in range(len(input_data) - input_window - forecast_horizon + stride):\n",
    "        end = start + input_window\n",
    "        X.append(input_data[start:end])\n",
    "        y.append(target_data[end:end + forecast_horizon])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "\n",
    "def build_model(input_shape, num_targets):\n",
    "    model = Sequential([\n",
    "        LSTM(256, input_shape=input_shape, return_sequences=True, kernel_regularizer=l2(0.02)), \n",
    "        BatchNormalization(),\n",
    "        Dropout(0.2),\n",
    "        LSTM(128, return_sequences=True),  \n",
    "        BatchNormalization(),\n",
    "        Dropout(0.2),\n",
    "        LSTM(64, return_sequences=True),  \n",
    "        BatchNormalization(),\n",
    "        Dropout(0.1),\n",
    "        LSTM(64, return_sequences=True),  \n",
    "        BatchNormalization(),\n",
    "        Dropout(0.1),\n",
    "        LSTM(32, return_sequences=False),\n",
    "        Dense(96 * num_targets), \n",
    "        Reshape((96, num_targets)) \n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def chronological_split(X, y, test_size=0.2):\n",
    "    # Calculate the index to split the data\n",
    "    total_samples = len(X)\n",
    "    split_index = int(total_samples * (1 - test_size))\n",
    "    \n",
    "    # Split the data chronologically\n",
    "    X_train = X[:split_index]\n",
    "    X_val = X[split_index:]\n",
    "    y_train = y[:split_index]\n",
    "    y_val = y[split_index:]\n",
    "    \n",
    "    return X_train, X_val, y_train, y_val\n",
    "\n",
    "# Learning Rate Scheduler function\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)\n",
    "\n",
    "# Create a LearningRateScheduler callback\n",
    "callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "\n",
    "\n",
    "\n",
    "# Define the training step\n",
    "@tf.function()\n",
    "def train_step(model, optimizer, loss_function, x_batch, y_batch):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(x_batch, training=True)\n",
    "        loss = loss_function(y_batch, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return loss\n",
    "\n",
    "# Define the validation step\n",
    "@tf.function()\n",
    "def val_step(model, loss_function, x_batch, y_batch):\n",
    "    predictions = model(x_batch, training=False)\n",
    "    loss = loss_function(y_batch, predictions)\n",
    "    return loss\n",
    "\n",
    "def run_workflow(training_data_transformed, target_variables, input_window, forecast_horizon, stride, epochs, batch_size, patience, checkpoint_path):\n",
    "    X_train_all, X_val_all, y_train_all, y_val_all = [], [], [], []\n",
    "    dataframe_identifiers = []\n",
    "    n_splits = 5  # Define the number of splits for cross-validation\n",
    "\n",
    "    # Data preparation\n",
    "    for i, transformed_data in enumerate(training_data_transformed()):\n",
    "        df = transformed_data[0]\n",
    "        X, y = create_sequences(df.values, df[target_variables].values, input_window, forecast_horizon, stride)\n",
    "        tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "        \n",
    "        for fold, (train_index, val_index) in enumerate(tscv.split(X)):\n",
    "            print(f\"Processing fold {fold+1}/{n_splits} for DataFrame_{i}\")\n",
    "            X_train, X_val = X[train_index], X[val_index]\n",
    "            y_train, y_val = y[train_index], y[val_index]\n",
    "            \n",
    "            X_train_all.append(X_train)\n",
    "            X_val_all.append(X_val)\n",
    "            y_train_all.append(y_train)\n",
    "            y_val_all.append(y_val)\n",
    "        \n",
    "        dataframe_identifiers.append(f\"DataFrame_{i}\")\n",
    "\n",
    "    # Model and training setup\n",
    "    model = build_model((input_window, X_train_all[0].shape[2]), len(target_variables))\n",
    "    optimizer = tf.keras.optimizers.Adam()\n",
    "    loss_function = tf.keras.losses.MeanSquaredError()\n",
    "    best_val_loss = np.inf\n",
    "\n",
    "    # Training and validation\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "        epoch_val_losses = []\n",
    "\n",
    "        for fold in range(n_splits):\n",
    "            print(f\"Training on fold {fold + 1}/{n_splits}\")\n",
    "            X_train, y_train = X_train_all[fold], y_train_all[fold]\n",
    "\n",
    "            dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "            for x_batch, y_batch in dataset:\n",
    "                train_step(model, optimizer, loss_function, x_batch, y_batch)\n",
    "\n",
    "            # Validation\n",
    "            X_val, y_val = X_val_all[fold], y_val_all[fold]\n",
    "            val_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val)).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "            val_losses = []\n",
    "            for x_batch, y_batch in val_dataset:\n",
    "                val_loss = val_step(model, loss_function, x_batch, y_batch)\n",
    "                val_losses.append(val_loss.numpy())\n",
    "\n",
    "            avg_val_loss = np.mean(val_losses)\n",
    "            epoch_val_losses.append(avg_val_loss)\n",
    "            print(f\"Validation loss for fold {fold+1}/{n_splits}: {avg_val_loss}\")\n",
    "\n",
    "        # Average validation loss across folds\n",
    "        average_val_loss = np.mean(epoch_val_losses)\n",
    "        print(f\"Average validation loss for epoch {epoch+1}: {average_val_loss}\")\n",
    "\n",
    "        # Early stopping and model saving logic\n",
    "        if average_val_loss < best_val_loss:\n",
    "            best_val_loss = average_val_loss\n",
    "            model.save(checkpoint_path)\n",
    "            print(f\"Model saved at epoch {epoch+1} with validation loss: {average_val_loss}\")\n",
    "            wait = 0  # Reset wait counter after improvement\n",
    "        else:\n",
    "            wait += 1\n",
    "            if wait >= patience:\n",
    "                print(f\"Stopping early due to no improvement in validation loss for {patience} epochs.\")\n",
    "                break\n",
    "\n",
    "    return checkpoint_path\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Example Usage\n",
    "plot_numbers = [2014, 2015, 2007]#, 2001]\n",
    "\n",
    "\n",
    "# Initialize a scaler\n",
    "scalers = {}\n",
    "\n",
    "# *** Important: Update the target_columns and continuous_columns based on your chosen target columns ***\n",
    "# *** Any columns included in target_columns should be removed from continuous_columns ***\n",
    "target_columns = ['VWC_06', 'VWC_18', 'VWC_30']\n",
    "time_columns = ['day_sin', 'day_cos', 'hour_sin', 'hour_cos', 'dow_sin', 'dow_cos']\n",
    "continuous_columns = [\n",
    "    'Ta_2m_Avg', 'RH_2m_Avg', 'Solar_2m_Avg', 'WndAveSpd_3m', 'Rain_1m_Tot', 'Dp_2m_Avg',\n",
    "    'TaMax_2m', 'TaMin_2m', 'RHMax_2m', 'RHMin_2m', 'HeatIndex_2m_Avg',\n",
    "    'daily_et', 'CWSI', 'SWSI', 'irrigation', 'precip_irrig','canopy_temp'\n",
    "]\n",
    "derivative_columns = ['precip_irrig']\n",
    "\n",
    "input_window = 168\n",
    "forecast_horizon = 96\n",
    "stride = 1\n",
    "epochs = 8000\n",
    "patience = 500\n",
    "batch_size = 32  \n",
    "checkpoint_path = \"./LSTM\"\n",
    "\n",
    "\n",
    "\n",
    "# Set to True to keep original columns unchanged\n",
    "keep_original_cols=True\n",
    "\n",
    "\n",
    "# Lambda function to handle training data and plot numbers\n",
    "training_data_dfs = lambda: [process_data_for_plot(plot) for plot in plot_numbers]\n",
    "\n",
    "\n",
    "# run once to get the transformation metadata\n",
    "_, transformation_metadata = transform_and_scale_data(training_data_dfs()[0], target_columns, scalers, keep_original_cols)\n",
    "\n",
    "# re-run with the transformation metadata for all training dataframes\n",
    "training_data_transformed = lambda: [transform_and_scale_data(df, target_columns, transformation_metadata['scalers'], keep_original_cols) for df in training_data_dfs()]\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# run the workflow for training the model\n",
    "checkpoint_path = run_workflow(training_data_transformed, target_columns, \n",
    "                                      input_window, forecast_horizon, stride, epochs, batch_size, patience, checkpoint_path)\n",
    "\n",
    "# run the workflow for training the model\n",
    "import pickle\n",
    "\n",
    "# Store the transformation metadata in checkpoint_path\n",
    "with open(f\"{checkpoint_path}/transformation_metadata1.pkl\", \"wb\") as file:\n",
    "    pickle.dump(transformation_metadata, file)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the workflow for training the model\n",
    "import pickle\n",
    "\n",
    "# Store the transformation metadata in checkpoint_path\n",
    "with open(f\"{checkpoint_path}/transformation_metadata1.pkl\", \"wb\") as file:\n",
    "    pickle.dump(transformation_metadata, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing plot number 2013\n",
      "Shape of transformed DataFrame: (833, 28)\n",
      "Means of the transformed data\n",
      "Ta_2m_Avg            0.514028\n",
      "RH_2m_Avg            0.561025\n",
      "Solar_2m_Avg         0.368935\n",
      "WndAveSpd_3m         0.373158\n",
      "Dp_2m_Avg            0.540345\n",
      "TaMax_2m             0.514284\n",
      "TaMin_2m             0.513267\n",
      "RHMax_2m             0.563949\n",
      "RHMin_2m             0.558389\n",
      "HeatIndex_2m_Avg     0.535314\n",
      "canopy_temp          0.514868\n",
      "VWC_06               0.533397\n",
      "VWC_18               0.466073\n",
      "VWC_30               0.433098\n",
      "daily_et             0.370864\n",
      "CWSI                 0.483845\n",
      "SWSI                 0.503080\n",
      "precip_irrig         0.191979\n",
      "day_sin              0.573683\n",
      "day_cos              0.378254\n",
      "hour_sin             0.496685\n",
      "hour_cos             0.500888\n",
      "dow_sin              0.495970\n",
      "dow_cos              0.480424\n",
      "precip_irrig_log     0.195014\n",
      "VWC_06_deriv         0.355560\n",
      "VWC_18_deriv         0.311325\n",
      "VWC_30_deriv         0.337294\n",
      "precip_irrig_bool    1.000000\n",
      "dtype: float64\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "Sequence shape: (1, 168, 29)\n",
      "Sequence (top 3 lines):\n",
      "[[0.56571246 0.6117826  0.56576549 0.33408017 0.70071939 0.5659152\n",
      "  0.56490276 0.62016511 0.6046566  0.6177344  0.71876931 0.68936199\n",
      "  0.41209857 0.41474668 0.32455432 0.48820707 0.22534663 0.1875\n",
      "  0.95961889 0.11623546 0.27902913 0.27902913 0.75060554 0.68871108\n",
      "  0.1875     0.31387936 0.11705932 0.31849742 1.        ]\n",
      " [0.58245985 0.60450768 0.67500643 0.29006177 0.71823345 0.58283887\n",
      "  0.58141645 0.61536416 0.59552436 0.64918451 0.69443137 0.68378295\n",
      "  0.40219713 0.41253256 0.32455432 0.48820707 0.25930249 0.1875\n",
      "  0.95961889 0.11623546 0.22936706 0.34375    0.75060554 0.68871108\n",
      "  0.1875     0.32174986 0.15166486 0.32266583 1.        ]\n",
      " [0.62945001 0.5389825  0.76939468 0.38303719 0.71718039 0.62959227\n",
      "  0.6286012  0.54785061 0.53096603 0.71133672 0.7309712  0.67929477\n",
      "  0.3942471  0.41078873 0.32455432 0.48820707 0.27840266 0.1875\n",
      "  0.95961889 0.11623546 0.19814818 0.41911905 0.75060554 0.68871108\n",
      "  0.1875     0.32855435 0.18255121 0.32597842 1.        ]]\n",
      "Predicted shape: (1, 96, 3)\n",
      "Predicted (top 3 lines):\n",
      "[[0.61083496 0.5866513  0.47748628]\n",
      " [0.6046584  0.58666503 0.46994823]\n",
      " [0.6026085  0.5827683  0.46543312]]\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "       VWC_06    VWC_18    VWC_30\n",
      "168  0.610835  0.586651  0.477486\n",
      "169  0.604658  0.586665  0.469948\n",
      "170  0.602609  0.582768  0.465433\n",
      "171  0.598187  0.577459  0.456721\n",
      "172  0.595611  0.570505  0.455879\n",
      "Plotting predictions and actuals before reverse transformation and scaling\n",
      "Values of predictions_df  and actuals_df before reverse transformation and scaling\n",
      "       VWC_06    VWC_18    VWC_30\n",
      "168  0.610835  0.586651  0.477486\n",
      "169  0.604658  0.586665  0.469948\n",
      "170  0.602609  0.582768  0.465433\n",
      "       VWC_06    VWC_18    VWC_30\n",
      "168  0.494491  0.170762  0.238508\n",
      "169  0.493064  0.168732  0.234721\n",
      "170  0.491211  0.166567  0.230871\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1000 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of input DataFrame: (576, 3)\n",
      "Mean for VWC_06:  17.820361585349556\n",
      "Reversed mean for VWC_06:  168    18.797558\n",
      "169    18.719418\n",
      "170    18.693485\n",
      "171    18.637545\n",
      "172    18.604961\n",
      "Name: VWC_06, dtype: float32\n",
      "Mean for VWC_18:  18.113769235404764\n",
      "Reversed mean for VWC_18:  168    19.459984\n",
      "169    19.460138\n",
      "170    19.416651\n",
      "171    19.357391\n",
      "172    19.279793\n",
      "Name: VWC_18, dtype: float32\n",
      "Mean for VWC_30:  22.610070112912528\n",
      "Reversed mean for VWC_30:  168    23.131231\n",
      "169    23.042765\n",
      "170    22.989775\n",
      "171    22.887533\n",
      "172    22.877649\n",
      "Name: VWC_30, dtype: float32\n",
      "Shape of input DataFrame: (576, 3)\n",
      "Mean for VWC_06:  17.820361585349556\n",
      "Reversed mean for VWC_06:  168    17.325695\n",
      "169    17.307639\n",
      "170    17.284199\n",
      "171    17.260483\n",
      "172    17.239968\n",
      "Name: VWC_06, dtype: float64\n",
      "Mean for VWC_18:  18.113769235404764\n",
      "Reversed mean for VWC_18:  168    14.818646\n",
      "169    14.795986\n",
      "170    14.771826\n",
      "171    14.755425\n",
      "172    14.735107\n",
      "Name: VWC_18, dtype: float64\n",
      "Mean for VWC_30:  22.610070112912528\n",
      "Reversed mean for VWC_30:  168    20.326582\n",
      "169    20.282137\n",
      "170    20.236949\n",
      "171    20.196801\n",
      "172    20.163216\n",
      "Name: VWC_30, dtype: float64\n",
      "Values of predictions_df  and actuals_df after reverse transformation and scaling\n",
      "        VWC_06     VWC_18     VWC_30\n",
      "168  18.797558  19.459984  23.131231\n",
      "169  18.719418  19.460138  23.042765\n",
      "170  18.693485  19.416651  22.989775\n",
      "        VWC_06     VWC_18     VWC_30\n",
      "168  17.325695  14.818646  20.326582\n",
      "169  17.307639  14.795986  20.282137\n",
      "170  17.284199  14.771826  20.236949\n",
      "Plotting predictions and actuals after reverse transformation and scaling\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1000 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def plot_predictions(predictions_df, actuals_df, target_columns, plot_number):\n",
    "    num_plots = len(target_columns)\n",
    "    num_rows = int(np.ceil(num_plots / 2))  # You can adjust the number of columns per row if you like\n",
    "    plt.figure(figsize=(15, 5 * num_rows))  # Adjust the figure size as needed\n",
    "    for i, column in enumerate(target_columns):\n",
    "        plt.subplot(num_rows, 2, i + 1)  # Adjust the number of columns per row if you like\n",
    "        plt.plot(predictions_df.index, predictions_df[column], label=f'Predicted {column}', color='red', alpha=0.7)\n",
    "        plt.plot(actuals_df.index, actuals_df[column], label=f'Actual {column}', color='blue')\n",
    "        plt.legend()\n",
    "        plt.title(f'{column} for Plot {plot_number}')\n",
    "        plt.xlabel('Timestamp')\n",
    "        plt.ylabel('Value')\n",
    "        plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def predict_with_sliding_window(model, df, current_transformation_metadata, target_columns, input_window, forecast_horizon, plot_number):\n",
    "    # Create input& target data, input data is all columns except target columns\n",
    "    target_data = df[target_columns].values\n",
    "    input_data = df.values\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    timestamps = []\n",
    "    \n",
    "    # first iteration flag\n",
    "    first_iter = True\n",
    "\n",
    "    # Adjust stride based on prediction: 1 for continuous sliding\n",
    "    stride = forecast_horizon\n",
    "    for start in range(0, len(df) - input_window - forecast_horizon + 1, stride):\n",
    "        end = start + input_window\n",
    "        if end + forecast_horizon > len(input_data):\n",
    "            break\n",
    "        sequence = input_data[start:end]\n",
    "        sequence = sequence.reshape((1, input_window, len(input_data[0])))\n",
    "\n",
    "        \n",
    "\n",
    "        pred = model.predict(sequence)\n",
    "\n",
    "        \n",
    "        if first_iter:\n",
    "            print(f\"Sequence shape: {sequence.shape}\")\n",
    "            # To print the top 3 lines, slice the second dimension (sequence length)\n",
    "            print(\"Sequence (top 3 lines):\")\n",
    "            print(sequence[0, :3, :])  # Access the first element of the first dimension, then slice\n",
    "            print(f\"Predicted shape: {pred.shape}\")\n",
    "            # Similarly, for the predictions, slice the second dimension\n",
    "            print(\"Predicted (top 3 lines):\")\n",
    "            print(pred[0, :3, :])  # Access the first element of the first dimension, then slice\n",
    "        \n",
    "            first_iter = False\n",
    "\n",
    "\n",
    "        pred = pred.reshape(-1, pred.shape[-1])\n",
    "        predictions.append(pred)\n",
    "        actuals.append(target_data[end:end + forecast_horizon])\n",
    "        timestamp_series = pd.Series(df.index[end:end + forecast_horizon], index=df.index[end:end + forecast_horizon])\n",
    "        timestamps.append(timestamp_series)\n",
    "\n",
    "    predictions = np.concatenate(predictions)\n",
    "    actuals = np.concatenate(actuals)\n",
    "    timestamps = pd.concat(timestamps)\n",
    "\n",
    "    # Create the DataFrame with the reshaped predictions and the correct timestamps\n",
    "    predictions_df = pd.DataFrame(predictions, columns=target_columns, index=timestamps)\n",
    "    actuals_df = pd.DataFrame(actuals, columns=target_columns, index=timestamps)\n",
    "    \n",
    "    print(predictions_df.head())\n",
    "\n",
    "    # Apply reverse transformation and scaling to both predictions and actuals\n",
    "\n",
    "    # Plot the predictions and actuals before reverse transformation and scaling\n",
    "    print(\"Plotting predictions and actuals before reverse transformation and scaling\")\n",
    "    print(\"Values of predictions_df  and actuals_df before reverse transformation and scaling\")\n",
    "    print(predictions_df.head(3))\n",
    "    print(actuals_df.head(3))\n",
    "\n",
    "    plot_predictions(predictions_df, actuals_df, target_columns, plot_number)\n",
    "\n",
    "    # Apply reverse transformation and scaling to both predictions and actuals\n",
    "    predictions_df = reverse_transform_and_scale_data(predictions_df, current_transformation_metadata, target_columns)\n",
    "    actuals_df = reverse_transform_and_scale_data(actuals_df, current_transformation_metadata, target_columns)\n",
    "\n",
    "    # Example usage\n",
    "    print(\"Values of predictions_df  and actuals_df after reverse transformation and scaling\")\n",
    "    print(predictions_df.head(3))\n",
    "    print(actuals_df.head(3))\n",
    "    print(\"Plotting predictions and actuals after reverse transformation and scaling\")\n",
    "    plot_predictions(predictions_df, actuals_df, target_columns, plot_number)\n",
    "\n",
    "    return predictions_df, actuals_df, timestamps\n",
    "\n",
    "# Array of plot numbers\n",
    "plot_numbers = [2013]\n",
    "\n",
    "# initialize predictions_df and actuals_df and timestamps as empty dataframes\n",
    "predictions_df = pd.DataFrame()\n",
    "actuals_df = pd.DataFrame()\n",
    "timestamps = pd.Series()\n",
    "\n",
    "# open the transformation metadata file\n",
    "with open(f\"{checkpoint_path}/transformation_metadata1.pkl\", \"rb\") as file:\n",
    "    transformation_metadata = pickle.load(file)\n",
    "\n",
    "# initialize scalers from transformation_metadata\n",
    "scalers = transformation_metadata['scalers']\n",
    "keep_original_cols = transformation_metadata['keep_original_cols'] \n",
    "\n",
    "# Loop through plot numbers\n",
    "for plot_number in plot_numbers:\n",
    "    print(f\"Processing plot number {plot_number}\")\n",
    "    \n",
    "    model = tf.keras.models.load_model(checkpoint_path)\n",
    "    \n",
    "\n",
    "    df_plot = process_data_for_plot(plot_number)\n",
    "    \n",
    "    #drop VWC_40 column if it exists\n",
    "    if 'VWC_42' in df_plot.columns:\n",
    "        df_plot = df_plot.drop(columns=['VWC_42'])\n",
    "        \n",
    "    # Get the column order and headers from transformation_metadata\n",
    "    column_order = transformation_metadata['columns']\n",
    "    column_headers = transformation_metadata['columns']\n",
    "\n",
    "    # Reorder the columns in the dataframe\n",
    "    df_plot = df_plot[column_order]\n",
    "    \n",
    "    # Reindex the columns\n",
    "    df_plot.columns = column_headers\n",
    "\n",
    "    df_plot, current_transform_metadata = transform_and_scale_data(df_plot, target_columns, scalers, keep_original_cols)\n",
    "    \n",
    "    # print the means of the transformed data\n",
    "    print(\"Means of the transformed data\")\n",
    "    print(df_plot.mean())\n",
    "\n",
    "    \n",
    "    predictions_df, actuals_df, timestamps = predict_with_sliding_window(model, df_plot, current_transformation_metadata=current_transform_metadata, \n",
    "                                                                         target_columns=target_columns, input_window=24*7, forecast_horizon=96, plot_number=plot_number)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'means': {'VWC_06': 17.820361585349556, 'VWC_18': 18.113769235404764, 'VWC_30': 22.610070112912528}, 'scalers': {'Ta_2m_Avg': MinMaxScaler(), 'RH_2m_Avg': MinMaxScaler(), 'Solar_2m_Avg': MinMaxScaler(), 'WndAveSpd_3m': MinMaxScaler(), 'Dp_2m_Avg': MinMaxScaler(), 'TaMax_2m': MinMaxScaler(), 'TaMin_2m': MinMaxScaler(), 'RHMax_2m': MinMaxScaler(), 'RHMin_2m': MinMaxScaler(), 'HeatIndex_2m_Avg': MinMaxScaler(), 'canopy_temp': MinMaxScaler(), 'VWC_06': MinMaxScaler(), 'VWC_18': MinMaxScaler(), 'VWC_30': MinMaxScaler(), 'daily_et': MinMaxScaler(), 'CWSI': MinMaxScaler(), 'SWSI': MinMaxScaler(), 'precip_irrig': MinMaxScaler(), 'day_sin': MinMaxScaler(), 'day_cos': MinMaxScaler(), 'hour_sin': MinMaxScaler(), 'hour_cos': MinMaxScaler(), 'dow_sin': MinMaxScaler(), 'dow_cos': MinMaxScaler(), 'precip_irrig_log': MinMaxScaler(), 'VWC_06_deriv': MinMaxScaler(), 'VWC_18_deriv': MinMaxScaler(), 'VWC_30_deriv': MinMaxScaler()}, 'keep_original_cols': True, 'initial_values': {}, 'columns': ['Ta_2m_Avg', 'RH_2m_Avg', 'Solar_2m_Avg', 'WndAveSpd_3m', 'Dp_2m_Avg', 'TaMax_2m', 'TaMin_2m', 'RHMax_2m', 'RHMin_2m', 'HeatIndex_2m_Avg', 'canopy_temp', 'VWC_06', 'VWC_18', 'VWC_30', 'daily_et', 'CWSI', 'SWSI', 'precip_irrig', 'day_sin', 'day_cos', 'hour_sin', 'hour_cos', 'dow_sin', 'dow_cos', 'precip_irrig_log']}\n"
     ]
    }
   ],
   "source": [
    "#print transformed_metadata\n",
    "print(current_transform_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
